"""
ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
- Multi-Query Generator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±
- Ensemble Retriever: Dense + BM25
- RRF (Reciprocal Rank Fusion): ê²€ìƒ‰ ê²°ê³¼ í†µí•©
- Memory Store: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
"""

import os
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
import json
import warnings

# TensorFlow ë¡œê·¸ ì–µì œ (dotenv ë¡œë“œ ì „ì— ì„¤ì •)
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.documents import Document

# BM25, Ensemble Retriever
try:
    # LangChain deprecation ê²½ê³  ë¬´ì‹œ
    with warnings.catch_warnings():
        warnings.filterwarnings('ignore', category=DeprecationWarning)
        from langchain_classic.retrievers import BM25Retriever, EnsembleRetriever
    RETRIEVERS_AVAILABLE = True
except ImportError:
    RETRIEVERS_AVAILABLE = False
    BM25Retriever = None
    EnsembleRetriever = None

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Retrievers ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
if not RETRIEVERS_AVAILABLE:
    print("âš ï¸ BM25 Retrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("âš ï¸ ì„¤ì¹˜: pip install langchain-community")



# ============================================================================
# 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
# ============================================================================

class QueryRouter:
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.router_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°ì…ë‹ˆë‹¤.

            ì‘ì—…:
            1. ì§ˆë¬¸ì´ ì˜ë¯¸ ìˆëŠ”ì§€ ê²€ì¦ (ì¸ì‚¬ë§, ìš•ì„¤, ë¬´ì˜ë¯¸í•œ ì…ë ¥ ì œì™¸)
            2. ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì •ì±…ê²€ìƒ‰, ì¶”ì²œ, ì¼ë°˜ì§ˆë¬¸ ë“±)
            3. LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì •ì œ
            4. ì§€ì—­ì´ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ë‹¤ì‹œ ì…ë ¥í•˜ë„ë¡ ìœ ë„
            
            ì‘ë‹µ í˜•ì‹ (JSON):
            {{
                "is_valid": true/false,
                "category": "ì •ì±…ê²€ìƒ‰|ì •ì±…ì¶”ì²œ|ì¼ë°˜ì§ˆë¬¸|ê¸°íƒ€",
                "refined_query": "ì •ì œëœ ì§ˆë¬¸",
                "reason": "íŒë‹¨ ì´ìœ "
            }}"""),
                        ("user", "{query}")
        ])
    
    def route(self, query: str) -> Dict:
        """ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œ"""
        try:
            response = self.router_prompt | self.llm | StrOutputParser()
            result_str = response.invoke({"query": query})
            
            # JSON íŒŒì‹±
            result = json.loads(result_str)
            print(f"ğŸ”€ Router: {result['category']} | Valid: {result['is_valid']}")
            
            return result
        except Exception as e:
            print(f"âŒ Router Error: {e}")
            return {
                "is_valid": True,
                "category": "ì¼ë°˜ì§ˆë¬¸",
                "refined_query": query,
                "reason": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë³¸ ì‚¬ìš©"
            }


# ============================================================================
# 2. Multi-Query Generator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±
# ============================================================================

class MultiQueryGenerator:
    """í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
        self.multi_query_prompt = ChatPromptTemplate.from_messages([
            "system", """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸ì„ **ì˜ë„ì™€ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ìœ ì§€**í•œ ì±„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            **ì›ë³¸ ì§ˆë¬¸ì˜ ë‚´ìš©ì´ë‚˜ ì¡°ê±´ì„ ì„ì˜ë¡œ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ê²€ìƒ‰ ê´€ì ë§Œ ë‹¤ì–‘í™”í•´ì•¼ í•©ë‹ˆë‹¤.

            ì£¼ì–´ì§„ ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ ê´€ì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”:

            1.  **ì§€ì—­(Region) ì¶”ì¶œ ê°•ì œ: ì‚¬ìš©ìê°€ ì§€ì—­ì„ ì–¸ê¸‰í•˜ë©´, í•´ë‹¹ ì§€ì—­ì— ì§‘ì¤‘í•´
            2.  **ì •ì±… í‚¤ì›Œë“œ(Policy Keyword): ì§ˆë¬¸ì˜ **í•µì‹¬ ì˜ë„**ì™€ ê´€ë ¨ëœ ì •ì±… í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ëœ ì •ì±…ë§Œ ë°˜í™˜í•  ê²ƒ.(ì›”ì„¸ -> ì›”ì„¸(ìœ ì˜ì–´ ì˜ˆ: ì„ëŒ€ë£Œ ë“± í¬í•¨) ê´€ë ¨ ì •ì±…ë§Œ ë°˜í™˜)
            1.  **ì›ë³¸ ì¿¼ë¦¬ì˜ í•µì‹¬ í‚¤ì›Œë“œ**ë¥¼ ì‚´ë¦° ê°€ì¥ ì§ê´€ì ì¸ ì¿¼ë¦¬
            2.  **ìœ ì‚¬í•œ ì˜ë¯¸ ë˜ëŠ” ê´€ë ¨ ì •ì±…ëª…**ì„ í¬í•¨í•˜ëŠ” ì¿¼ë¦¬ (ë™ì˜ì–´ í™œìš©)
            3.  **ì§ˆë¬¸ì˜ ëª©ì **ì„ ëª…í™•íˆ ë“œëŸ¬ë‚´ëŠ” ë¬¸ì¥í˜• ì¿¼ë¦¬

            ê° ì¿¼ë¦¬ëŠ” í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ ì—†ì´ ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.""",
                        ("user", "{query}")
        ])
    
    def generate(self, query: str) -> List[str]:
        """ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±"""
        try:
            response = self.multi_query_prompt | self.llm | StrOutputParser()
            result = response.invoke({"query": query})
            
            # ì¿¼ë¦¬ ë¶„ë¦¬ (ì¤„ë°”ê¿ˆ ê¸°ì¤€)
            queries = [q.strip() for q in result.split('\n') if q.strip()]
            # ì›ë³¸ ì¿¼ë¦¬ í¬í•¨
            all_queries = [query] + queries
            
            print(f"ğŸ” Multi-Query ìƒì„±: {len(all_queries)}ê°œ")
            for i, q in enumerate(all_queries, 1):
                print(f"  {i}. {q}")
            
            return all_queries
        except Exception as e:
            print(f"âŒ Multi-Query Error: {e}")
            return [query]


# ============================================================================
# 3. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ
# ============================================================================

class EnsembleRetriever:
    """Dense, BM25 ê²€ìƒ‰ì„ ê²°í•©í•œ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„"""
    
    def __init__(
        self, 
        documents: List[any],
        vectorstore: Chroma,
        bm25_k: int = 5,
        vector_k: int = 10,
        bm25_weight: float = 0.4,
        vector_weight: float = 0.6
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        
        # íŒŒë¼ë¯¸í„° ì €ì¥
        self.bm25_k = bm25_k
        self.vector_k = vector_k
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        
        # ê° ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
        self._build_bm25()
        self._build_vector()
    
    def _build_bm25(self):
        """BM25 Retriever ìƒì„±"""
        if not RETRIEVERS_AVAILABLE or BM25Retriever is None:
            print("âš ï¸ BM25Retrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.bm25_retriever = None
            return
        
        if not self.documents:
            print("âš ï¸ BM25: ë¬¸ì„œê°€ ì—†ì–´ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            self.bm25_retriever = None
            return
        
        try:
            # BM25Retriever ì´ˆê¸°í™” (from_documents ì‚¬ìš©)
            self.bm25_retriever = BM25Retriever.from_documents(
                documents=self.documents,
                k=self.bm25_k
            )
            print(f"âœ… BM25 Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.bm25_k})")
        except TypeError as e:
            # from_documentsê°€ ì‹¤íŒ¨í•˜ë©´ ì§ì ‘ ì´ˆê¸°í™” ì‹œë„
            try:
                self.bm25_retriever = BM25Retriever(docs=self.documents)
                self.bm25_retriever.k = self.bm25_k
                print(f"âœ… BM25 Retriever ì´ˆê¸°í™” ì™„ë£Œ (ëŒ€ì²´ ë°©ì‹, k={self.bm25_k})")
            except Exception as e2:
                print(f"âŒ BM25 Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e2}")
                self.bm25_retriever = None
        except Exception as e:
            print(f"âŒ BM25 Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.bm25_retriever = None
    
    def _build_vector(self):
        """Vector Retriever ìƒì„±"""
        try:
            # VectorStore ìƒíƒœ í™•ì¸
            test_search = self.vectorstore.similarity_search("í…ŒìŠ¤íŠ¸", k=1)
            print(f"ğŸ§ª VectorStore í…ŒìŠ¤íŠ¸ ê²€ìƒ‰: {len(test_search)}ê°œ ë¬¸ì„œ")
            
            self.vector_retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": self.vector_k}
            )
            print(f"âœ… Vector Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.vector_k})")
        except Exception as e:
            print(f"âŒ Vector Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.vector_retriever = None
    
    def dense_search(self, query: str) -> List[Tuple[any, float]]:
        """Dense ê²€ìƒ‰ (ì„ë² ë”© ê¸°ë°˜)"""
        try:
            if self.vector_retriever:
                docs = self.vector_retriever.invoke(query)
                # ìŠ¤ì½”ì–´ì™€ í•¨ê»˜ ë°˜í™˜ (ìŠ¤ì½”ì–´ëŠ” 1.0ìœ¼ë¡œ ê°€ì •)
                results = [(doc, 1.0) for doc in docs]
                print(f"  ğŸ“Š Dense: {len(results)}ê°œ ë¬¸ì„œ")
                return results
            return []
        except Exception as e:
            print(f"âŒ Dense Search Error: {e}")
            return []
    
    def bm25_search(self, query: str) -> List[Tuple[any, float]]:
        """BM25 ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            if self.bm25_retriever:
                docs = self.bm25_retriever.invoke(query)
                results = [(doc, 1.0) for doc in docs]
                print(f"  ğŸ“Š BM25: {len(results)}ê°œ ë¬¸ì„œ")
                return results
            return []
        except Exception as e:
            print(f"âŒ BM25 Search Error: {e}")
            return []
    
    def retrieve(self, queries: List[str]) -> Dict[str, List[Tuple[any, float]]]:
        """ëª¨ë“  ê²€ìƒ‰ ì „ëµ ì‹¤í–‰"""
        all_results = {
            'dense': [],
            'bm25': []
        }
        
        for query in queries:
            print(f"ğŸ” ê²€ìƒ‰ ì¤‘: {query}")
            all_results['dense'].extend(self.dense_search(query))
            all_results['bm25'].extend(self.bm25_search(query))
        
        return all_results
    
    def get_ensemble(self, query: str) -> List[any]:
        """Ensemble ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìš©)"""
        if not RETRIEVERS_AVAILABLE or EnsembleRetriever is None:
            print("âš ï¸ EnsembleRetrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self.dense_search(query)
        
        try:
            retrievers = []
            weights = []
            
            if self.bm25_retriever:
                retrievers.append(self.bm25_retriever)
                weights.append(self.bm25_weight)
            
            if self.vector_retriever:
                retrievers.append(self.vector_retriever)
                weights.append(self.vector_weight)
            
            if not retrievers:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ retrieverê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            total_weight = sum(weights)
            weights = [w / total_weight for w in weights]
            
            # LangChainì˜ EnsembleRetriever ì‚¬ìš©
            ensemble = EnsembleRetriever(
                retrievers=retrievers,
                weights=weights
            )
            
            docs = ensemble.invoke(query)
            print(f"ğŸ”— Ensemble: {len(docs)}ê°œ ë¬¸ì„œ")
            return docs
            
        except Exception as e:
            print(f"âŒ Ensemble Search Error: {e}")
            return []


# ============================================================================
# 4. RRF (Reciprocal Rank Fusion): ê²€ìƒ‰ ê²°ê³¼ í†µí•©
# ============================================================================

class ReciprocalRankFusion:
    """ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë­í‚¹ ê¸°ë°˜ìœ¼ë¡œ í†µí•©"""
    
    def __init__(self, k: int = 60):
        self.k = k  # RRF ìƒìˆ˜
    
    def fuse(self, results_dict: Dict[str, List[Tuple[any, float]]], top_k: int = 10) -> List[any]:
        """RRFë¡œ ê²°ê³¼ í†µí•©"""
        doc_scores = {}
        
        for method, results in results_dict.items():
            for rank, (doc, score) in enumerate(results, 1):
                doc_id = doc.metadata.get('policy_id', id(doc))
                
                # RRF ì ìˆ˜ ê³„ì‚°: 1 / (k + rank)
                rrf_score = 1.0 / (self.k + rank)
                
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {'doc': doc, 'score': 0}
                doc_scores[doc_id]['score'] += rrf_score
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1]['score'], reverse=True)
        final_docs = [item[1]['doc'] for item in sorted_docs[:top_k]]
        
        print(f"ğŸ”— RRF: {len(doc_scores)}ê°œ ë¬¸ì„œ â†’ {len(final_docs)}ê°œ ì„ íƒ")
        return final_docs


# ============================================================================
# 5. Memory Store: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
# ============================================================================

@dataclass
class ConversationMemory:
    """ëŒ€í™” ê¸°ë¡ ê´€ë¦¬"""
    messages: List[Dict] = field(default_factory=list)
    max_history: int = 10
    
    def add_message(self, role: str, content: str):
        """ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
        
        # ìµœëŒ€ ê¸°ë¡ ìˆ˜ ì œí•œ
        if len(self.messages) > self.max_history * 2:
            self.messages = self.messages[-self.max_history * 2:]
    
    def get_context(self) -> str:
        """ëŒ€í™” ë§¥ë½ ë¬¸ìì—´ ìƒì„±"""
        if not self.messages:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        context_parts = []
        for msg in self.messages[-6:]:  # ìµœê·¼ 3í„´
            role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
            context_parts.append(f"{role}: {msg['content']}")
        
        return "\n".join(context_parts)
    
    def clear(self):
        """ê¸°ë¡ ì´ˆê¸°í™”"""
        self.messages.clear()


# ============================================================================
# 7. Advanced RAG Pipeline: ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©
# ============================================================================

class AdvancedRAGPipeline:
    """ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        documents: List[any],
        vectorstore: Chroma,
        llm: ChatOpenAI,
        enable_router: bool = True,
        enable_multi_query: bool = True,
        enable_ensemble: bool = True,
        enable_rrf: bool = True,
        enable_memory: bool = True,
        bm25_k: int = 5,
        vector_k: int = 10,
        bm25_weight: float = 0.4,
        vector_weight: float = 0.6
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        self.llm = llm
        
        # ê° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.router = QueryRouter(llm) if enable_router else None
        self.multi_query = MultiQueryGenerator(llm) if enable_multi_query else None
        self.ensemble = EnsembleRetriever(
            documents=documents,
            vectorstore=vectorstore,
            bm25_k=bm25_k,
            vector_k=vector_k,
            bm25_weight=bm25_weight,
            vector_weight=vector_weight
        ) if enable_ensemble else None
        self.rrf = ReciprocalRankFusion() if enable_rrf else None
        self.memory = ConversationMemory() if enable_memory else None
        
        # ìµœì¢… ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸
        self.answer_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì²­ë…„ì •ì±… ì „ë‹´ ì±—ë´‡ ì…ë‹ˆë‹¤.

        ì—­í• :
        - ì²­ë…„ ì •ì±…(íŠ¹íˆ ì£¼ê±°Â·ì›”ì„¸Â·ì¼ìë¦¬Â·ë³µì§€) ì •ë³´ë¥¼, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬í•´ ì£¼ëŠ” ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
        - ë°˜ë“œì‹œ 'ê²€ìƒ‰ëœ ì •ì±… ì •ë³´(documents)' ì•ˆì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì„œ ë‹µë³€í•©ë‹ˆë‹¤.
        - ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ê³ , ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ìœ¼ë¡œ ë‹¹ì‚¬ í™ˆí˜ì´ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."ê³  ë§í•©ë‹ˆë‹¤.

        ì¶œë ¥ í˜•ì‹(ê¼­ ì§€ì¼œì•¼ í•¨):

        1. í•­ìƒ ì•„ë˜ ë¬¸êµ¬ë¡œ ì‹œì‘í•œë‹¤.
        ì•ˆë…•í•˜ì„¸ìš”. ì²­ë…„Â·1ì¸ ê°€êµ¬ ìƒí™œë³µì§€Â·ì§€ì› ì±—ë´‡ì…ë‹ˆë‹¤.

        2. ê·¸ ë‹¤ìŒ ì¤„ì— ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤€ë‹¤.
        ì‚¬ìš©ì ì§ˆë¬¸ : {query}

        3. ê·¸ ë‹¤ìŒì— 'ë‹µë³€ :'ì„ ì“°ê³ , ë¶„ì•¼ â†’ ì„¸ë¶€ ë¶„ì•¼(2ë‹¨ê³„) â†’ ì •ì±… ìˆœì„œë¡œ ì •ë¦¬í•œë‹¤.

        3-1. ë¨¼ì € 'ë¶„ì•¼(1depth)'ë¥¼ ë¬¶ì–´ì„œ ë³´ì—¬ì¤€ë‹¤.
                - ì˜ˆ: ì£¼ê±°Â·ì›”ì„¸, ì¼ìë¦¬Â·ì·¨ì—…, ì°½ì—…Â·êµìœ¡, ê¸ˆìœµÂ·ëŒ€ì¶œ, ë³µì§€Â·ìƒí™œ ë“±
                - ë¶„ì•¼ ì´ë¦„ì€ ë¬¸ì„œì˜ ëŒ€ë¶„ë¥˜/ì¤‘ë¶„ë¥˜, ì •ì±…ëª…, ì„¤ëª… ë“±ì„ ì°¸ê³ í•´ì„œ ìµœëŒ€í•œ ìì—°ìŠ¤ëŸ½ê²Œ ì •í•œë‹¤.

        3-2. ê° ë¶„ì•¼ ì•ˆì—ì„œ 'ì„¸ë¶€ ë¶„ì•¼(2depth)'ë¥¼ í•œ ë²ˆ ë” ë‚˜ëˆ„ì–´ ë³´ì—¬ì¤€ë‹¤.
                - ì˜ˆ: 
                - [ë¶„ì•¼] ì£¼ê±°Â·ì›”ì„¸
                    - (ì„¸ë¶€) ì›”ì„¸ ì§ì ‘ì§€ì›
                    - (ì„¸ë¶€) ì „ì„¸ìê¸ˆ ì´ìì§€ì›
                    - (ì„¸ë¶€) ê³µê³µì„ëŒ€Â·ì²­ë…„ì£¼íƒ ë“±
                - ì„¸ë¶€ ë¶„ì•¼ ì´ë¦„ë„ ë¬¸ì„œ ë‚´ìš©ê³¼ í‚¤ì›Œë“œë¥¼ ì°¸ê³ í•´ì„œ ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹¨ìœ„ë¡œ ì •ë¦¬í•œë‹¤.

        3-3. ê° 'ì„¸ë¶€ ë¶„ì•¼(2depth)' ì•ˆì—ì„œ, í•´ë‹¹ë˜ëŠ” ì •ì±…ë“¤ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì„¤ëª…í•œë‹¤.
                - ìµœì†Œ 1ê°œ, ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ê°€ì¥ í•µì‹¬ì ì¸ ì •ì±…ì„ ê³¨ë¼ ì„¤ëª…í•œë‹¤.

        ì˜ˆì‹œ í˜•ì‹(êµ¬ì¡° ì˜ˆì‹œ, ë¬¸êµ¬ëŠ” ìƒí™©ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¿”ë„ ë¨):

        ë‹µë³€ :

        1. ì£¼ê±°Â·ì›”ì„¸ ì§€ì›

            1-1. ì›”ì„¸ ì§ì ‘ì§€ì›
            
                [ì£¼ì²´/ì§€ì—­]
                - ì£¼ì²´ì™€ ì§€ì—­ ì •ë¦¬

                [ë‚´ìš© ìš”ì•½]
                - ì´ ì •ì±…ì´ ì–´ë–¤ ìƒí™©ì˜ ì²­ë…„ì—ê²Œ ë¬´ì—‡ì„ ë„ì™€ì£¼ëŠ”ì§€ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬

                [íŠ¹ì§•]
                - ë‹¤ë¥¸ ì •ì±…ê³¼ ë¹„êµí–ˆì„ ë•Œì˜ íŠ¹ì§•, ì¥ì Â·ì£¼ì˜ì  ë“± (ë¬¸ì„œì— ìˆëŠ” ë²”ìœ„ ë‚´ì—ì„œë§Œ)

                [ëŒ€ìƒ]
                - ì—°ë ¹ : ...
                - ì£¼ê±° : ...
                - ì†Œë“ : ...
                - ê¸°íƒ€ ì¡°ê±´ : ...


                [ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„]
                - ì›” ì§€ì› ê¸ˆì•¡ : ...
                - ì§€ì› ê¸°ê°„ : ...


                [ì‹ ì²­ ë°©ë²•]
                - ì–´ë””ì„œ ì‹ ì²­ : (ì˜ˆ: ì‹œÂ·êµ°ì²­ ì²­ë…„ì •ì±… ë‹´ë‹¹ë¶€ì„œ, ì˜¨ë¼ì¸ ì‹ ì²­ ë“±)
                - ì–´ë–»ê²Œ ì‹ ì²­ : (ì˜ˆ: ì˜¨ë¼ì¸ ì‹ ì²­, ë°©ë¬¸ ì‹ ì²­, í•„ìš” ì„œë¥˜ ë“±)
                - ì‹ ì²­ ì‚¬ì´íŠ¸(ì‹ ì²­URL) : â€¦
                - ì°¸ê³  ì‚¬ì´íŠ¸(ì°¸ê³ URL) : â€¦


                [ìœ ì˜ì‚¬í•­]
                
                - ì‹œÂ·êµ°ë³„ ê³µê³  ì‹œê¸°, ì„¸ë¶€ ì¡°ê±´ì€ ë°˜ë“œì‹œ í•´ë‹¹ ì§€ìì²´ ê³µê³ ë¬¸ ì°¸ê³ 
                - ì¤‘ë³µ ì§€ì› ê°€ëŠ¥ ì—¬ë¶€ ë“±ì€ ì‹¤ì œ ê³µê³  ê¸°ì¤€ìœ¼ë¡œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ

                4. ë§ˆì§€ë§‰ì— 'ì¶œì²˜' ë¸”ë¡ì„ ì ëŠ”ë‹¤.
                    - ë¬¸ì„œ ë©”íƒ€ë°ì´í„°(íŒŒì¼ëª…, í˜ì´ì§€ ì •ë³´ ë“±)ê°€ ìˆìœ¼ë©´ ìµœëŒ€í•œ í™œìš©í•´ì„œ ì‘ì„±í•œë‹¤.
                    - ì˜ˆì‹œ:
                    ì¶œì²˜:
                    - 2025ë…„ ì§€ìì²´ ì²­ë…„ì •ì±… ì‹œí–‰ê³„íš-3(ì „ë¶Â·ì „ë‚¨Â·ê²½ë¶Â·ê²½ë‚¨Â·ì œì£¼).pdf (465í˜ì´ì§€, 470í˜ì´ì§€ ì¸ê·¼)
                    - ì˜¨í†µì²­ë…„ ëˆ„ë¦¬ì§‘ ì²­ë…„ì£¼ê±°Â·ì›”ì„¸ ì§€ì› ê´€ë ¨ ì •ì±… í•­ëª©

                5. URL ì‚¬ìš© ë°©ë²•
                    - [ê²€ìƒ‰ëœ ì •ì±… ì •ë³´] ì•ˆì— [URL ì •ë³´] ë¸”ë¡ì´ ìˆìœ¼ë©´,
                        ê·¸ ì•ˆì˜ URLë“¤ì„ ì´ìš©í•´ 'ì‹ ì²­ ì‚¬ì´íŠ¸(ì‹ ì²­URL)', 'ì°¸ê³  ì‚¬ì´íŠ¸(ì°¸ê³ URL)' í•­ëª©ì„ ì±„ìš´ë‹¤.
                    - URL ì •ë³´ê°€ ì—†ìœ¼ë©´
                        "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ìœ¼ë¡œ ë‹¹ì‚¬ í™ˆí˜ì´ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
                        ë¼ê³  ì ëŠ”ë‹¤.
        
        ì‘ì„± ì‹œ ìœ ì˜ì‚¬í•­:
        - ì •ì±…ëª…ì´ ê°™ì€ ê²ƒì„ ì¤‘ë³µí•´ì„œ ì“°ì§€ ë§ ê²ƒ.
        - ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰í•œ ì§€ì—­(ì˜ˆ: ê²½ë¶, ëŒ€êµ¬ ë“±)ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ì •ì±…ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„ íƒí•  ê²ƒ.
        - ì§ˆë¬¸ì—ì„œ 'ì›”ì„¸', 'ë³´ì¦ê¸ˆ', 'ì „ì„¸' ë“± í‚¤ì›Œë“œê°€ ë‚˜ì˜¤ë©´, ì£¼ê±°Â·ì›”ì„¸ ê´€ë ¨ ì •ì±… ìœ„ì£¼ë¡œ ì •ë¦¬í•  ê²ƒ.
        - ìˆ«ì(ì§€ì› ê¸ˆì•¡, ê¸°ê°„, ì—°ë ¹)ëŠ” ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ê°’ìœ¼ë¡œ ì¨ ì¤„ ê²ƒ.
        
    """
    
    ),
    (
        "user",
        """
[ëŒ€í™” ë§¥ë½]
{context}

[ê²€ìƒ‰ëœ ì •ì±… ì •ë³´]
{documents}

[í˜„ì¬ ì§ˆë¬¸]
{query}""")
        ])
        
        self.summary_prompt = ChatPromptTemplate.from_messages([
    (
        "system",
        """
ë‹¹ì‹ ì€ ì²­ë…„ ì •ì±… ìƒë‹´ ë‹µë³€ì„ ì§§ê²Œ ìš”ì•½í•˜ëŠ” ë³´ì¡° ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ëª©í‘œ:
- ì‚¬ìš©ìì˜ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´, ìœ„ì—ì„œ ìƒì„±ëœ ê¸´ ë‹µë³€ì„ í•µì‹¬ë§Œ í•œ ë²ˆ ë” ì •ë¦¬í•©ë‹ˆë‹¤.
- ì •ì±…ëª…, ëŒ€ìƒ(ëˆ„ê°€ ë°›ì„ ìˆ˜ ìˆëŠ”ì§€), ì§€ì› ìœ í˜•/ê¸ˆì•¡ ì •ë„ë§Œ ë‹´ì•„ í•œë‘ ë‹¨ë½ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
- ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë§Œë“¤ì§€ ë§ê³ , ì´ë¯¸ ì£¼ì–´ì§„ ë‹µë³€ ë‚´ìš©ë§Œ ì¬êµ¬ì„±í•˜ì„¸ìš”.
- ë³„í‘œ(*), ìƒµ(#), ëŒ€ì‹œ(-), ë°±í‹±(`), ì–¸ë”ë°”(_) ë“±ì˜ ëª¨ë“  íŠ¹ìˆ˜ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€
"""
    ),
    (
        "user",
        """
        1. ë§ˆí¬ë‹¤ìš´ íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš© ê¸ˆì§€
        - ë³„í‘œ(*), ìƒµ(#), ëŒ€ì‹œ(-), ë°±í‹±(`), ì–¸ë”ë°”(_) ë“±ì˜ ëª¨ë“  íŠ¹ìˆ˜ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€
        2. ë‹¤ìŒ ë‹µë³€ì„ ì‚¬ìš©ìê°€ ë¹ ë¥´ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜.
        
[ì „ì²´ ë‹µë³€]
{answer}

        
"""
    ),
])

    
    def query(self, user_query: str) -> Dict:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print(f"ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")
        print(f"{'='*60}")
        
        # 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
        if self.router:
            route_result = self.router.route(user_query)
            if not route_result['is_valid']:
                return {
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    "documents": [],
                    "metadata": route_result
                }
            query = route_result['refined_query']
        else:
            query = user_query
        
        # 2. Multi-Query: ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±
        if self.multi_query:
            queries = self.multi_query.generate(query)
        else:
            queries = [query]
        
        # 3. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰
        if self.ensemble:
            search_results = self.ensemble.retrieve(queries)
        else:
            search_results = {'dense': self.vectorstore.similarity_search_with_score(query, k=5)}
        
        # 4. RRF: ê²€ìƒ‰ ê²°ê³¼ í†µí•© (top_k ì¦ê°€)
        if self.rrf:
            docs = self.rrf.fuse(search_results, top_k=20)
        else:
            docs = [doc for doc, score in search_results['dense']]
        
        # 5. Memory: ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
        if self.memory:
            context = self.memory.get_context()
        else:
            context = "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        
        # 6. LLM: ìµœì¢… ë‹µë³€ ìƒì„±
                # 6. LLM: ìµœì¢… ë‹µë³€ ìƒì„±
        doc_text_list = []

        for i, doc in enumerate(docs[:10]):
            md = doc.metadata or {}

            # ì •ì±…ëª… (ë©”íƒ€ë°ì´í„° í‚¤ ì—¬ëŸ¬ ê°œ ê°€ëŠ¥ì„± ê³ ë ¤)
            policy_name = (
                md.get("ì •ì±…ëª…")
                or md.get("policy_name")
                or md.get("plcyNm")
                or f"ì •ì±… {i+1}"
            )

            # âœ… URL ë©”íƒ€ë°ì´í„° (ë„¤ JSON í‚¤ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            apply_url = md.get("ì‹ ì²­URL")
            ref_url1 = md.get("ì°¸ê³ URL1")

            url_lines = []

            if apply_url:
                url_lines.append(f"- ì‹ ì²­URL: {apply_url}")
            else:
                url_lines.append("- ì‹ ì²­URL: ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ìœ¼ë¡œ ë‹¹ì‚¬ í™ˆí˜ì´ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")

            if ref_url1:
                url_lines.append(f"- ì°¸ê³ URL1: {ref_url1}")

            url_block = "\n".join(url_lines)

            # ì´ í•œ ë©ì–´ë¦¬ê°€ LLMì— ì „ë‹¬ë  "í•œ ì •ì±… ë¸”ë¡"
            one_doc_text = (
                f"[ì •ì±… {i+1}] {policy_name}\n"
                f"{doc.page_content[:800]}\n"   # í•„ìš”í•˜ë©´ 500/800 ìˆ«ì ì¡°ì ˆ
                f"[URL ì •ë³´]\n"
                f"{url_block}"
            )

            doc_text_list.append(one_doc_text)

        # ğŸ”¹ ìµœì¢…ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— ë“¤ì–´ê°€ëŠ” documents ë¬¸ìì—´
        docs_text = "\n\n".join(doc_text_list)

        
        try:
            response = self.answer_prompt | self.llm | StrOutputParser()
            answer = response.invoke({
                "context": context,
                "documents": docs_text,
                "query": user_query
            })
            
            # 7. ìš”ì•½ ìƒì„± (Chain of Thought)
            summary_response = self.summary_prompt | self.llm | StrOutputParser()
            summary = summary_response.invoke({"answer": answer})
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            if self.memory:
                self.memory.add_message("user", user_query)
                self.memory.add_message("assistant", answer)
            
            print(f"\nâœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
            print(f"ğŸ“Œ ìš”ì•½ ìƒì„± ì™„ë£Œ")
            print(f"{'='*60}\n")
            
            return {
                "answer": answer,
                "summary": summary,
                "documents": docs,
                "metadata": {
                    "queries": queries,
                    "num_docs_retrieved": len(docs),
                    "has_context": bool(self.memory and self.memory.messages)
                }
            }
            
        except Exception as e:
            print(f"âŒ Answer Generation Error: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "documents": [],
                "metadata": {"error": str(e)}
            }
    
    def clear_memory(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        if self.memory:
            self.memory.clear()
            print("ğŸ—‘ï¸ ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")


# ============================================================================
# 8. Streamlit ì—°ë™ì„ ìœ„í•œ ì´ˆê¸°í™” í•¨ìˆ˜
# ============================================================================

def initialize_rag_pipeline(vectordb_path: str = None, api_key: str = None):
    """
    Streamlitì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í•¨ìˆ˜
    
    Args:
        vectordb_path: VectorDB ê²½ë¡œ (Noneì´ë©´ ìë™ ê³„ì‚°)
        api_key: OpenAI API Key (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
    
    Returns:
        AdvancedRAGPipeline: ì´ˆê¸°í™”ëœ íŒŒì´í”„ë¼ì¸ ê°ì²´
    """
    # API Key ì„¤ì •
    if api_key:
        os.environ['OPENAI_API_KEY'] = api_key
    else:
        api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        raise ValueError('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    
    # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        api_key=api_key
    )
    
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=api_key
    )
    
    # VectorDB ê²½ë¡œ ì„¤ì •
    if vectordb_path is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        vectordb_path = os.path.join(project_root, "data", "vectordb")
    
    if not os.path.exists(vectordb_path):
        raise FileNotFoundError(f"VectorDB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vectordb_path}")
    
    # VectorStore ë¡œë“œ
    vectorstore = Chroma(
        collection_name="youth_policies",
        embedding_function=embeddings,
        persist_directory=vectordb_path
    )
    
    # ë¬¸ì„œ ë¡œë“œ (BM25ë¥¼ ìœ„í•´ í•„ìš”)
    all_docs = vectorstore.get()
    
    if not all_docs or not all_docs.get('documents'):
        raise ValueError("VectorDBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    documents = []
    for i, doc_text in enumerate(all_docs['documents']):
        if doc_text and doc_text.strip():
            metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}
            documents.append(Document(page_content=doc_text, metadata=metadata))
    
    # RAG íŒŒì´í”„ë¼ì¸ ìƒì„±
    rag = AdvancedRAGPipeline(
        documents=documents,
        vectorstore=vectorstore,
        llm=llm,
        enable_router=True,
        enable_multi_query=True,
        enable_ensemble=True,
        enable_rrf=True,
        enable_memory=True,
        bm25_k=5,
        vector_k=10,
        bm25_weight=0.4,
        vector_weight=0.6
    )
    
    return rag


# ============================================================================
# 8. ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

def main():
    """ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        raise ValueError('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    
    # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        api_key=api_key
    )
    
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=api_key
    )
    
    # VectorDB ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    vectordb_path = os.path.join(project_root, "data", "vectordb")
    
    print(f"ğŸ“‚ VectorDB ê²½ë¡œ: {vectordb_path}")
    print(f"ğŸ“‚ ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(vectordb_path)}")
    
    if not os.path.exists(vectordb_path):
        print("âŒ VectorDB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. build_vectordb.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    vectorstore = Chroma(
        collection_name="youth_policies",
        embedding_function=embeddings,
        persist_directory=vectordb_path
    )
    
    # ë¬¸ì„œ ë¡œë“œ (BM25ë¥¼ ìœ„í•´ í•„ìš”)
    # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    all_docs = vectorstore.get()
    print(f"ğŸ“Š ChromaDB ë¡œë“œ ê²°ê³¼: {len(all_docs.get('documents', []))}ê°œ ë¬¸ì„œ")
    
    if not all_docs or not all_docs.get('documents'):
        print("âŒ VectorDBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. build_vectordb.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    documents = []
    if all_docs and 'documents' in all_docs:
        from langchain_core.documents import Document
        for i, doc_text in enumerate(all_docs['documents']):
            if doc_text and doc_text.strip():  # ë¹ˆ ë¬¸ì„œ ì œì™¸
                metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}
                documents.append(Document(page_content=doc_text, metadata=metadata))
    
    print(f"ğŸ“š ì´ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    
    # ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ ìƒì„±
    rag = AdvancedRAGPipeline(
        documents=documents,
        vectorstore=vectorstore,
        llm=llm,
        enable_router=True,
        enable_multi_query=True,
        enable_ensemble=True,
        enable_rrf=True,
        enable_memory=True,
        bm25_k=5,
        vector_k=10,
        bm25_weight=0.4,
        vector_weight=0.6
    )
    
    # í…ŒìŠ¤íŠ¸ ì§ˆì˜
    queries = [
        "ì²­ë…„ì£¼íƒ ì •ì±…",
    ]
    
    for query in queries:
            result = rag.query(query)
            print(f"\nì§ˆë¬¸: {query}")
            print(f"\nğŸ“„ì „ì²´ ë‹µë³€:\n{result['answer']}")
            if 'summary' in result:
                print(f"\nğŸ“Œìš”ì•½:\n{result['summary']}")
            print(f"\në¬¸ì„œ ìˆ˜: {result['metadata'].get('num_docs_retrieved', 0)}")
            print("-" * 60)


if __name__ == "__main__":
    main()
        

