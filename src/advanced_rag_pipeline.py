"""
ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
- Multi-Query Generator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±
- Ensemble Retriever: Dense + BM25 + TF-IDF
- RRF (Reciprocal Rank Fusion): ê²€ìƒ‰ ê²°ê³¼ í†µí•©
- Self-Reg: ë¬¸ì„œ í’ˆì§ˆ ê²€ì¦
- Memory Store: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
"""

import os
import logging
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
import json

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.documents import Document

# BM25, TF-IDF, Ensemble Retriever
try:
    from langchain_classic.retrievers import BM25Retriever, EnsembleRetriever, TFIDFRetriever
    RETRIEVERS_AVAILABLE = True
except ImportError:
    RETRIEVERS_AVAILABLE = False
    BM25Retriever = None
    TFIDFRetriever = None
    EnsembleRetriever = None

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger('advanced_rag')

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Retrievers ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
if not RETRIEVERS_AVAILABLE:
    print("âš ï¸ BM25/TF-IDF Retrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("âš ï¸ ì„¤ì¹˜: pip install langchain-community")



# ============================================================================
# 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
# ============================================================================

class QueryRouter:
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.router_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°ì…ë‹ˆë‹¤.

ì‘ì—…:
1. ì§ˆë¬¸ì´ ì˜ë¯¸ ìˆëŠ”ì§€ ê²€ì¦ (ì¸ì‚¬ë§, ìš•ì„¤, ë¬´ì˜ë¯¸í•œ ì…ë ¥ ì œì™¸)
2. ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì •ì±…ê²€ìƒ‰, ì¶”ì²œ, ì¼ë°˜ì§ˆë¬¸ ë“±)
3. LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì •ì œ

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "is_valid": true/false,
    "category": "ì •ì±…ê²€ìƒ‰|ì •ì±…ì¶”ì²œ|ì¼ë°˜ì§ˆë¬¸|ê¸°íƒ€",
    "refined_query": "ì •ì œëœ ì§ˆë¬¸",
    "reason": "íŒë‹¨ ì´ìœ "
}}"""),
            ("user", "{query}")
        ])
    
    def route(self, query: str) -> Dict:
        """ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œ"""
        try:
            response = self.router_prompt | self.llm | StrOutputParser()
            result_str = response.invoke({"query": query})
            
            # JSON íŒŒì‹±
            result = json.loads(result_str)
            print(f"ğŸ”€ Router: {result['category']} | Valid: {result['is_valid']}")
            
            return result
        except Exception as e:
            print(f"âŒ Router Error: {e}")
            return {
                "is_valid": True,
                "category": "ì¼ë°˜ì§ˆë¬¸",
                "refined_query": query,
                "reason": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë³¸ ì‚¬ìš©"
            }


# ============================================================================
# 2. Multi-Query Generator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±
# ============================================================================

class MultiQueryGenerator:
    """í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.multi_query_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë‹¤ì–‘í•œ ê´€ì ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ ê´€ì ì—ì„œ ì¬êµ¬ì„±í•˜ì„¸ìš”:
1. í‚¤ì›Œë“œ ì¤‘ì‹¬ ì¿¼ë¦¬
2. ì˜ë¯¸ ì¤‘ì‹¬ ì¿¼ë¦¬
3. ë§¥ë½ ì¤‘ì‹¬ ì¿¼ë¦¬

ê° ì¿¼ë¦¬ëŠ” í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ ì—†ì´ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”."""),
            ("user", "{query}")
        ])
    
    def generate(self, query: str) -> List[str]:
        """ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±"""
        try:
            response = self.multi_query_prompt | self.llm | StrOutputParser()
            result = response.invoke({"query": query})
            
            # ì¿¼ë¦¬ ë¶„ë¦¬ (ì¤„ë°”ê¿ˆ ê¸°ì¤€)
            queries = [q.strip() for q in result.split('\n') if q.strip()]
            # ì›ë³¸ ì¿¼ë¦¬ í¬í•¨
            all_queries = [query] + queries
            
            print(f"ğŸ” Multi-Query ìƒì„±: {len(all_queries)}ê°œ")
            for i, q in enumerate(all_queries, 1):
                print(f"  {i}. {q}")
            
            return all_queries
        except Exception as e:
            print(f"âŒ Multi-Query Error: {e}")
            return [query]


# ============================================================================
# 3. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ
# ============================================================================

class EnsembleRetriever:
    """Dense, BM25, TF-IDF ê²€ìƒ‰ì„ ê²°í•©í•œ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„"""
    
    def __init__(
        self, 
        documents: List[any],
        vectorstore: Chroma,
        bm25_k: int = 5,
        tfidf_k: int = 5,
        vector_k: int = 5,
        bm25_weight: float = 0.3,
        tfidf_weight: float = 0.3,
        vector_weight: float = 0.4
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        
        # íŒŒë¼ë¯¸í„° ì €ì¥
        self.bm25_k = bm25_k
        self.tfidf_k = tfidf_k
        self.vector_k = vector_k
        self.bm25_weight = bm25_weight
        self.tfidf_weight = tfidf_weight
        self.vector_weight = vector_weight
        
        # ê° ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
        self._build_bm25()
        self._build_tfidf()
        self._build_vector()
    
    def _build_bm25(self):
        """BM25 Retriever ìƒì„±"""
        if not RETRIEVERS_AVAILABLE or BM25Retriever is None:
            print("âš ï¸ BM25Retrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.bm25_retriever = None
            return
        
        try:
            self.bm25_retriever = BM25Retriever.from_documents(self.documents)
            self.bm25_retriever.k = self.bm25_k
            print(f"âœ… BM25 Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.bm25_k})")
        except Exception as e:
            print(f"âŒ BM25 Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.bm25_retriever = None
    
    def _build_tfidf(self):
        """TF-IDF Retriever ìƒì„±"""
        if not RETRIEVERS_AVAILABLE or TFIDFRetriever is None:
            print("âš ï¸ TFIDFRetrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.tfidf_retriever = None
            return
        
        try:
            self.tfidf_retriever = TFIDFRetriever.from_documents(self.documents)
            self.tfidf_retriever.k = self.tfidf_k
            print(f"âœ… TF-IDF Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.tfidf_k})")
        except Exception as e:
            print(f"âŒ TF-IDF Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.tfidf_retriever = None
    
    def _build_vector(self):
        """Vector Retriever ìƒì„±"""
        try:
            self.vector_retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": self.vector_k}
            )
            print(f"âœ… Vector Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.vector_k})")
        except Exception as e:
            print(f"âŒ Vector Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.vector_retriever = None
    
    def dense_search(self, query: str) -> List[Tuple[any, float]]:
        """Dense ê²€ìƒ‰ (ì„ë² ë”© ê¸°ë°˜)"""
        try:
            if self.vector_retriever:
                docs = self.vector_retriever.invoke(query)
                # ìŠ¤ì½”ì–´ì™€ í•¨ê»˜ ë°˜í™˜ (ìŠ¤ì½”ì–´ëŠ” 1.0ìœ¼ë¡œ ê°€ì •)
                results = [(doc, 1.0) for doc in docs]
                print(f"  ğŸ“Š Dense: {len(results)}ê°œ ë¬¸ì„œ")
                return results
            return []
        except Exception as e:
            print(f"âŒ Dense Search Error: {e}")
            return []
    
    def bm25_search(self, query: str) -> List[Tuple[any, float]]:
        """BM25 ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            if self.bm25_retriever:
                docs = self.bm25_retriever.invoke(query)
                results = [(doc, 1.0) for doc in docs]
                print(f"  ğŸ“Š BM25: {len(results)}ê°œ ë¬¸ì„œ")
                return results
            return []
        except Exception as e:
            print(f"âŒ BM25 Search Error: {e}")
            return []
    
    def tfidf_search(self, query: str) -> List[Tuple[any, float]]:
        """TF-IDF ê²€ìƒ‰"""
        try:
            if self.tfidf_retriever:
                docs = self.tfidf_retriever.invoke(query)
                results = [(doc, 1.0) for doc in docs]
                print(f"  ğŸ“Š TF-IDF: {len(results)}ê°œ ë¬¸ì„œ")
                return results
            return []
        except Exception as e:
            print(f"âŒ TF-IDF Search Error: {e}")
            return []
    
    def retrieve(self, queries: List[str]) -> Dict[str, List[Tuple[any, float]]]:
        """ëª¨ë“  ê²€ìƒ‰ ì „ëµ ì‹¤í–‰"""
        all_results = {
            'dense': [],
            'bm25': [],
            'tfidf': []
        }
        
        for query in queries:
            print(f"ğŸ” ê²€ìƒ‰ ì¤‘: {query}")
            all_results['dense'].extend(self.dense_search(query))
            all_results['bm25'].extend(self.bm25_search(query))
            all_results['tfidf'].extend(self.tfidf_search(query))
        
        return all_results
    
    def get_ensemble(self, query: str) -> List[any]:
        """Ensemble ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìš©)"""
        if not RETRIEVERS_AVAILABLE or EnsembleRetriever is None:
            print("âš ï¸ EnsembleRetrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self.dense_search(query)
        
        try:
            retrievers = []
            weights = []
            
            if self.bm25_retriever:
                retrievers.append(self.bm25_retriever)
                weights.append(self.bm25_weight)
            
            if self.tfidf_retriever:
                retrievers.append(self.tfidf_retriever)
                weights.append(self.tfidf_weight)
            
            if self.vector_retriever:
                retrievers.append(self.vector_retriever)
                weights.append(self.vector_weight)
            
            if not retrievers:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ retrieverê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            total_weight = sum(weights)
            weights = [w / total_weight for w in weights]
            
            # LangChainì˜ EnsembleRetriever ì‚¬ìš©
            ensemble = EnsembleRetriever(
                retrievers=retrievers,
                weights=weights
            )
            
            docs = ensemble.invoke(query)
            print(f"ğŸ”— Ensemble: {len(docs)}ê°œ ë¬¸ì„œ")
            return docs
            
        except Exception as e:
            print(f"âŒ Ensemble Search Error: {e}")
            return []


# ============================================================================
# 4. RRF (Reciprocal Rank Fusion): ê²€ìƒ‰ ê²°ê³¼ í†µí•©
# ============================================================================

class ReciprocalRankFusion:
    """ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë­í‚¹ ê¸°ë°˜ìœ¼ë¡œ í†µí•©"""
    
    def __init__(self, k: int = 60):
        self.k = k  # RRF ìƒìˆ˜
    
    def fuse(self, results_dict: Dict[str, List[Tuple[any, float]]], top_k: int = 10) -> List[any]:
        """RRFë¡œ ê²°ê³¼ í†µí•©"""
        doc_scores = {}
        
        for method, results in results_dict.items():
            for rank, (doc, score) in enumerate(results, 1):
                doc_id = doc.metadata.get('policy_id', id(doc))
                
                # RRF ì ìˆ˜ ê³„ì‚°: 1 / (k + rank)
                rrf_score = 1.0 / (self.k + rank)
                
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {'doc': doc, 'score': 0}
                doc_scores[doc_id]['score'] += rrf_score
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1]['score'], reverse=True)
        final_docs = [item[1]['doc'] for item in sorted_docs[:top_k]]
        
        print(f"ğŸ”— RRF: {len(doc_scores)}ê°œ ë¬¸ì„œ â†’ {len(final_docs)}ê°œ ì„ íƒ")
        return final_docs


# ============================================================================
# 5. Self-Reg: ë¬¸ì„œ í’ˆì§ˆ ê²€ì¦
# ============================================================================

class SelfRegValidator:
    """LLMì´ ë¬¸ì„œì˜ ì •í™•ì„±ê³¼ ì í•©ì„±ì„ ìì²´ ê²€ì¦"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.validator_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ë¬¸ì„œì˜ ì •í™•ì„±ê³¼ ì í•©ì„±ì„ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ íŒë‹¨í•˜ì„¸ìš”:
1. ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ê°€?
2. ë¬¸ì„œì˜ ì •ë³´ê°€ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€?
3. ë¬¸ì„œê°€ ë‹µë³€ ìƒì„±ì— ë„ì›€ì´ ë˜ëŠ”ê°€?

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "is_relevant": true/false,
    "confidence": 0.0~1.0,
    "reason": "íŒë‹¨ ì´ìœ "
}}"""),
            ("user", """ì§ˆë¬¸: {query}

ë¬¸ì„œ ì œëª©: {title}
ë¬¸ì„œ ë‚´ìš©: {content}""")
        ])
    
    def validate(self, query: str, docs: List[any]) -> List[any]:
        """ë¬¸ì„œ í’ˆì§ˆ ê²€ì¦"""
        validated_docs = []
        
        for doc in docs:
            try:
                title = doc.metadata.get('policy_name', 'ì œëª© ì—†ìŒ')
                content = doc.page_content[:500]  # ì²˜ìŒ 500ìë§Œ
                
                response = self.validator_prompt | self.llm | StrOutputParser()
                result_str = response.invoke({
                    "query": query,
                    "title": title,
                    "content": content
                })
                
                result = json.loads(result_str)
                
                if result['is_relevant'] and result['confidence'] > 0.5:
                    validated_docs.append(doc)
                    print(f"  âœ… {title} (ì‹ ë¢°ë„: {result['confidence']:.2f})")
                else:
                    print(f"  âŒ {title} (ì‹ ë¢°ë„: {result['confidence']:.2f})")
                    
            except Exception as e:
                print(f"âŒ Validation Error: {e}")
                validated_docs.append(doc)  # ì—ëŸ¬ ì‹œ í¬í•¨
        
        print(f"ğŸ” Self-Reg: {len(docs)}ê°œ â†’ {len(validated_docs)}ê°œ ê²€ì¦ í†µê³¼")
        return validated_docs


# ============================================================================
# 6. Memory Store: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
# ============================================================================

@dataclass
class ConversationMemory:
    """ëŒ€í™” ê¸°ë¡ ê´€ë¦¬"""
    messages: List[Dict] = field(default_factory=list)
    user_profile: Dict = field(default_factory=dict)
    max_history: int = 10
    
    def add_message(self, role: str, content: str):
        """ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
        
        # ìµœëŒ€ ê¸°ë¡ ìˆ˜ ì œí•œ
        if len(self.messages) > self.max_history * 2:
            self.messages = self.messages[-self.max_history * 2:]
    
    def update_profile(self, **kwargs):
        """ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""
        self.user_profile.update(kwargs)
    
    def get_context(self) -> str:
        """ëŒ€í™” ë§¥ë½ ë¬¸ìì—´ ìƒì„±"""
        if not self.messages:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        context_parts = []
        for msg in self.messages[-6:]:  # ìµœê·¼ 3í„´
            role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
            context_parts.append(f"{role}: {msg['content']}")
        
        return "\n".join(context_parts)
    
    def clear(self):
        """ê¸°ë¡ ì´ˆê¸°í™”"""
        self.messages.clear()
        self.user_profile.clear()


# ============================================================================
# 7. Advanced RAG Pipeline: ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©
# ============================================================================

class AdvancedRAGPipeline:
    """ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        documents: List[any],
        vectorstore: Chroma,
        llm: ChatOpenAI,
        enable_router: bool = True,
        enable_multi_query: bool = True,
        enable_ensemble: bool = True,
        enable_rrf: bool = True,
        enable_self_reg: bool = True,
        enable_memory: bool = True,
        bm25_k: int = 5,
        tfidf_k: int = 5,
        vector_k: int = 5,
        bm25_weight: float = 0.3,
        tfidf_weight: float = 0.3,
        vector_weight: float = 0.4
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        self.llm = llm
        
        # ê° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.router = QueryRouter(llm) if enable_router else None
        self.multi_query = MultiQueryGenerator(llm) if enable_multi_query else None
        self.ensemble = EnsembleRetriever(
            documents=documents,
            vectorstore=vectorstore,
            bm25_k=bm25_k,
            tfidf_k=tfidf_k,
            vector_k=vector_k,
            bm25_weight=bm25_weight,
            tfidf_weight=tfidf_weight,
            vector_weight=vector_weight
        ) if enable_ensemble else None
        self.rrf = ReciprocalRankFusion() if enable_rrf else None
        self.self_reg = SelfRegValidator(llm) if enable_self_reg else None
        self.memory = ConversationMemory() if enable_memory else None
        
        # ìµœì¢… ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸
        self.answer_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì²­ë…„ ì •ì±… ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

ê²€ìƒ‰ëœ ì •ì±… ì •ë³´ì™€ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ë‹µë³€ ì›ì¹™:
1. ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
2. ì •ì±…ëª…, ì‹ ì²­ ê¸°ê°„, ì§€ì› ë‚´ìš© ë“± êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
3. ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€
4. ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì†”ì§í•˜ê²Œ ë§í•˜ê¸°"""),
            ("user", """[ëŒ€í™” ë§¥ë½]
{context}

[ì‚¬ìš©ì í”„ë¡œí•„]
{profile}

[ê²€ìƒ‰ëœ ì •ì±… ì •ë³´]
{documents}

[í˜„ì¬ ì§ˆë¬¸]
{query}""")
        ])
    
    def query(self, user_query: str) -> Dict:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print(f"ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")
        print(f"{'='*60}")
        
        # 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
        if self.router:
            route_result = self.router.route(user_query)
            if not route_result['is_valid']:
                return {
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    "documents": [],
                    "metadata": route_result
                }
            query = route_result['refined_query']
        else:
            query = user_query
        
        # 2. Multi-Query: ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±
        if self.multi_query:
            queries = self.multi_query.generate(query)
        else:
            queries = [query]
        
        # 3. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰
        if self.ensemble:
            search_results = self.ensemble.retrieve(queries)
        else:
            search_results = {'dense': self.vectorstore.similarity_search_with_score(query, k=5)}
        
        # 4. RRF: ê²€ìƒ‰ ê²°ê³¼ í†µí•©
        if self.rrf:
            docs = self.rrf.fuse(search_results, top_k=10)
        else:
            docs = [doc for doc, score in search_results['dense']]
        
        # 5. Self-Reg: ë¬¸ì„œ í’ˆì§ˆ ê²€ì¦
        if self.self_reg:
            docs = self.self_reg.validate(query, docs)
        
        # 6. Memory: ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
        if self.memory:
            context = self.memory.get_context()
            profile = json.dumps(self.memory.user_profile, ensure_ascii=False)
        else:
            context = "ì´ì „ ëŒ€í™” ì—†ìŒ"
            profile = "{}"
        
        # 7. LLM: ìµœì¢… ë‹µë³€ ìƒì„±
        docs_text = "\n\n".join([
            f"[ì •ì±… {i+1}] {doc.metadata.get('policy_name', 'ì œëª© ì—†ìŒ')}\n{doc.page_content[:300]}"
            for i, doc in enumerate(docs[:5])
        ])
        
        try:
            response = self.answer_prompt | self.llm | StrOutputParser()
            answer = response.invoke({
                "context": context,
                "profile": profile,
                "documents": docs_text,
                "query": user_query
            })
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            if self.memory:
                self.memory.add_message("user", user_query)
                self.memory.add_message("assistant", answer)
            
            print(f"\nâœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
            print(f"{'='*60}\n")
            
            return {
                "answer": answer,
                "documents": docs,
                "metadata": {
                    "queries": queries,
                    "num_docs_retrieved": len(docs),
                    "has_context": bool(self.memory and self.memory.messages)
                }
            }
            
        except Exception as e:
            print(f"âŒ Answer Generation Error: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "documents": [],
                "metadata": {"error": str(e)}
            }
    
    def update_user_profile(self, **kwargs):
        """ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""
        if self.memory:
            self.memory.update_profile(**kwargs)
            print(f"ğŸ‘¤ í”„ë¡œí•„ ì—…ë°ì´íŠ¸: {kwargs}")
    
    def clear_memory(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        if self.memory:
            self.memory.clear()
            print("ğŸ—‘ï¸ ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")


# ============================================================================
# 8. ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

def main():
    """ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        raise ValueError('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    
    # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        api_key=api_key
    )
    
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=api_key
    )
    
    # VectorDB ë¡œë“œ
    vectorstore = Chroma(
        collection_name="youth_policies",
        embedding_function=embeddings,
        persist_directory="./data/vectordb"
    )
    
    # ë¬¸ì„œ ë¡œë“œ (BM25, TF-IDFë¥¼ ìœ„í•´ í•„ìš”)
    # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    all_docs = vectorstore.get()
    documents = []
    if all_docs and 'documents' in all_docs:
        from langchain_core.documents import Document
        for i, doc_text in enumerate(all_docs['documents']):
            metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}
            documents.append(Document(page_content=doc_text, metadata=metadata))
    
    print(f"ğŸ“š ì´ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    
    # ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ ìƒì„±
    rag = AdvancedRAGPipeline(
        documents=documents,
        vectorstore=vectorstore,
        llm=llm,
        enable_router=True,
        enable_multi_query=True,
        enable_ensemble=True,
        enable_rrf=True,
        enable_self_reg=True,
        enable_memory=True,
        bm25_k=5,
        tfidf_k=5,
        vector_k=5,
        bm25_weight=0.3,
        tfidf_weight=0.3,
        vector_weight=0.4
    )
    
    # ì‚¬ìš©ì í”„ë¡œí•„ ì„¤ì •
    rag.update_user_profile(
        age=25,
        region="ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬",
    )
    
    # í…ŒìŠ¤íŠ¸ ì§ˆì˜
    queries = [
        "ë°•ëŒíšŒ ì •ë„ ì•Œë ¤ì¤˜",
        "ë‹¤ë¥¸ ë°•ëŒíšŒë„ ë” ì•Œë ¤ì¤˜"
    ]
    
    for query in queries:
        result = rag.query(query)
        print(f"\nì§ˆë¬¸: {query}")
        print(f"ë‹µë³€: {result['answer']}")
        print(f"ë¬¸ì„œ ìˆ˜: {result['metadata'].get('num_docs_retrieved', 0)}")
        print("-" * 60)


if __name__ == "__main__":
    main()
