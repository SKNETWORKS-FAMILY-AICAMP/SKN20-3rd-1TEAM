"""
ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
- Multi-Query Generator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±
- Ensemble Retriever: Dense + BM25
- RRF (Reciprocal Rank Fusion): ê²€ìƒ‰ ê²°ê³¼ í†µí•©
- Memory Store: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
"""

import os
import logging
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
import json
import warnings

# TensorFlow ë¡œê·¸ ì–µì œ (dotenv ë¡œë“œ ì „ì— ì„¤ì •)
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.documents import Document

# BM25, Ensemble Retriever
try:
    # LangChain deprecation ê²½ê³  ë¬´ì‹œ
    with warnings.catch_warnings():
        warnings.filterwarnings('ignore', category=DeprecationWarning)
        from langchain_classic.retrievers import BM25Retriever, EnsembleRetriever
    RETRIEVERS_AVAILABLE = True
except ImportError:
    RETRIEVERS_AVAILABLE = False
    BM25Retriever = None
    EnsembleRetriever = None

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger('advanced_rag')

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Retrievers ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
if not RETRIEVERS_AVAILABLE:
    print("âš ï¸ BM25 Retrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("âš ï¸ ì„¤ì¹˜: pip install langchain-community")



# ============================================================================
# 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
# ============================================================================

class QueryRouter:
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.router_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°ì…ë‹ˆë‹¤.

ì‘ì—…:
1. ì§ˆë¬¸ì´ ì˜ë¯¸ ìˆëŠ”ì§€ ê²€ì¦ (ì¸ì‚¬ë§, ìš•ì„¤, ë¬´ì˜ë¯¸í•œ ì…ë ¥ ì œì™¸)
2. ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì •ì±…ê²€ìƒ‰, ì¶”ì²œ, ì¼ë°˜ì§ˆë¬¸ ë“±)
3. LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì •ì œ

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "is_valid": true/false,
    "category": "ì •ì±…ê²€ìƒ‰|ì •ì±…ì¶”ì²œ|ì¼ë°˜ì§ˆë¬¸|ê¸°íƒ€",
    "refined_query": "ì •ì œëœ ì§ˆë¬¸",
    "reason": "íŒë‹¨ ì´ìœ "
}}"""),
            ("user", "{query}")
        ])
    
    def route(self, query: str) -> Dict:
        """ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œ"""
        try:
            response = self.router_prompt | self.llm | StrOutputParser()
            result_str = response.invoke({"query": query})
            
            # JSON íŒŒì‹±
            result = json.loads(result_str)
            print(f"ğŸ”€ Router: {result['category']} | Valid: {result['is_valid']}")
            
            return result
        except Exception as e:
            print(f"âŒ Router Error: {e}")
            return {
                "is_valid": True,
                "category": "ì¼ë°˜ì§ˆë¬¸",
                "refined_query": query,
                "reason": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë³¸ ì‚¬ìš©"
            }


# ============================================================================
# 2. Multi-Query Generator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±
# ============================================================================

class MultiQueryGenerator:
    """í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.user_region = None  # ì‚¬ìš©ì ì§€ì—­ ì •ë³´
        
        self.multi_query_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë‹¤ì–‘í•œ ê´€ì ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ ê´€ì ì—ì„œ ì¬êµ¬ì„±í•˜ì„¸ìš”:
1. í‚¤ì›Œë“œ ì¤‘ì‹¬ ì¿¼ë¦¬
2. ì˜ë¯¸ ì¤‘ì‹¬ ì¿¼ë¦¬
3. ë§¥ë½ ì¤‘ì‹¬ ì¿¼ë¦¬

{region_instruction}

ê° ì¿¼ë¦¬ëŠ” í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ ì—†ì´ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”."""),
            ("user", "{query}")
        ])
    
    def generate(self, query: str) -> List[str]:
        """ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±"""
        try:
            # ì§€ì—­ ì •ë³´ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            region_instruction = ""
            if self.user_region:
                region_instruction = f"ì‚¬ìš©ìì˜ ì§€ì—­ì€ '{self.user_region}'ì…ë‹ˆë‹¤. ê°€ëŠ¥í•˜ë©´ ì§€ì—­ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ì„¸ìš”."
            
            response = self.multi_query_prompt | self.llm | StrOutputParser()
            result = response.invoke({
                "query": query,
                "region_instruction": region_instruction
            })
            
            # ì¿¼ë¦¬ ë¶„ë¦¬ (ì¤„ë°”ê¿ˆ ê¸°ì¤€)
            queries = [q.strip() for q in result.split('\n') if q.strip()]
            # ì›ë³¸ ì¿¼ë¦¬ í¬í•¨
            all_queries = [query] + queries
            
            print(f"ğŸ” Multi-Query ìƒì„±: {len(all_queries)}ê°œ")
            for i, q in enumerate(all_queries, 1):
                print(f"  {i}. {q}")
            
            return all_queries
        except Exception as e:
            print(f"âŒ Multi-Query Error: {e}")
            return [query]


# ============================================================================
# 3. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ
# ============================================================================

class EnsembleRetriever:
    """Dense, BM25 ê²€ìƒ‰ì„ ê²°í•©í•œ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„"""
    
    def __init__(
        self, 
        documents: List[any],
        vectorstore: Chroma,
        bm25_k: int = 5,
        vector_k: int = 10,
        bm25_weight: float = 0.4,
        vector_weight: float = 0.6
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        
        # íŒŒë¼ë¯¸í„° ì €ì¥
        self.bm25_k = bm25_k
        self.vector_k = vector_k
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        
        # ì‚¬ìš©ì ì •ë³´ ì´ˆê¸°í™”
        self.user_age = None
        self.user_region = None
        
        # ê° ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
        self._build_bm25()
        self._build_vector()
    
    def _build_bm25(self):
        """BM25 Retriever ìƒì„±"""
        if not RETRIEVERS_AVAILABLE or BM25Retriever is None:
            print("âš ï¸ BM25Retrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.bm25_retriever = None
            return
        
        try:
            self.bm25_retriever = BM25Retriever.from_documents(self.documents)
            self.bm25_retriever.k = self.bm25_k
            print(f"âœ… BM25 Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.bm25_k})")
        except Exception as e:
            print(f"âŒ BM25 Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.bm25_retriever = None
    
    def _build_vector(self):
        """Vector Retriever ìƒì„±"""
        try:
            # VectorStore ìƒíƒœ í™•ì¸
            test_search = self.vectorstore.similarity_search("í…ŒìŠ¤íŠ¸", k=1)
            print(f"ğŸ§ª VectorStore í…ŒìŠ¤íŠ¸ ê²€ìƒ‰: {len(test_search)}ê°œ ë¬¸ì„œ")
            
            self.vector_retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": self.vector_k}
            )
            print(f"âœ… Vector Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.vector_k})")
        except Exception as e:
            print(f"âŒ Vector Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.vector_retriever = None
    
    def filter_by_user_info(self, documents):
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì •ë³´(ë‚˜ì´, ì§€ì—­)ë¡œ í•„í„°ë§
        
        Args:
            documents: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            list: í•„í„°ë§ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        # ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìœ¼ë©´ í•„í„°ë§ ì—†ì´ ë°˜í™˜
        if not (self.user_age or self.user_region):
            return documents
        
        filtered = []
        
        for doc in documents:
            metadata = doc.metadata
            
            # 1. ë‚˜ì´ í•„í„°ë§
            age_match = True
            if self.user_age:
                try:
                    min_age = int(metadata.get('ì§€ì›ìµœì†Œì—°ë ¹', '0') or '0')
                    max_age = int(metadata.get('ì§€ì›ìµœëŒ€ì—°ë ¹', '0') or '0')
                    
                    if min_age > 0 and self.user_age < min_age:
                        age_match = False
                    if max_age > 0 and max_age < 999 and self.user_age > max_age:
                        age_match = False
                except:
                    pass
            
            # 2. ì§€ì—­ í•„í„°ë§ (ë“œë¡­ë‹¤ìš´ í˜•ì‹ ë§¤ì¹­)
            region_match = True
            if self.user_region:
                policy_region = metadata.get('ì§€ì—­', '')  # ì‹¤ì œ ì •ì±… ì ìš© ì§€ì—­
                
                # ì§€ì—­ í•„ë“œê°€ ìˆìœ¼ë©´ í™•ì¸, ì—†ìœ¼ë©´ ì „êµ­ ë‹¨ìœ„ ì •ì±…ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ í¬í•¨
                if policy_region:
                    region_match = False
                    
                    # ì •ì±… ì§€ì—­ì„ ì‰¼í‘œë¡œ ë¶„ë¦¬ (ê° ì§€ì—­ì´ ê°œë³„ í•­ëª©)
                    policy_regions = [r.strip() for r in policy_region.split(',')]
                    
                    # ì‚¬ìš©ì ì§€ì—­ íŒŒì‹±: "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë™êµ¬" â†’ "ì„œìš¸íŠ¹ë³„ì‹œ", "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë™êµ¬"
                    user_sido = self.user_region.split()[0] if ' ' in self.user_region else self.user_region
                    
                    # ê° ì •ì±… ì§€ì—­ê³¼ ë¹„êµ
                    for pr in policy_regions:
                        # ì •í™•íˆ ì¼ì¹˜: "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë™êµ¬" == "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë™êµ¬"
                        # ë˜ëŠ” ì‹œ/ë„ ë§¤ì¹­: "ì„œìš¸íŠ¹ë³„ì‹œ" == "ì„œìš¸íŠ¹ë³„ì‹œ"
                        if self.user_region == pr or user_sido == pr:
                            region_match = True
                            break
                # else: ì§€ì—­ í•„ë“œ ì—†ìŒ = ì „êµ­ ë‹¨ìœ„ ì •ì±… (region_match = True ìœ ì§€)
            
            # ë‘ ì¡°ê±´ ëª¨ë‘ ë§Œì¡±í•˜ë©´ í¬í•¨
            if age_match and region_match:
                filtered.append(doc)
        
        print(f"ğŸ“Š í•„í„°ë§: {len(documents)}ê°œ â†’ {len(filtered)}ê°œ")
        return filtered
    
    def _enhance_query(self, query):
        """
        ì‚¬ìš©ì ì •ë³´ë¥¼ í™œìš©í•´ ê²€ìƒ‰ ì¿¼ë¦¬ ì¦ê°•
        
        Args:
            query: ì›ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            str: ì¦ê°•ëœ ê²€ìƒ‰ ì¿¼ë¦¬
        """
        enhanced = query
        
        # ì§€ì—­ ì •ë³´ ì¶”ê°€ (ì „ì²´ ì§€ì—­ëª… ì‚¬ìš©)
        if self.user_region:
            # ì¿¼ë¦¬ì— ì§€ì—­ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì „ì²´ ì§€ì—­ëª… ì¶”ê°€
            # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë™êµ¬" ì „ì²´ë¥¼ ì¶”ê°€
            if self.user_region not in query:
                enhanced = f"{query} {self.user_region}"
        
        if enhanced != query:
            print(f"ğŸ” ì¿¼ë¦¬ ì¦ê°•: '{query}' â†’ '{enhanced}'")
        
        return enhanced
    
    def dense_search(self, query: str) -> List[Tuple[any, float]]:
        """Dense ê²€ìƒ‰ (ì„ë² ë”© ê¸°ë°˜)"""
        try:
            if self.vector_retriever:
                docs = self.vector_retriever.invoke(query)
                # ìŠ¤ì½”ì–´ì™€ í•¨ê»˜ ë°˜í™˜ (ìŠ¤ì½”ì–´ëŠ” 1.0ìœ¼ë¡œ ê°€ì •)
                results = [(doc, 1.0) for doc in docs]
                print(f"  ğŸ“Š Dense: {len(results)}ê°œ ë¬¸ì„œ")
                return results
            return []
        except Exception as e:
            print(f"âŒ Dense Search Error: {e}")
            return []
    
    def bm25_search(self, query: str) -> List[Tuple[any, float]]:
        """BM25 ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            if self.bm25_retriever:
                docs = self.bm25_retriever.invoke(query)
                results = [(doc, 1.0) for doc in docs]
                print(f"  ğŸ“Š BM25: {len(results)}ê°œ ë¬¸ì„œ")
                return results
            return []
        except Exception as e:
            print(f"âŒ BM25 Search Error: {e}")
            return []
    
    def retrieve(self, queries: List[str]) -> Dict[str, List[Tuple[any, float]]]:
        """ëª¨ë“  ê²€ìƒ‰ ì „ëµ ì‹¤í–‰"""
        all_results = {
            'dense': [],
            'bm25': []
        }
        
        for query in queries:
            # ì¿¼ë¦¬ ì¦ê°• ì œê±° - MultiQueryGeneratorì—ì„œ ì´ë¯¸ ì§€ì—­ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ìƒì„±
            # enhanced_query = self._enhance_query(query)
            enhanced_query = query
            
            print(f"ğŸ” ê²€ìƒ‰ ì¤‘: {enhanced_query}")
            all_results['dense'].extend(self.dense_search(enhanced_query))
            all_results['bm25'].extend(self.bm25_search(enhanced_query))
        
        return all_results
    
    def get_ensemble(self, query: str) -> List[any]:
        """Ensemble ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìš©)"""
        if not RETRIEVERS_AVAILABLE or EnsembleRetriever is None:
            print("âš ï¸ EnsembleRetrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self.dense_search(query)
        
        try:
            retrievers = []
            weights = []
            
            if self.bm25_retriever:
                retrievers.append(self.bm25_retriever)
                weights.append(self.bm25_weight)
            
            if self.vector_retriever:
                retrievers.append(self.vector_retriever)
                weights.append(self.vector_weight)
            
            if not retrievers:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ retrieverê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            total_weight = sum(weights)
            weights = [w / total_weight for w in weights]
            
            # LangChainì˜ EnsembleRetriever ì‚¬ìš©
            ensemble = EnsembleRetriever(
                retrievers=retrievers,
                weights=weights
            )
            
            docs = ensemble.invoke(query)
            print(f"ğŸ”— Ensemble: {len(docs)}ê°œ ë¬¸ì„œ")
            return docs
            
        except Exception as e:
            print(f"âŒ Ensemble Search Error: {e}")
            return []


# ============================================================================
# 4. RRF (Reciprocal Rank Fusion): ê²€ìƒ‰ ê²°ê³¼ í†µí•©
# ============================================================================

class ReciprocalRankFusion:
    """ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë­í‚¹ ê¸°ë°˜ìœ¼ë¡œ í†µí•©"""
    
    def __init__(self, k: int = 60):
        self.k = k  # RRF ìƒìˆ˜
    
    def fuse(self, results_dict: Dict[str, List[Tuple[any, float]]], top_k: int = 10) -> List[any]:
        """RRFë¡œ ê²°ê³¼ í†µí•©"""
        doc_scores = {}
        
        for method, results in results_dict.items():
            for rank, (doc, score) in enumerate(results, 1):
                doc_id = doc.metadata.get('policy_id', id(doc))
                
                # RRF ì ìˆ˜ ê³„ì‚°: 1 / (k + rank)
                rrf_score = 1.0 / (self.k + rank)
                
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {'doc': doc, 'score': 0}
                doc_scores[doc_id]['score'] += rrf_score
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1]['score'], reverse=True)
        final_docs = [item[1]['doc'] for item in sorted_docs[:top_k]]
        
        print(f"ğŸ”— RRF: {len(doc_scores)}ê°œ ë¬¸ì„œ â†’ {len(final_docs)}ê°œ ì„ íƒ")
        return final_docs


# ============================================================================
# 5. Memory Store: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
# ============================================================================

@dataclass
class ConversationMemory:
    """ëŒ€í™” ê¸°ë¡ ê´€ë¦¬"""
    messages: List[Dict] = field(default_factory=list)
    user_profile: Dict = field(default_factory=dict)
    max_history: int = 10
    
    def add_message(self, role: str, content: str):
        """ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
        
        # ìµœëŒ€ ê¸°ë¡ ìˆ˜ ì œí•œ
        if len(self.messages) > self.max_history * 2:
            self.messages = self.messages[-self.max_history * 2:]
    
    def update_profile(self, **kwargs):
        """ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""
        self.user_profile.update(kwargs)
    
    def get_context(self) -> str:
        """ëŒ€í™” ë§¥ë½ ë¬¸ìì—´ ìƒì„±"""
        if not self.messages:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        context_parts = []
        for msg in self.messages[-6:]:  # ìµœê·¼ 3í„´
            role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
            context_parts.append(f"{role}: {msg['content']}")
        
        return "\n".join(context_parts)
    
    def clear(self):
        """ê¸°ë¡ ì´ˆê¸°í™”"""
        self.messages.clear()
        self.user_profile.clear()


# ============================================================================
# 7. Advanced RAG Pipeline: ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©
# ============================================================================

class AdvancedRAGPipeline:
    """ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        documents: List[any],
        vectorstore: Chroma,
        llm: ChatOpenAI,
        enable_router: bool = True,
        enable_multi_query: bool = True,
        enable_ensemble: bool = True,
        enable_rrf: bool = True,
        enable_memory: bool = True,
        bm25_k: int = 5,
        vector_k: int = 10,
        bm25_weight: float = 0.4,
        vector_weight: float = 0.6
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        self.llm = llm
        
        # ê° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.router = QueryRouter(llm) if enable_router else None
        self.multi_query = MultiQueryGenerator(llm) if enable_multi_query else None
        self.ensemble = EnsembleRetriever(
            documents=documents,
            vectorstore=vectorstore,
            bm25_k=bm25_k,
            vector_k=vector_k,
            bm25_weight=bm25_weight,
            vector_weight=vector_weight
        ) if enable_ensemble else None
        self.rrf = ReciprocalRankFusion() if enable_rrf else None
        self.memory = ConversationMemory() if enable_memory else None
        
        # ìµœì¢… ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸
        self.answer_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì²­ë…„ ì •ì±… ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

ê²€ìƒ‰ëœ ì •ì±… ì •ë³´ì™€ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ë‹µë³€ ì›ì¹™:
1. ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
2. ì •ì±…ëª…, ì‹ ì²­ ê¸°ê°„, ì§€ì› ë‚´ìš© ë“± êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
3. ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€
4. ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì†”ì§í•˜ê²Œ ë§í•˜ê¸°
5. **ì œê³µëœ ëª¨ë“  ì •ì±…ì„ ê°€ëŠ¥í•œ í¬í•¨í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”** (ìµœì†Œ 3ê°œ ì´ìƒ)"""),
            ("user", """[ëŒ€í™” ë§¥ë½]
{context}

[ì‚¬ìš©ì í”„ë¡œí•„]
{profile}

[ê²€ìƒ‰ëœ ì •ì±… ì •ë³´]
{documents}

[í˜„ì¬ ì§ˆë¬¸]
{query}""")
        ])
    
    def query(self, user_query: str) -> Dict:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print(f"ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")
        print(f"{'='*60}")
        
        # 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
        if self.router:
            route_result = self.router.route(user_query)
            if not route_result['is_valid']:
                return {
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    "documents": [],
                    "metadata": route_result
                }
            query = route_result['refined_query']
        else:
            query = user_query
        
        # 2. Multi-Query: ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±
        if self.multi_query:
            queries = self.multi_query.generate(query)
        else:
            queries = [query]
        
        # 3. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰
        if self.ensemble:
            search_results = self.ensemble.retrieve(queries)
        else:
            search_results = {'dense': self.vectorstore.similarity_search_with_score(query, k=5)}
        
        # 4. RRF: ê²€ìƒ‰ ê²°ê³¼ í†µí•© (top_k ì¦ê°€)
        if self.rrf:
            docs = self.rrf.fuse(search_results, top_k=20)
        else:
            docs = [doc for doc, score in search_results['dense']]
        
        # 5. ì‚¬ìš©ì ì •ë³´ í•„í„°ë§ (ë‚˜ì´, ì§€ì—­)
        if self.ensemble and (self.ensemble.user_age or self.ensemble.user_region):
            docs = self.ensemble.filter_by_user_info(docs)
        
        # 6. Memory: ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
        if self.memory:
            context = self.memory.get_context()
            profile = json.dumps(self.memory.user_profile, ensure_ascii=False)
        else:
            context = "ì´ì „ ëŒ€í™” ì—†ìŒ"
            profile = "{}"
        
        # 7. LLM: ìµœì¢… ë‹µë³€ ìƒì„±
        docs_text = "\n\n".join([
            f"[ì •ì±… {i+1}] {doc.metadata.get('policy_name', 'ì œëª© ì—†ìŒ')}\n{doc.page_content[:500]}"
            for i, doc in enumerate(docs[:10])
        ])
        
        try:
            response = self.answer_prompt | self.llm | StrOutputParser()
            answer = response.invoke({
                "context": context,
                "profile": profile,
                "documents": docs_text,
                "query": user_query
            })
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            if self.memory:
                self.memory.add_message("user", user_query)
                self.memory.add_message("assistant", answer)
            
            print(f"\nâœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
            print(f"{'='*60}\n")
            
            return {
                "answer": answer,
                "documents": docs,
                "metadata": {
                    "queries": queries,
                    "num_docs_retrieved": len(docs),
                    "has_context": bool(self.memory and self.memory.messages)
                }
            }
            
        except Exception as e:
            print(f"âŒ Answer Generation Error: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "documents": [],
                "metadata": {"error": str(e)}
            }
    
    def update_user_profile(self, **kwargs):
        """ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""
        if self.memory:
            self.memory.update_profile(**kwargs)
            print(f"ğŸ‘¤ í”„ë¡œí•„ ì—…ë°ì´íŠ¸: {kwargs}")
        
        # Ensemble Retrieverì—ë„ ì‚¬ìš©ì ì •ë³´ ì„¤ì •
        if self.ensemble:
            age = kwargs.get('age')
            region = kwargs.get('region')
            
            if age is not None:
                self.ensemble.user_age = age
            if region is not None:
                self.ensemble.user_region = region
        
        # MultiQueryGeneratorì—ë„ ì§€ì—­ ì •ë³´ ì„¤ì •
        if self.multi_query:
            region = kwargs.get('region')
            if region is not None:
                self.multi_query.user_region = region
    
    def clear_memory(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        if self.memory:
            self.memory.clear()
            print("ğŸ—‘ï¸ ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")


# ============================================================================
# 8. ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

def main():
    """ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        raise ValueError('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    
    # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        api_key=api_key
    )
    
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=api_key
    )
    
    # VectorDB ë¡œë“œ (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
    vectordb_path = os.path.abspath("../data/vectordb")
    print(f"ğŸ“‚ VectorDB ê²½ë¡œ: {vectordb_path}")
    print(f"ğŸ“‚ ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(vectordb_path)}")
    
    vectorstore = Chroma(
        collection_name="youth_policies",
        embedding_function=embeddings,
        persist_directory=vectordb_path
    )
    
    # ë¬¸ì„œ ë¡œë“œ (BM25, TF-IDFë¥¼ ìœ„í•´ í•„ìš”)
    # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    all_docs = vectorstore.get()
    print(f"ğŸ“Š ChromaDB ë¡œë“œ ê²°ê³¼: {len(all_docs.get('documents', []))}ê°œ ë¬¸ì„œ")
    
    documents = []
    if all_docs and 'documents' in all_docs:
        from langchain_core.documents import Document
        for i, doc_text in enumerate(all_docs['documents']):
            metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}
            documents.append(Document(page_content=doc_text, metadata=metadata))
    
    print(f"ğŸ“š ì´ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    
    # ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ ìƒì„±
    rag = AdvancedRAGPipeline(
        documents=documents,
        vectorstore=vectorstore,
        llm=llm,
        enable_router=True,
        enable_multi_query=True,
        enable_ensemble=True,
        enable_rrf=True,
        enable_memory=True,
        bm25_k=5,
        vector_k=10,
        bm25_weight=0.4,
        vector_weight=0.6
    )
    
    # ì‚¬ìš©ì í”„ë¡œí•„ ì„¤ì •
    rag.update_user_profile(
        age=25,
        region="ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬",
    )
    
    # í…ŒìŠ¤íŠ¸ ì§ˆì˜
    queries = [
        "ì›”ì„¸ ì§€ì›",
    ]
    
    for query in queries:
        result = rag.query(query)
        print(f"\nì§ˆë¬¸: {query}")
        print(f"ë‹µë³€: {result['answer']}")
        print(f"ë¬¸ì„œ ìˆ˜: {result['metadata'].get('num_docs_retrieved', 0)}")
        print("-" * 60)


if __name__ == "__main__":
    main()
