{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d4022d",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1435cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# TensorFlow ë¡œê·¸ ì–µì œ\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# BM25, Ensemble Retriever\n",
    "try:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "        from langchain_classic.retrievers import BM25Retriever, EnsembleRetriever\n",
    "    RETRIEVERS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    RETRIEVERS_AVAILABLE = False\n",
    "    BM25Retriever = None\n",
    "    EnsembleRetriever = None\n",
    "\n",
    "# SelfQueryRetriever\n",
    "try:\n",
    "    from langchain_classic.retrievers.self_query.base import SelfQueryRetriever\n",
    "    from langchain_classic.chains.query_constructor.schema import AttributeInfo\n",
    "    SELF_QUERY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SELF_QUERY_AVAILABLE = False\n",
    "    SelfQueryRetriever = None\n",
    "    AttributeInfo = None\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# Retrievers ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "if not RETRIEVERS_AVAILABLE:\n",
    "    print(\"âš ï¸ BM25 Retrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"âš ï¸ ì„¤ì¹˜: pip install langchain-community\")\n",
    "\n",
    "if not SELF_QUERY_AVAILABLE:\n",
    "    print(\"âš ï¸ SelfQueryRetrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"âš ï¸ ì„¤ì¹˜: pip install langchain-community\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb4d99",
   "metadata": {},
   "source": [
    "## 2. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8214bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryRouter:\n",
    "    \"\"\"ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "        self.router_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°ì…ë‹ˆë‹¤.\n",
    "\n",
    "            ì‘ì—…:\n",
    "            1. ì§ˆë¬¸ì´ ì˜ë¯¸ ìˆëŠ”ì§€ ê²€ì¦ (ì¸ì‚¬ë§, ìš•ì„¤, ë¬´ì˜ë¯¸í•œ ì…ë ¥ ì œì™¸)\n",
    "            2. ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì •ì±…ê²€ìƒ‰, ì¶”ì²œ, ì¼ë°˜ì§ˆë¬¸ ë“±)\n",
    "            3. LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì •ì œ\n",
    "            4. ì§€ì—­ì´ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ë‹¤ì‹œ ì…ë ¥í•˜ë„ë¡ ìœ ë„\n",
    "            \n",
    "            ì‘ë‹µ í˜•ì‹ (JSON):\n",
    "            {{\n",
    "                \"is_valid\": true/false,\n",
    "                \"category\": \"ì •ì±…ê²€ìƒ‰|ì •ì±…ì¶”ì²œ|ì¼ë°˜ì§ˆë¬¸|ê¸°íƒ€\",\n",
    "                \"refined_query\": \"ì •ì œëœ ì§ˆë¬¸\",\n",
    "                \"reason\": \"íŒë‹¨ ì´ìœ \"\n",
    "            }}\"\"\"),\n",
    "            (\"user\", \"{query}\")\n",
    "        ])\n",
    "    \n",
    "    def route(self, query: str) -> Dict:\n",
    "        \"\"\"ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œ\"\"\"\n",
    "        try:\n",
    "            response = self.router_prompt | self.llm | StrOutputParser()\n",
    "            result_str = response.invoke({\"query\": query})\n",
    "            \n",
    "            # JSON íŒŒì‹±\n",
    "            result = json.loads(result_str)\n",
    "            print(f\"ğŸ”€ Router: {result['category']} | Valid: {result['is_valid']}\")\n",
    "            \n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Router Error: {e}\")\n",
    "            return {\n",
    "                \"is_valid\": True,\n",
    "                \"category\": \"ì¼ë°˜ì§ˆë¬¸\",\n",
    "                \"refined_query\": query,\n",
    "                \"reason\": \"íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë³¸ ì‚¬ìš©\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7fc14",
   "metadata": {},
   "source": [
    "## 1.5. ì§€ì—­ í•„í„°ë§ ìœ í‹¸ë¦¬í‹°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab6e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionFilter:\n",
    "    \"\"\"ì§€ì—­ ê¸°ë°˜ í•„í„°ë§ì„ ìˆ˜í–‰í•˜ëŠ” ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "        self.region_detection_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì§€ì—­ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‘ì—…:\n",
    "1. ì§ˆë¬¸ì—ì„œ ì§€ì—­ëª…(ì‹œ/ë„, ì‹œ/êµ°/êµ¬)ì„ ì¶”ì¶œ\n",
    "2. 'ì „ì²´', 'ì „êµ­', 'ëª¨ë“ ', 'ëª¨ë‘' ë“±ì˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ 'ì „êµ­'ìœ¼ë¡œ ë¶„ë¥˜\n",
    "3. ì§€ì—­ëª…ì´ ì—†ìœ¼ë©´ None ë°˜í™˜\n",
    "\n",
    "ì‘ë‹µ í˜•ì‹ (JSON):\n",
    "{{\n",
    "    \"has_region\": true/false,\n",
    "    \"is_national\": true/false,\n",
    "    \"region_name\": \"ì§€ì—­ëª… ë˜ëŠ” null\",\n",
    "    \"reason\": \"íŒë‹¨ ì´ìœ \"\n",
    "}}\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "- \"ëŒ€êµ¬ ì›”ì„¸ ì§€ì›\" -> {{\"has_region\": true, \"is_national\": false, \"region_name\": \"ëŒ€êµ¬\", \"reason\": \"ëŒ€êµ¬ ì§€ì—­ ëª…ì‹œ\"}}\n",
    "- \"ì „êµ­ ì²­ë…„ ì •ì±…\" -> {{\"has_region\": true, \"is_national\": true, \"region_name\": null, \"reason\": \"ì „êµ­ í‚¤ì›Œë“œ ì‚¬ìš©\"}}\n",
    "- \"ì›”ì„¸ ì§€ì›\" -> {{\"has_region\": false, \"is_national\": false, \"region_name\": null, \"reason\": \"ì§€ì—­ ì •ë³´ ì—†ìŒ\"}}\n",
    "\"\"\"),\n",
    "            (\"user\", \"{query}\")\n",
    "        ])\n",
    "    \n",
    "    def detect_region(self, query: str) -> Dict:\n",
    "        \"\"\"ì§ˆë¬¸ì—ì„œ ì§€ì—­ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        try:\n",
    "            response = self.region_detection_prompt | self.llm | StrOutputParser()\n",
    "            result_str = response.invoke({\"query\": query})\n",
    "            \n",
    "            # JSON íŒŒì‹±\n",
    "            result = json.loads(result_str)\n",
    "            print(f\"ğŸŒ ì§€ì—­ íƒì§€: {result.get('region_name', 'ì—†ìŒ')} | ì „êµ­: {result.get('is_national', False)}\")\n",
    "            \n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Region Detection Error: {e}\")\n",
    "            return {\n",
    "                \"has_region\": False,\n",
    "                \"is_national\": False,\n",
    "                \"region_name\": None,\n",
    "                \"reason\": \"íŒŒì‹± ì‹¤íŒ¨\"\n",
    "            }\n",
    "    \n",
    "    def build_filter(self, region_info: Dict) -> Optional[Dict]:\n",
    "        \"\"\"ì§€ì—­ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° í•„í„° ìƒì„±\"\"\"\n",
    "        if region_info.get('is_national', False):\n",
    "            # ì „êµ­ ì •ì±…ë§Œ í•„í„°ë§\n",
    "            return {\"ì§€ì—­ë²”ìœ„\": \"ì „êµ­\"}\n",
    "        elif region_info.get('has_region', False) and region_info.get('region_name'):\n",
    "            # íŠ¹ì • ì§€ì—­ì´ í¬í•¨ëœ ì •ì±… í•„í„°ë§ (ChromaDBëŠ” $or ë¯¸ì§€ì›, Pythonì—ì„œ í›„ì²˜ë¦¬)\n",
    "            # ChromaDB í•„í„°ë¡œëŠ” ìš°ì„  ëª¨ë“  ì •ì±…ì„ ê°€ì ¸ì˜¤ê³ , í›„ì²˜ë¦¬ì—ì„œ í•„í„°ë§\n",
    "            return None  # í•„í„° ì—†ì´ ê²€ìƒ‰ í›„ Pythonì—ì„œ í•„í„°ë§\n",
    "        else:\n",
    "            # í•„í„° ì—†ìŒ (ëª¨ë“  ì •ì±… ê²€ìƒ‰)\n",
    "            return None\n",
    "    \n",
    "    def filter_documents(self, documents: List, region_info: Dict) -> List:\n",
    "        \"\"\"ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì§€ì—­ ì •ë³´ë¡œ í›„ì²˜ë¦¬ í•„í„°ë§\"\"\"\n",
    "        if not region_info.get('has_region', False) or region_info.get('is_national', False):\n",
    "            return documents\n",
    "        \n",
    "        region_name = region_info.get('region_name')\n",
    "        if not region_name:\n",
    "            return documents\n",
    "        \n",
    "        filtered_docs = []\n",
    "        for doc in documents:\n",
    "            # ì „êµ­ ì •ì±…ì€ í•­ìƒ í¬í•¨\n",
    "            if doc.metadata.get('ì§€ì—­ë²”ìœ„') == 'ì „êµ­':\n",
    "                filtered_docs.append(doc)\n",
    "            # ì§€ì—­ í•„ë“œì— í•´ë‹¹ ì§€ì—­ëª…ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í¬í•¨\n",
    "            elif region_name in doc.metadata.get('ì§€ì—­', ''):\n",
    "                filtered_docs.append(doc)\n",
    "        \n",
    "        print(f\"ğŸ” ì§€ì—­ í•„í„°ë§: {len(documents)}ê°œ â†’ {len(filtered_docs)}ê°œ\")\n",
    "        return filtered_docs if filtered_docs else documents  # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41931ce",
   "metadata": {},
   "source": [
    "## 3. Multi-Query Generator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abb0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiQueryGenerator:\n",
    "    \"\"\"í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "        \n",
    "        self.multi_query_prompt = ChatPromptTemplate.from_messages([\n",
    "            \"system\", \"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸ì„ **ì˜ë„ì™€ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ìœ ì§€**í•œ ì±„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "            **ì›ë³¸ ì§ˆë¬¸ì˜ ë‚´ìš©ì´ë‚˜ ì¡°ê±´ì„ ì„ì˜ë¡œ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ê²€ìƒ‰ ê´€ì ë§Œ ë‹¤ì–‘í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "            ì£¼ì–´ì§„ ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ ê´€ì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”:\n",
    "\n",
    "            1.  **ì§€ì—­(Region) ì¶”ì¶œ ê°•ì œ: ì‚¬ìš©ìê°€ ì§€ì—­ì„ ì–¸ê¸‰í•˜ë©´, í•´ë‹¹ ì§€ì—­ì— ì§‘ì¤‘í•´\n",
    "            2.  **ì •ì±… í‚¤ì›Œë“œ(Policy Keyword): ì§ˆë¬¸ì˜ **í•µì‹¬ ì˜ë„**ì™€ ê´€ë ¨ëœ ì •ì±… í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ëœ ì •ì±…ë§Œ ë°˜í™˜í•  ê²ƒ.(ì›”ì„¸ -> ì›”ì„¸(ìœ ì˜ì–´ ì˜ˆ: ì„ëŒ€ë£Œ ë“± í¬í•¨) ê´€ë ¨ ì •ì±…ë§Œ ë°˜í™˜)\n",
    "            1.  **ì›ë³¸ ì¿¼ë¦¬ì˜ í•µì‹¬ í‚¤ì›Œë“œ**ë¥¼ ì‚´ë¦° ê°€ì¥ ì§ê´€ì ì¸ ì¿¼ë¦¬\n",
    "            2.  **ìœ ì‚¬í•œ ì˜ë¯¸ ë˜ëŠ” ê´€ë ¨ ì •ì±…ëª…**ì„ í¬í•¨í•˜ëŠ” ì¿¼ë¦¬ (ë™ì˜ì–´ í™œìš©)\n",
    "            3.  **ì§ˆë¬¸ì˜ ëª©ì **ì„ ëª…í™•íˆ ë“œëŸ¬ë‚´ëŠ” ë¬¸ì¥í˜• ì¿¼ë¦¬\n",
    "\n",
    "            ê° ì¿¼ë¦¬ëŠ” í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ ì—†ì´ ì¤„ë°”ê¿ˆ(\\n)ìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.\"\"\",\n",
    "            (\"user\", \"{query}\")\n",
    "        ])\n",
    "    \n",
    "    def generate(self, query: str) -> List[str]:\n",
    "        \"\"\"ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            response = self.multi_query_prompt | self.llm | StrOutputParser()\n",
    "            result = response.invoke({\"query\": query})\n",
    "            \n",
    "            # ì¿¼ë¦¬ ë¶„ë¦¬ (ì¤„ë°”ê¿ˆ ê¸°ì¤€)\n",
    "            queries = [q.strip() for q in result.split('\\n') if q.strip()]\n",
    "            # ì›ë³¸ ì¿¼ë¦¬ í¬í•¨\n",
    "            all_queries = [query] + queries\n",
    "            \n",
    "            print(f\"ğŸ” Multi-Query ìƒì„±: {len(all_queries)}ê°œ\")\n",
    "            for i, q in enumerate(all_queries, 1):\n",
    "                print(f\"  {i}. {q}\")\n",
    "            \n",
    "            return all_queries\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Multi-Query Error: {e}\")\n",
    "            return [query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf61aa6",
   "metadata": {},
   "source": [
    "## 4. Ensemble Retriever: Dense + BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bf6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleRetriever:\n",
    "    \"\"\"Dense, BM25 ê²€ìƒ‰ì„ ê²°í•©í•œ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        documents: List[any],\n",
    "        vectorstore: Chroma,\n",
    "        llm: ChatOpenAI = None,\n",
    "        bm25_k: int = 5,\n",
    "        vector_k: int = 10,\n",
    "        bm25_weight: float = 0.4,\n",
    "        vector_weight: float = 0.6\n",
    "    ):\n",
    "        self.documents = documents\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        \n",
    "        # íŒŒë¼ë¯¸í„° ì €ì¥\n",
    "        self.bm25_k = bm25_k\n",
    "        self.vector_k = vector_k\n",
    "        self.bm25_weight = bm25_weight\n",
    "        self.vector_weight = vector_weight\n",
    "        \n",
    "        # ê° ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”\n",
    "        self._build_bm25()\n",
    "        self._build_vector()\n",
    "        self._build_self_query()\n",
    "    \n",
    "    def _build_bm25(self):\n",
    "        \"\"\"BM25 Retriever ìƒì„±\"\"\"\n",
    "        if not RETRIEVERS_AVAILABLE or BM25Retriever is None:\n",
    "            print(\"âš ï¸ BM25Retrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            self.bm25_retriever = None\n",
    "            return\n",
    "        \n",
    "        if not self.documents:\n",
    "            print(\"âš ï¸ BM25: ë¬¸ì„œê°€ ì—†ì–´ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            self.bm25_retriever = None\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # BM25Retriever ì´ˆê¸°í™” (from_documents ì‚¬ìš©)\n",
    "            self.bm25_retriever = BM25Retriever.from_documents(\n",
    "                documents=self.documents,\n",
    "                k=self.bm25_k\n",
    "            )\n",
    "            print(f\"âœ… BM25 Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.bm25_k})\")\n",
    "        except TypeError as e:\n",
    "            # from_documentsê°€ ì‹¤íŒ¨í•˜ë©´ ì§ì ‘ ì´ˆê¸°í™” ì‹œë„\n",
    "            try:\n",
    "                self.bm25_retriever = BM25Retriever(docs=self.documents)\n",
    "                self.bm25_retriever.k = self.bm25_k\n",
    "                print(f\"âœ… BM25 Retriever ì´ˆê¸°í™” ì™„ë£Œ (ëŒ€ì²´ ë°©ì‹, k={self.bm25_k})\")\n",
    "            except Exception as e2:\n",
    "                print(f\"âŒ BM25 Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e2}\")\n",
    "                self.bm25_retriever = None\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ BM25 Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            self.bm25_retriever = None\n",
    "    \n",
    "    def _build_vector(self):\n",
    "        \"\"\"Vector Retriever ìƒì„±\"\"\"\n",
    "        try:\n",
    "            # VectorStore ìƒíƒœ í™•ì¸\n",
    "            test_search = self.vectorstore.similarity_search(\"í…ŒìŠ¤íŠ¸\", k=1)\n",
    "            print(f\"ğŸ§ª VectorStore í…ŒìŠ¤íŠ¸ ê²€ìƒ‰: {len(test_search)}ê°œ ë¬¸ì„œ\")\n",
    "            \n",
    "            self.vector_retriever = self.vectorstore.as_retriever(\n",
    "                search_type=\"similarity\",\n",
    "                search_kwargs={\"k\": self.vector_k}\n",
    "            )\n",
    "            print(f\"âœ… Vector Retriever ì´ˆê¸°í™” ì™„ë£Œ (k={self.vector_k})\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Vector Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            self.vector_retriever = None\n",
    "    \n",
    "    def _build_self_query(self):\n",
    "        \"\"\"SelfQuery Retriever ìƒì„±\"\"\"\n",
    "        if not SELF_QUERY_AVAILABLE or SelfQueryRetriever is None or not self.llm:\n",
    "            print(\"âš ï¸ SelfQueryRetrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            self.self_query_retriever = None\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ì˜\n",
    "            metadata_field_info = [\n",
    "                AttributeInfo(\n",
    "                    name=\"ì§€ì—­ë²”ìœ„\",\n",
    "                    description=\"ì •ì±…ì˜ ì§€ì—­ ì ìš© ë²”ìœ„ (national=ì „êµ­, local=ì§€ì—­)\",\n",
    "                    type=\"string\"\n",
    "                ),\n",
    "                AttributeInfo(\n",
    "                    name=\"ì§€ì—­\",\n",
    "                    description=\"ì •ì±…ì´ ì ìš©ë˜ëŠ” ìƒì„¸ ì§€ì—­ ëª©ë¡\",\n",
    "                    type=\"string\"\n",
    "                ),\n",
    "                AttributeInfo(\n",
    "                    name=\"ëŒ€ë¶„ë¥˜\",\n",
    "                    description=\"ì •ì±…ì˜ ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬\",\n",
    "                    type=\"string\"\n",
    "                ),\n",
    "                AttributeInfo(\n",
    "                    name=\"ì¤‘ë¶„ë¥˜\",\n",
    "                    description=\"ì •ì±…ì˜ ì¤‘ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬\",\n",
    "                    type=\"string\"\n",
    "                ),\n",
    "            ]\n",
    "            \n",
    "            document_description = \"ì²­ë…„ ì •ì±… ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°\"\n",
    "            \n",
    "            self.self_query_retriever = SelfQueryRetriever.from_llm(\n",
    "                llm=self.llm,\n",
    "                vectorstore=self.vectorstore,\n",
    "                document_contents=document_description,\n",
    "                metadata_field_info=metadata_field_info,\n",
    "                verbose=True\n",
    "            )\n",
    "            print(\"âœ… SelfQueryRetriever ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ SelfQueryRetriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            self.self_query_retriever = None\n",
    "    \n",
    "    def dense_search(self, query: str, metadata_filter: Dict = None) -> List[Tuple[any, float]]:\n",
    "        \"\"\"Dense ê²€ìƒ‰ (ì„ë² ë”© ê¸°ë°˜)\"\"\"\n",
    "        try:\n",
    "            if self.vector_retriever:\n",
    "                if metadata_filter:\n",
    "                    # ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©\n",
    "                    docs = self.vectorstore.similarity_search(\n",
    "                        query, \n",
    "                        k=self.vector_k,\n",
    "                        filter=metadata_filter\n",
    "                    )\n",
    "                else:\n",
    "                    docs = self.vector_retriever.invoke(query)\n",
    "                \n",
    "                results = [(doc, 1.0) for doc in docs]\n",
    "                print(f\"  ğŸ“Š Dense: {len(results)}ê°œ ë¬¸ì„œ\")\n",
    "                return results\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Dense Search Error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def bm25_search(self, query: str) -> List[Tuple[any, float]]:\n",
    "        \"\"\"BM25 ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)\"\"\"\n",
    "        try:\n",
    "            if self.bm25_retriever:\n",
    "                docs = self.bm25_retriever.invoke(query)\n",
    "                results = [(doc, 1.0) for doc in docs]\n",
    "                print(f\"  ğŸ“Š BM25: {len(results)}ê°œ ë¬¸ì„œ\")\n",
    "                return results\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ BM25 Search Error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def retrieve(self, queries: List[str], metadata_filter: Dict = None) -> Dict[str, List[Tuple[any, float]]]:\n",
    "        \"\"\"ëª¨ë“  ê²€ìƒ‰ ì „ëµ ì‹¤í–‰\"\"\"\n",
    "        all_results = {\n",
    "            'dense': [],\n",
    "            'bm25': []\n",
    "        }\n",
    "        \n",
    "        for query in queries:\n",
    "            print(f\"ğŸ” ê²€ìƒ‰ ì¤‘: {query}\")\n",
    "            all_results['dense'].extend(self.dense_search(query, metadata_filter))\n",
    "            all_results['bm25'].extend(self.bm25_search(query))\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def get_ensemble(self, query: str) -> List[any]:\n",
    "        \"\"\"Ensemble ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìš©)\"\"\"\n",
    "        if not RETRIEVERS_AVAILABLE or EnsembleRetriever is None:\n",
    "            print(\"âš ï¸ EnsembleRetrieverë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "            return self.dense_search(query)\n",
    "        \n",
    "        try:\n",
    "            retrievers = []\n",
    "            weights = []\n",
    "            \n",
    "            if self.bm25_retriever:\n",
    "                retrievers.append(self.bm25_retriever)\n",
    "                weights.append(self.bm25_weight)\n",
    "            \n",
    "            if self.vector_retriever:\n",
    "                retrievers.append(self.vector_retriever)\n",
    "                weights.append(self.vector_weight)\n",
    "            \n",
    "            if not retrievers:\n",
    "                print(\"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ retrieverê°€ ì—†ìŠµë‹ˆë‹¤\")\n",
    "                return []\n",
    "            \n",
    "            # ê°€ì¤‘ì¹˜ ì •ê·œí™”\n",
    "            total_weight = sum(weights)\n",
    "            weights = [w / total_weight for w in weights]\n",
    "            \n",
    "            # LangChainì˜ EnsembleRetriever ì‚¬ìš©\n",
    "            ensemble = EnsembleRetriever(\n",
    "                retrievers=retrievers,\n",
    "                weights=weights\n",
    "            )\n",
    "            \n",
    "            docs = ensemble.invoke(query)\n",
    "            print(f\"ğŸ”— Ensemble: {len(docs)}ê°œ ë¬¸ì„œ\")\n",
    "            return docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Ensemble Search Error: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab75a0",
   "metadata": {},
   "source": [
    "## 5. RRF (Reciprocal Rank Fusion): ê²€ìƒ‰ ê²°ê³¼ í†µí•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2f94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReciprocalRankFusion:\n",
    "    \"\"\"ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë­í‚¹ ê¸°ë°˜ìœ¼ë¡œ í†µí•©\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 60):\n",
    "        self.k = k  # RRF ìƒìˆ˜\n",
    "    \n",
    "    def fuse(self, results_dict: Dict[str, List[Tuple[any, float]]], top_k: int = 10) -> List[any]:\n",
    "        \"\"\"RRFë¡œ ê²°ê³¼ í†µí•©\"\"\"\n",
    "        doc_scores = {}\n",
    "        \n",
    "        for method, results in results_dict.items():\n",
    "            for rank, (doc, score) in enumerate(results, 1):\n",
    "                doc_id = doc.metadata.get('policy_id', id(doc))\n",
    "                \n",
    "                # RRF ì ìˆ˜ ê³„ì‚°: 1 / (k + rank)\n",
    "                rrf_score = 1.0 / (self.k + rank)\n",
    "                \n",
    "                if doc_id not in doc_scores:\n",
    "                    doc_scores[doc_id] = {'doc': doc, 'score': 0}\n",
    "                doc_scores[doc_id]['score'] += rrf_score\n",
    "        \n",
    "        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬\n",
    "        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1]['score'], reverse=True)\n",
    "        final_docs = [item[1]['doc'] for item in sorted_docs[:top_k]]\n",
    "        \n",
    "        print(f\"ğŸ”— RRF: {len(doc_scores)}ê°œ ë¬¸ì„œ â†’ {len(final_docs)}ê°œ ì„ íƒ\")\n",
    "        return final_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19827d4f",
   "metadata": {},
   "source": [
    "## 6. Memory Store: ëŒ€í™” ë§¥ë½ ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83514375",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConversationMemory:\n",
    "    \"\"\"ëŒ€í™” ê¸°ë¡ ê´€ë¦¬\"\"\"\n",
    "    messages: List[Dict] = field(default_factory=list)\n",
    "    max_history: int = 10\n",
    "    \n",
    "    def add_message(self, role: str, content: str):\n",
    "        \"\"\"ë©”ì‹œì§€ ì¶”ê°€\"\"\"\n",
    "        self.messages.append({\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # ìµœëŒ€ ê¸°ë¡ ìˆ˜ ì œí•œ\n",
    "        if len(self.messages) > self.max_history * 2:\n",
    "            self.messages = self.messages[-self.max_history * 2:]\n",
    "    \n",
    "    def get_context(self) -> str:\n",
    "        \"\"\"ëŒ€í™” ë§¥ë½ ë¬¸ìì—´ ìƒì„±\"\"\"\n",
    "        if not self.messages:\n",
    "            return \"ì´ì „ ëŒ€í™” ì—†ìŒ\"\n",
    "        \n",
    "        context_parts = []\n",
    "        for msg in self.messages[-6:]:  # ìµœê·¼ 3í„´\n",
    "            role = \"ì‚¬ìš©ì\" if msg['role'] == 'user' else \"AI\"\n",
    "            context_parts.append(f\"{role}: {msg['content']}\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"ê¸°ë¡ ì´ˆê¸°í™”\"\"\"\n",
    "        self.messages.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03cd202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedRAGPipeline:\n",
    "    \"\"\"ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        documents: List[any],\n",
    "        vectorstore: Chroma,\n",
    "        llm: ChatOpenAI,\n",
    "        enable_router: bool = True,\n",
    "        enable_multi_query: bool = True,\n",
    "        enable_ensemble: bool = True,\n",
    "        enable_rrf: bool = True,\n",
    "        enable_memory: bool = True,\n",
    "        enable_region_filter: bool = True,\n",
    "        bm25_k: int = 5,\n",
    "        vector_k: int = 10,\n",
    "        bm25_weight: float = 0.4,\n",
    "        vector_weight: float = 0.6\n",
    "    ):\n",
    "        self.documents = documents\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        \n",
    "        # ê° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”\n",
    "        self.router = QueryRouter(llm) if enable_router else None\n",
    "        self.multi_query = MultiQueryGenerator(llm) if enable_multi_query else None\n",
    "        self.region_filter = RegionFilter(llm) if enable_region_filter else None\n",
    "        self.ensemble = EnsembleRetriever(\n",
    "            documents=documents,\n",
    "            vectorstore=vectorstore,\n",
    "            llm=llm,\n",
    "            bm25_k=bm25_k,\n",
    "            vector_k=vector_k,\n",
    "            bm25_weight=bm25_weight,\n",
    "            vector_weight=vector_weight\n",
    "        ) if enable_ensemble else None\n",
    "        self.rrf = ReciprocalRankFusion() if enable_rrf else None\n",
    "        self.memory = ConversationMemory() if enable_memory else None\n",
    "        \n",
    "        # ìµœì¢… ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
    "        self.answer_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"ë‹¹ì‹ ì€ 'ì˜¨í†µì²­ë…„ ì²­ë…„ì •ì±… ì „ë‹´ ì±—ë´‡ í“¨ë´‡'ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—­í• :\n",
    "- ì²­ë…„ ì •ì±…(íŠ¹íˆ ì£¼ê±°Â·ì›”ì„¸Â·ì¼ìë¦¬Â·ë³µì§€) ì •ë³´ë¥¼, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬í•´ ì£¼ëŠ” ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\n",
    "- ë°˜ë“œì‹œ 'ê²€ìƒ‰ëœ ì •ì±… ì •ë³´(documents)' ì•ˆì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì„œ ë‹µë³€í•©ë‹ˆë‹¤.\n",
    "- ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ê³ , ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” \"ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë¼ í™•ë‹µì´ ì–´ë µë‹¤\"ê³  ë§í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹(ê¼­ ì§€ì¼œì•¼ í•¨):\n",
    "\n",
    "1. í•­ìƒ ì•„ë˜ ë¬¸êµ¬ë¡œ ì‹œì‘í•œë‹¤.\n",
    "   ì•ˆë…•í•˜ì„¸ìš”. ì²­ë…„Â·1ì¸ ê°€êµ¬ ìƒí™œë³µì§€Â·ì§€ì› ì±—ë´‡ì…ë‹ˆë‹¤.\n",
    "\n",
    "2. ê·¸ ë‹¤ìŒ ì¤„ì— ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤€ë‹¤.\n",
    "   ì‚¬ìš©ì ì§ˆë¬¸ : {query}\n",
    "\n",
    "3. ê·¸ ë‹¤ìŒì— 'ë‹µë³€ :'ì„ ì“°ê³ , ì •ì±…ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ì„œ ì •ë¦¬í•œë‹¤.\n",
    "   - ìµœì†Œ 1ê°œ, ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ê°€ì¥ í•µì‹¬ì ì¸ ì •ì±…ì„ ê³¨ë¼ ì„¤ëª…í•œë‹¤.\n",
    "   - ê° ì •ì±…ì€ ì•„ë˜ êµ¬ì¡°ë¥¼ ë”°ë¥¸ë‹¤.\n",
    "\n",
    "   ì˜ˆì‹œ í˜•ì‹:\n",
    "\n",
    "   ë‹µë³€ :\n",
    "   1. ì •ì±…ëª… (ì£¼ì²´/ì§€ì—­)\n",
    "   ì‚¬ì—… ê°œìš”\n",
    "   - ì‚¬ì—… ê¸°ê°„ : ...\n",
    "   - ëª©ì  : ...\n",
    "\n",
    "   ì‹ ì²­ ìê²©(í•µì‹¬ ìš”ê±´)\n",
    "   - ì—°ë ¹ : ...\n",
    "   - ì£¼ê±° : ...\n",
    "   - ì†Œë“ : ...\n",
    "   - ê¸°íƒ€ ì¡°ê±´ : ...\n",
    "\n",
    "   ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„\n",
    "   - ì›” ì§€ì› ê¸ˆì•¡ : ...\n",
    "   - ì§€ì› ê¸°ê°„ : ...\n",
    "\n",
    "   ì‹ ì²­ ë°©ë²•(ì ˆì°¨)\n",
    "   - ì–´ë””ì— ì‹ ì²­ : ...\n",
    "   - ì–´ë–»ê²Œ ì‹ ì²­ : ...\n",
    "\n",
    "   ìœ ì˜ì‚¬í•­\n",
    "   - ì‹œÂ·êµ°ë³„ ê³µê³  ì‹œê¸°, ì„¸ë¶€ ì¡°ê±´ì€ ë°˜ë“œì‹œ í•´ë‹¹ ì§€ìì²´ ê³µê³ ë¬¸ ì°¸ê³ \n",
    "   - ì¤‘ë³µ ì§€ì› ê°€ëŠ¥ ì—¬ë¶€ ë“±ì€ ì‹¤ì œ ê³µê³  ê¸°ì¤€ìœ¼ë¡œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ\n",
    "\n",
    "4. ë§ˆì§€ë§‰ì— 'ì¶œì²˜' ë¸”ë¡ì„ ì ëŠ”ë‹¤.\n",
    "   - ë¬¸ì„œ ë©”íƒ€ë°ì´í„°(íŒŒì¼ëª…, í˜ì´ì§€ ì •ë³´ ë“±)ê°€ ìˆìœ¼ë©´ ìµœëŒ€í•œ í™œìš©í•´ì„œ ì‘ì„±í•œë‹¤.\n",
    "   - ì˜ˆì‹œ:\n",
    "     ì¶œì²˜:\n",
    "     - 2025ë…„ ì§€ìì²´ ì²­ë…„ì •ì±… ì‹œí–‰ê³„íš-3(ì „ë¶Â·ì „ë‚¨Â·ê²½ë¶Â·ê²½ë‚¨Â·ì œì£¼).pdf (465í˜ì´ì§€, 470í˜ì´ì§€ ì¸ê·¼)\n",
    "     - ì˜¨í†µì²­ë…„ ëˆ„ë¦¬ì§‘ ì²­ë…„ì£¼ê±°Â·ì›”ì„¸ ì§€ì› ê´€ë ¨ ì •ì±… í•­ëª©\n",
    "\n",
    "ì‘ì„± ì‹œ ìœ ì˜ì‚¬í•­:\n",
    "- ì •ì±…ëª…ì´ ê°™ì€ ê²ƒì„ ì¤‘ë³µí•´ì„œ ì“°ì§€ ë§ ê²ƒ.\n",
    "- ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰í•œ ì§€ì—­(ì˜ˆ: ê²½ë¶, ëŒ€êµ¬ ë“±)ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ì •ì±…ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„ íƒí•  ê²ƒ.\n",
    "- ì§ˆë¬¸ì—ì„œ 'ì›”ì„¸', 'ë³´ì¦ê¸ˆ', 'ì „ì„¸' ë“± í‚¤ì›Œë“œê°€ ë‚˜ì˜¤ë©´, ì£¼ê±°Â·ì›”ì„¸ ê´€ë ¨ ì •ì±… ìœ„ì£¼ë¡œ ì •ë¦¬í•  ê²ƒ.\n",
    "- ìˆ«ì(ì§€ì› ê¸ˆì•¡, ê¸°ê°„, ì—°ë ¹)ëŠ” ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ê°’ìœ¼ë¡œ ì¨ ì¤„ ê²ƒ.\n",
    "\"\"\"),\n",
    "            (\"user\", \"\"\"[ëŒ€í™” ë§¥ë½]\n",
    "{context}\n",
    "\n",
    "[ê²€ìƒ‰ëœ ì •ì±… ì •ë³´]\n",
    "{documents}\n",
    "\n",
    "[í˜„ì¬ ì§ˆë¬¸]\n",
    "{query}\"\"\")\n",
    "        ])\n",
    "        \n",
    "        self.summary_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"ë‹¹ì‹ ì€ ì²­ë…„ ì •ì±… ìƒë‹´ ë‹µë³€ì„ ì§§ê²Œ ìš”ì•½í•˜ëŠ” ë³´ì¡° ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ëª©í‘œ:\n",
    "- ì‚¬ìš©ìì˜ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´, ìœ„ì—ì„œ ìƒì„±ëœ ê¸´ ë‹µë³€ì„ í•µì‹¬ë§Œ í•œ ë²ˆ ë” ì •ë¦¬í•©ë‹ˆë‹¤.\n",
    "- ì •ì±…ëª…, ëŒ€ìƒ(ëˆ„ê°€ ë°›ì„ ìˆ˜ ìˆëŠ”ì§€), ì§€ì› ìœ í˜•/ê¸ˆì•¡ ì •ë„ë§Œ ë‹´ì•„ í•œë‘ ë‹¨ë½ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\n",
    "- ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë§Œë“¤ì§€ ë§ê³ , ì´ë¯¸ ì£¼ì–´ì§„ ë‹µë³€ ë‚´ìš©ë§Œ ì¬êµ¬ì„±í•˜ì„¸ìš”.\n",
    "\"\"\"),\n",
    "            (\"user\", \"\"\"ë‹¤ìŒ ë‹µë³€ì„ ì‚¬ìš©ìê°€ ë¹ ë¥´ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜.\n",
    "\n",
    "[ì „ì²´ ë‹µë³€]\n",
    "{answer}\n",
    "\"\"\")\n",
    "        ])\n",
    "\n",
    "    def query(self, user_query: str) -> Dict:\n",
    "        \"\"\"ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸: {user_query}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ\n",
    "        if self.router:\n",
    "            route_result = self.router.route(user_query)\n",
    "            if not route_result['is_valid']:\n",
    "                return {\n",
    "                    \"answer\": \"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”.\",\n",
    "                    \"documents\": [],\n",
    "                    \"metadata\": route_result\n",
    "                }\n",
    "            query = route_result['refined_query']\n",
    "        else:\n",
    "            query = user_query\n",
    "        \n",
    "        # 2. Region Filter: ì§€ì—­ ì •ë³´ ì¶”ì¶œ ë° í•„í„° ìƒì„±\n",
    "        metadata_filter = None\n",
    "        if self.region_filter:\n",
    "            region_info = self.region_filter.detect_region(query)\n",
    "            metadata_filter = self.region_filter.build_filter(region_info)\n",
    "            if metadata_filter:\n",
    "                print(f\"ğŸ” ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©: {metadata_filter}\")\n",
    "        \n",
    "        # 3. Multi-Query: ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±\n",
    "        if self.multi_query:\n",
    "            queries = self.multi_query.generate(query)\n",
    "        else:\n",
    "            queries = [query]\n",
    "        \n",
    "        # 4. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©)\n",
    "        if self.ensemble:\n",
    "            search_results = self.ensemble.retrieve(queries, metadata_filter)\n",
    "        else:\n",
    "            if metadata_filter:\n",
    "                docs_with_score = self.vectorstore.similarity_search_with_score(\n",
    "                    query, k=5, filter=metadata_filter\n",
    "                )\n",
    "            else:\n",
    "                docs_with_score = self.vectorstore.similarity_search_with_score(query, k=5)\n",
    "            search_results = {'dense': docs_with_score}\n",
    "        \n",
    "        # 5. RRF: ê²€ìƒ‰ ê²°ê³¼ í†µí•© (top_k ì¦ê°€)\n",
    "        if self.rrf:\n",
    "            docs = self.rrf.fuse(search_results, top_k=20)\n",
    "        else:\n",
    "            docs = [doc for doc, score in search_results['dense']]\n",
    "        \n",
    "        # 6. Memory: ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°\n",
    "        if self.memory:\n",
    "            context = self.memory.get_context()\n",
    "        else:\n",
    "            context = \"ì´ì „ ëŒ€í™” ì—†ìŒ\"\n",
    "        \n",
    "        # 7. LLM: ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "        docs_text = \"\\n\\n\".join([\n",
    "            f\"[ì •ì±… {i+1}] {doc.metadata.get('policy_name', 'ì œëª© ì—†ìŒ')}\\n{doc.page_content[:500]}\"\n",
    "            for i, doc in enumerate(docs[:10])\n",
    "        ])\n",
    "        \n",
    "        try:\n",
    "            response = self.answer_prompt | self.llm | StrOutputParser()\n",
    "            answer = response.invoke({\n",
    "                \"context\": context,\n",
    "                \"documents\": docs_text,\n",
    "                \"query\": user_query\n",
    "            })\n",
    "            \n",
    "            # 8. ìš”ì•½ ìƒì„± (Chain of Thought)\n",
    "            summary_response = self.summary_prompt | self.llm | StrOutputParser()\n",
    "            summary = summary_response.invoke({\"answer\": answer})\n",
    "            \n",
    "            # ë©”ëª¨ë¦¬ì— ì €ì¥\n",
    "            if self.memory:\n",
    "                self.memory.add_message(\"user\", user_query)\n",
    "                self.memory.add_message(\"assistant\", answer)\n",
    "            \n",
    "            print(f\"\\nâœ… ë‹µë³€ ìƒì„± ì™„ë£Œ\")\n",
    "            print(f\"ğŸ“Œ ìš”ì•½ ìƒì„± ì™„ë£Œ\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            \n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"summary\": summary,\n",
    "                \"documents\": docs,\n",
    "                \"metadata\": {\n",
    "                    \"queries\": queries,\n",
    "                    \"num_docs_retrieved\": len(docs),\n",
    "                    \"has_context\": bool(self.memory and self.memory.messages),\n",
    "                    \"region_filter\": metadata_filter\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Answer Generation Error: {e}\")\n",
    "            return {\n",
    "                \"answer\": \"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\",\n",
    "                \"documents\": [],\n",
    "                \"metadata\": {\"error\": str(e)}\n",
    "            }\n",
    "    \n",
    "    def clear_memory(self):\n",
    "        \"\"\"ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”\"\"\"\n",
    "        if self.memory:\n",
    "            self.memory.clear()\n",
    "            print(\"ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1851072",
   "metadata": {},
   "source": [
    "## 8. Streamlit ì—°ë™ìš© ì´ˆê¸°í™” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e57eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_rag_pipeline(vectordb_path: str = None, api_key: str = None):\n",
    "    \"\"\"\n",
    "    Streamlitì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        vectordb_path: VectorDB ê²½ë¡œ (Noneì´ë©´ ìë™ ê³„ì‚°)\n",
    "        api_key: OpenAI API Key (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)\n",
    "    \n",
    "    Returns:\n",
    "        AdvancedRAGPipeline: ì´ˆê¸°í™”ëœ íŒŒì´í”„ë¼ì¸ ê°ì²´\n",
    "    \"\"\"\n",
    "    # API Key ì„¤ì •\n",
    "    if api_key:\n",
    "        os.environ['OPENAI_API_KEY'] = api_key\n",
    "    else:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        raise ValueError('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')\n",
    "    \n",
    "    # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.7,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        api_key=api_key\n",
    "    )\n",
    "    \n",
    "    # VectorDB ê²½ë¡œ ì„¤ì •\n",
    "    if vectordb_path is None:\n",
    "        script_dir = os.getcwd()\n",
    "        project_root = os.path.dirname(script_dir)\n",
    "        vectordb_path = os.path.join(project_root, \"data\", \"vectordb\")\n",
    "    \n",
    "    if not os.path.exists(vectordb_path):\n",
    "        raise FileNotFoundError(f\"VectorDB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vectordb_path}\")\n",
    "    \n",
    "    # VectorStore ë¡œë“œ\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=\"youth_policies\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=vectordb_path\n",
    "    )\n",
    "    \n",
    "    # ë¬¸ì„œ ë¡œë“œ (BM25ë¥¼ ìœ„í•´ í•„ìš”)\n",
    "    all_docs = vectorstore.get()\n",
    "    \n",
    "    if not all_docs or not all_docs.get('documents'):\n",
    "        raise ValueError(\"VectorDBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    documents = []\n",
    "    for i, doc_text in enumerate(all_docs['documents']):\n",
    "        if doc_text and doc_text.strip():\n",
    "            metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}\n",
    "            documents.append(Document(page_content=doc_text, metadata=metadata))\n",
    "    \n",
    "    # RAG íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "    rag = AdvancedRAGPipeline(\n",
    "        documents=documents,\n",
    "        vectorstore=vectorstore,\n",
    "        llm=llm,\n",
    "        enable_router=True,\n",
    "        enable_multi_query=True,\n",
    "        enable_ensemble=True,\n",
    "        enable_rrf=True,\n",
    "        enable_memory=True,\n",
    "        enable_region_filter=True,\n",
    "        bm25_k=5,\n",
    "        vector_k=10,\n",
    "        bm25_weight=0.4,\n",
    "        vector_weight=0.6\n",
    "    )\n",
    "    \n",
    "    return rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c1c3d",
   "metadata": {},
   "source": [
    "## 9. ì‚¬ìš© ì˜ˆì‹œ (main í•¨ìˆ˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f40d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')\n",
    "    \n",
    "    # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.0,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        api_key=api_key\n",
    "    )\n",
    "    \n",
    "    # VectorDB ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ)\n",
    "    script_dir = os.getcwd()\n",
    "    project_root = os.path.dirname(script_dir)\n",
    "    chroma_path = os.path.join(project_root, \"SKN_3rd\", \"data\", \"chromadb\")\n",
    "    \n",
    "    print(f\"ğŸ“‚ VectorDB ê²½ë¡œ: {chroma_path}\")\n",
    "    print(f\"ğŸ“‚ ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(chroma_path)}\")\n",
    "    \n",
    "    if not os.path.exists(chroma_path):\n",
    "        print(\"âŒ VectorDB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. build_vectordb.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    vectorstore = Chroma(\n",
    "        collection_name=\"youth_policies\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=chroma_path\n",
    "    )\n",
    "    \n",
    "    # ë¬¸ì„œ ë¡œë“œ (BM25ë¥¼ ìœ„í•´ í•„ìš”)\n",
    "    all_docs = vectorstore.get()\n",
    "    print(f\"ğŸ“Š ChromaDB ë¡œë“œ ê²°ê³¼: {len(all_docs.get('documents', []))}ê°œ ë¬¸ì„œ\")\n",
    "    \n",
    "    if not all_docs or not all_docs.get('documents'):\n",
    "        print(\"âŒ VectorDBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. build_vectordb.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    documents = []\n",
    "    if all_docs and 'documents' in all_docs:\n",
    "        for i, doc_text in enumerate(all_docs['documents']):\n",
    "            if doc_text and doc_text.strip():\n",
    "                metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}\n",
    "                documents.append(Document(page_content=doc_text, metadata=metadata))\n",
    "    \n",
    "    print(f\"ğŸ“š ì´ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
    "    \n",
    "    # ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "    rag = AdvancedRAGPipeline(\n",
    "        documents=documents,\n",
    "        vectorstore=vectorstore,\n",
    "        llm=llm,\n",
    "        enable_router=True,\n",
    "        enable_multi_query=True,\n",
    "        enable_ensemble=True,\n",
    "        enable_rrf=True,\n",
    "        enable_memory=True,\n",
    "        enable_region_filter=True,\n",
    "        bm25_k=5,\n",
    "        vector_k=10,\n",
    "        bm25_weight=0.4,\n",
    "        vector_weight=0.6\n",
    "    )\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì§ˆì˜ \n",
    "    queries = [ \"ì „êµ­ ì›”ì„¸ ì •ì±…\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        result = rag.query(query)\n",
    "        print(f\"\\nì§ˆë¬¸: {query}\")\n",
    "        print(f\"\\nğŸ“„ì „ì²´ ë‹µë³€:\\n{result['answer']}\")\n",
    "        if 'summary' in result:\n",
    "            print(f\"\\nğŸ“Œìš”ì•½:\\n{result['summary']}\")\n",
    "        print(f\"\\në¬¸ì„œ ìˆ˜: {result['metadata'].get('num_docs_retrieved', 0)}\")\n",
    "        print(f\"ì§€ì—­ í•„í„°: {result['metadata'].get('region_filter', 'None')}\")\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58074feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ VectorDB ê²½ë¡œ: c:\\Users\\playdata2\\Desktop\\SKN_3rd\\data\\chromadb\n",
      "ğŸ“‚ ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: True\n",
      "ğŸ“Š ChromaDB ë¡œë“œ ê²°ê³¼: 3550ê°œ ë¬¸ì„œ\n",
      "ğŸ“š ì´ 3550ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ“Š ChromaDB ë¡œë“œ ê²°ê³¼: 3550ê°œ ë¬¸ì„œ\n",
      "ğŸ“š ì´ 3550ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\n",
      "âœ… BM25 Retriever ì´ˆê¸°í™” ì™„ë£Œ (k=5)\n",
      "âœ… BM25 Retriever ì´ˆê¸°í™” ì™„ë£Œ (k=5)\n",
      "ğŸ§ª VectorStore í…ŒìŠ¤íŠ¸ ê²€ìƒ‰: 1ê°œ ë¬¸ì„œ\n",
      "âœ… Vector Retriever ì´ˆê¸°í™” ì™„ë£Œ (k=10)\n",
      "ğŸ§ª VectorStore í…ŒìŠ¤íŠ¸ ê²€ìƒ‰: 1ê°œ ë¬¸ì„œ\n",
      "âœ… Vector Retriever ì´ˆê¸°í™” ì™„ë£Œ (k=10)\n",
      "âœ… SelfQueryRetriever ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸: ì „êµ­ ì›”ì„¸ ì •ì±…\n",
      "============================================================\n",
      "âœ… SelfQueryRetriever ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸: ì „êµ­ ì›”ì„¸ ì •ì±…\n",
      "============================================================\n",
      "ğŸ”€ Router: ì •ì±…ê²€ìƒ‰ | Valid: True\n",
      "ğŸ”€ Router: ì •ì±…ê²€ìƒ‰ | Valid: True\n",
      "ğŸŒ ì§€ì—­ íƒì§€: None | ì „êµ­: True\n",
      "ğŸ” ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©: {'ì§€ì—­ë²”ìœ„': 'ì „êµ­'}\n",
      "ğŸŒ ì§€ì—­ íƒì§€: None | ì „êµ­: True\n",
      "ğŸ” ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©: {'ì§€ì—­ë²”ìœ„': 'ì „êµ­'}\n",
      "ğŸ” Multi-Query ìƒì„±: 4ê°œ\n",
      "  1. ì „êµ­ì˜ ì›”ì„¸ ì •ì±…ì— ëŒ€í•œ ì •ë³´\n",
      "  2. ì „êµ­ì˜ ì›”ì„¸ ê´€ë ¨ ì •ì±… ì •ë³´\n",
      "  3. ì „êµ­ì˜ ì„ëŒ€ë£Œ ì •ì±…ì— ëŒ€í•œ ì •ë³´\n",
      "  4. ì „êµ­ì—ì„œ ì‹œí–‰ë˜ëŠ” ì›”ì„¸ ê´€ë ¨ ì •ì±…ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "ğŸ” ê²€ìƒ‰ ì¤‘: ì „êµ­ì˜ ì›”ì„¸ ì •ì±…ì— ëŒ€í•œ ì •ë³´\n",
      "ğŸ” Multi-Query ìƒì„±: 4ê°œ\n",
      "  1. ì „êµ­ì˜ ì›”ì„¸ ì •ì±…ì— ëŒ€í•œ ì •ë³´\n",
      "  2. ì „êµ­ì˜ ì›”ì„¸ ê´€ë ¨ ì •ì±… ì •ë³´\n",
      "  3. ì „êµ­ì˜ ì„ëŒ€ë£Œ ì •ì±…ì— ëŒ€í•œ ì •ë³´\n",
      "  4. ì „êµ­ì—ì„œ ì‹œí–‰ë˜ëŠ” ì›”ì„¸ ê´€ë ¨ ì •ì±…ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "ğŸ” ê²€ìƒ‰ ì¤‘: ì „êµ­ì˜ ì›”ì„¸ ì •ì±…ì— ëŒ€í•œ ì •ë³´\n",
      "  ğŸ“Š Dense: 10ê°œ ë¬¸ì„œ\n",
      "  ğŸ“Š BM25: 5ê°œ ë¬¸ì„œ\n",
      "ğŸ” ê²€ìƒ‰ ì¤‘: ì „êµ­ì˜ ì›”ì„¸ ê´€ë ¨ ì •ì±… ì •ë³´\n",
      "  ğŸ“Š Dense: 10ê°œ ë¬¸ì„œ\n",
      "  ğŸ“Š BM25: 5ê°œ ë¬¸ì„œ\n",
      "ğŸ” ê²€ìƒ‰ ì¤‘: ì „êµ­ì˜ ì›”ì„¸ ê´€ë ¨ ì •ì±… ì •ë³´\n",
      "  ğŸ“Š Dense: 10ê°œ ë¬¸ì„œ\n",
      "  ğŸ“Š BM25: 5ê°œ ë¬¸ì„œ\n",
      "ğŸ” ê²€ìƒ‰ ì¤‘: ì „êµ­ì˜ ì„ëŒ€ë£Œ ì •ì±…ì— ëŒ€í•œ ì •ë³´\n",
      "  ğŸ“Š Dense: 10ê°œ ë¬¸ì„œ\n",
      "  ğŸ“Š BM25: 5ê°œ ë¬¸ì„œ\n",
      "ğŸ” ê²€ìƒ‰ ì¤‘: ì „êµ­ì˜ ì„ëŒ€ë£Œ ì •ì±…ì— ëŒ€í•œ ì •ë³´\n",
      "  ğŸ“Š Dense: 10ê°œ ë¬¸ì„œ\n",
      "  ğŸ“Š BM25: 5ê°œ ë¬¸ì„œ\n",
      "ğŸ” ê²€ìƒ‰ ì¤‘: ì „êµ­ì—ì„œ ì‹œí–‰ë˜ëŠ” ì›”ì„¸ ê´€ë ¨ ì •ì±…ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "  ğŸ“Š Dense: 10ê°œ ë¬¸ì„œ\n",
      "  ğŸ“Š BM25: 5ê°œ ë¬¸ì„œ\n",
      "ğŸ” ê²€ìƒ‰ ì¤‘: ì „êµ­ì—ì„œ ì‹œí–‰ë˜ëŠ” ì›”ì„¸ ê´€ë ¨ ì •ì±…ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "  ğŸ“Š Dense: 10ê°œ ë¬¸ì„œ\n",
      "  ğŸ“Š BM25: 5ê°œ ë¬¸ì„œ\n",
      "ğŸ”— RRF: 56ê°œ ë¬¸ì„œ â†’ 20ê°œ ì„ íƒ\n",
      "  ğŸ“Š Dense: 10ê°œ ë¬¸ì„œ\n",
      "  ğŸ“Š BM25: 5ê°œ ë¬¸ì„œ\n",
      "ğŸ”— RRF: 56ê°œ ë¬¸ì„œ â†’ 20ê°œ ì„ íƒ\n",
      "\n",
      "âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ\n",
      "ğŸ“Œ ìš”ì•½ ìƒì„± ì™„ë£Œ\n",
      "============================================================\n",
      "\n",
      "\n",
      "ì§ˆë¬¸: ì „êµ­ ì›”ì„¸ ì •ì±…\n",
      "\n",
      "ğŸ“„ì „ì²´ ë‹µë³€:\n",
      "ì•ˆë…•í•˜ì„¸ìš”. ì²­ë…„Â·1ì¸ ê°€êµ¬ ìƒí™œë³µì§€Â·ì§€ì› ì±—ë´‡ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ì ì§ˆë¬¸ : ì „êµ­ ì›”ì„¸ ì •ì±…\n",
      "\n",
      "ë‹µë³€ :\n",
      "1. ì²­ë…„ì›”ì„¸ ì§€ì›ì‚¬ì—… (ì£¼ì²´/ì „êµ­)\n",
      "   ì‚¬ì—… ê°œìš”\n",
      "   - ì‚¬ì—… ê¸°ê°„ : 2022ë…„ 8ì›” ~ 2027ë…„ 12ì›”\n",
      "   - ëª©ì  : ê³ ê¸ˆë¦¬Â·ê³ ë¬¼ê°€ ë“±ìœ¼ë¡œ ê²½ì œì  ì–´ë ¤ì›€ì„ ê²ªëŠ” ì²­ë…„ì¸µì˜ ì£¼ê±°ë¹„ ê²½ê°\n",
      "\n",
      "   ì‹ ì²­ ìê²©(í•µì‹¬ ìš”ê±´)\n",
      "   - ì—°ë ¹ : 19~34ì„¸ ì´í•˜\n",
      "   - ì£¼ê±° : ë¶€ëª¨ë‹˜ê³¼ ë³„ë„ ê±°ì£¼í•˜ëŠ” ë¬´ì£¼íƒ ì²­ë…„\n",
      "   - ì†Œë“ : ì²­ë…„ê°€êµ¬ ì¤‘ìœ„ì†Œë“ 60% ì´í•˜\n",
      "   - ê¸°íƒ€ ì¡°ê±´ : ì¬ì‚° 122ë°±ë§Œì› ì´í•˜, ì›ê°€êµ¬ ì¤‘ìœ„ì†Œë“ 100% ì´í•˜ & ì¬ì‚° 470ë§Œì› ì´í•˜\n",
      "\n",
      "   ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„\n",
      "   - ì›” ì§€ì› ê¸ˆì•¡ : ìµœëŒ€ 20ë§Œì›\n",
      "   - ì§€ì› ê¸°ê°„ : ìµœëŒ€ 24ê°œì›”\n",
      "\n",
      "   ì‹ ì²­ ë°©ë²•(ì ˆì°¨)\n",
      "   - ì–´ë””ì— ì‹ ì²­ : í•´ë‹¹ ì§€ìì²´ ê³µê³ ë¬¸ ì°¸ê³ \n",
      "   - ì–´ë–»ê²Œ ì‹ ì²­ : ì§€ìì²´ë³„ ì‹ ì²­ ë°©ë²•ì— ë”°ë¼ ì§„í–‰\n",
      "\n",
      "   ìœ ì˜ì‚¬í•­\n",
      "   - ì‹œÂ·êµ°ë³„ ê³µê³  ì‹œê¸°, ì„¸ë¶€ ì¡°ê±´ì€ ë°˜ë“œì‹œ í•´ë‹¹ ì§€ìì²´ ê³µê³ ë¬¸ ì°¸ê³ \n",
      "   - ì¤‘ë³µ ì§€ì› ê°€ëŠ¥ ì—¬ë¶€ ë“±ì€ ì‹¤ì œ ê³µê³  ê¸°ì¤€ìœ¼ë¡œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ\n",
      "\n",
      "2. ì²­ë…„ì›”ì„¸ í•œì‹œ íŠ¹ë³„ì§€ì› (ì£¼ì²´/ì „êµ­)\n",
      "   ì‚¬ì—… ê°œìš”\n",
      "   - ëª©ì  : ê³ ê¸ˆë¦¬Â·ê³ ë¬¼ê°€ ë“±ìœ¼ë¡œ ê²½ì œì  ì–´ë ¤ì›€ì„ ê²ªëŠ” ì²­ë…„ì¸µì˜ ì£¼ê±°ë¹„ ë¶€ë‹´ ê²½ê°\n",
      "\n",
      "   ì‹ ì²­ ìê²©(í•µì‹¬ ìš”ê±´)\n",
      "   - ì—°ë ¹ : ì œí•œ ì—†ìŒ\n",
      "   - ì£¼ê±° : ì›”ì„¸ë¡œ ê±°ì£¼í•˜ëŠ” ì²­ë…„\n",
      "   - ì†Œë“ : ì œí•œ ì—†ìŒ\n",
      "\n",
      "   ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„\n",
      "   - ì›” ì§€ì› ê¸ˆì•¡ : ìµœëŒ€ 20ë§Œì›\n",
      "   - ì§€ì› ê¸°ê°„ : ìµœëŒ€ 12ê°œì›”\n",
      "\n",
      "   ì‹ ì²­ ë°©ë²•(ì ˆì°¨)\n",
      "   - ì–´ë””ì— ì‹ ì²­ : í•´ë‹¹ ì§€ìì²´ ê³µê³ ë¬¸ ì°¸ê³ \n",
      "   - ì–´ë–»ê²Œ ì‹ ì²­ : ì§€ìì²´ë³„ ì‹ ì²­ ë°©ë²•ì— ë”°ë¼ ì§„í–‰\n",
      "\n",
      "   ìœ ì˜ì‚¬í•­\n",
      "   - ì§€ì›ì€ ì‹¤ì œ ë‚©ë¶€í•˜ëŠ” ì„ëŒ€ë£Œ ë²”ìœ„ ë‚´ì—ì„œ ì´ë£¨ì–´ì§€ë©°, ì„ì°¨ë³´ì¦ê¸ˆ, ê´€ë¦¬ë¹„ ë“±ì€ ì œì™¸ë¨\n",
      "\n",
      "ì¶œì²˜:\n",
      "- 2025ë…„ ì§€ìì²´ ì²­ë…„ì •ì±… ì‹œí–‰ê³„íš-3(ì „ë¶Â·ì „ë‚¨Â·ê²½ë¶Â·ê²½ë‚¨Â·ì œì£¼).pdf (465í˜ì´ì§€, 470í˜ì´ì§€ ì¸ê·¼)\n",
      "- ì˜¨í†µì²­ë…„ ëˆ„ë¦¬ì§‘ ì²­ë…„ì£¼ê±°Â·ì›”ì„¸ ì§€ì› ê´€ë ¨ ì •ì±… í•­ëª©\n",
      "\n",
      "ğŸ“Œìš”ì•½:\n",
      "1. **ì²­ë…„ì›”ì„¸ ì§€ì›ì‚¬ì—…**\n",
      "   - **ëŒ€ìƒ**: 19~34ì„¸ ì´í•˜ ë¬´ì£¼íƒ ì²­ë…„, ì†Œë“ 60% ì´í•˜\n",
      "   - **ì§€ì› ìœ í˜•/ê¸ˆì•¡**: ì›” ìµœëŒ€ 20ë§Œì›, ìµœëŒ€ 24ê°œì›”\n",
      "   \n",
      "2. **ì²­ë…„ì›”ì„¸ í•œì‹œ íŠ¹ë³„ì§€ì›**\n",
      "   - **ëŒ€ìƒ**: ì›”ì„¸ ê±°ì£¼ ì²­ë…„, ì—°ë ¹ ë° ì†Œë“ ì œí•œ ì—†ìŒ\n",
      "   - **ì§€ì› ìœ í˜•/ê¸ˆì•¡**: ì›” ìµœëŒ€ 20ë§Œì›, ìµœëŒ€ 12ê°œì›”\n",
      "\n",
      "ì‹ ì²­ì€ ê° ì§€ìì²´ ê³µê³ ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ì§„í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë¬¸ì„œ ìˆ˜: 20\n",
      "ì§€ì—­ í•„í„°: {'ì§€ì—­ë²”ìœ„': 'ì „êµ­'}\n",
      "------------------------------------------------------------\n",
      "\n",
      "âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ\n",
      "ğŸ“Œ ìš”ì•½ ìƒì„± ì™„ë£Œ\n",
      "============================================================\n",
      "\n",
      "\n",
      "ì§ˆë¬¸: ì „êµ­ ì›”ì„¸ ì •ì±…\n",
      "\n",
      "ğŸ“„ì „ì²´ ë‹µë³€:\n",
      "ì•ˆë…•í•˜ì„¸ìš”. ì²­ë…„Â·1ì¸ ê°€êµ¬ ìƒí™œë³µì§€Â·ì§€ì› ì±—ë´‡ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ì ì§ˆë¬¸ : ì „êµ­ ì›”ì„¸ ì •ì±…\n",
      "\n",
      "ë‹µë³€ :\n",
      "1. ì²­ë…„ì›”ì„¸ ì§€ì›ì‚¬ì—… (ì£¼ì²´/ì „êµ­)\n",
      "   ì‚¬ì—… ê°œìš”\n",
      "   - ì‚¬ì—… ê¸°ê°„ : 2022ë…„ 8ì›” ~ 2027ë…„ 12ì›”\n",
      "   - ëª©ì  : ê³ ê¸ˆë¦¬Â·ê³ ë¬¼ê°€ ë“±ìœ¼ë¡œ ê²½ì œì  ì–´ë ¤ì›€ì„ ê²ªëŠ” ì²­ë…„ì¸µì˜ ì£¼ê±°ë¹„ ê²½ê°\n",
      "\n",
      "   ì‹ ì²­ ìê²©(í•µì‹¬ ìš”ê±´)\n",
      "   - ì—°ë ¹ : 19~34ì„¸ ì´í•˜\n",
      "   - ì£¼ê±° : ë¶€ëª¨ë‹˜ê³¼ ë³„ë„ ê±°ì£¼í•˜ëŠ” ë¬´ì£¼íƒ ì²­ë…„\n",
      "   - ì†Œë“ : ì²­ë…„ê°€êµ¬ ì¤‘ìœ„ì†Œë“ 60% ì´í•˜\n",
      "   - ê¸°íƒ€ ì¡°ê±´ : ì¬ì‚° 122ë°±ë§Œì› ì´í•˜, ì›ê°€êµ¬ ì¤‘ìœ„ì†Œë“ 100% ì´í•˜ & ì¬ì‚° 470ë§Œì› ì´í•˜\n",
      "\n",
      "   ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„\n",
      "   - ì›” ì§€ì› ê¸ˆì•¡ : ìµœëŒ€ 20ë§Œì›\n",
      "   - ì§€ì› ê¸°ê°„ : ìµœëŒ€ 24ê°œì›”\n",
      "\n",
      "   ì‹ ì²­ ë°©ë²•(ì ˆì°¨)\n",
      "   - ì–´ë””ì— ì‹ ì²­ : í•´ë‹¹ ì§€ìì²´ ê³µê³ ë¬¸ ì°¸ê³ \n",
      "   - ì–´ë–»ê²Œ ì‹ ì²­ : ì§€ìì²´ë³„ ì‹ ì²­ ë°©ë²•ì— ë”°ë¼ ì§„í–‰\n",
      "\n",
      "   ìœ ì˜ì‚¬í•­\n",
      "   - ì‹œÂ·êµ°ë³„ ê³µê³  ì‹œê¸°, ì„¸ë¶€ ì¡°ê±´ì€ ë°˜ë“œì‹œ í•´ë‹¹ ì§€ìì²´ ê³µê³ ë¬¸ ì°¸ê³ \n",
      "   - ì¤‘ë³µ ì§€ì› ê°€ëŠ¥ ì—¬ë¶€ ë“±ì€ ì‹¤ì œ ê³µê³  ê¸°ì¤€ìœ¼ë¡œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ\n",
      "\n",
      "2. ì²­ë…„ì›”ì„¸ í•œì‹œ íŠ¹ë³„ì§€ì› (ì£¼ì²´/ì „êµ­)\n",
      "   ì‚¬ì—… ê°œìš”\n",
      "   - ëª©ì  : ê³ ê¸ˆë¦¬Â·ê³ ë¬¼ê°€ ë“±ìœ¼ë¡œ ê²½ì œì  ì–´ë ¤ì›€ì„ ê²ªëŠ” ì²­ë…„ì¸µì˜ ì£¼ê±°ë¹„ ë¶€ë‹´ ê²½ê°\n",
      "\n",
      "   ì‹ ì²­ ìê²©(í•µì‹¬ ìš”ê±´)\n",
      "   - ì—°ë ¹ : ì œí•œ ì—†ìŒ\n",
      "   - ì£¼ê±° : ì›”ì„¸ë¡œ ê±°ì£¼í•˜ëŠ” ì²­ë…„\n",
      "   - ì†Œë“ : ì œí•œ ì—†ìŒ\n",
      "\n",
      "   ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„\n",
      "   - ì›” ì§€ì› ê¸ˆì•¡ : ìµœëŒ€ 20ë§Œì›\n",
      "   - ì§€ì› ê¸°ê°„ : ìµœëŒ€ 12ê°œì›”\n",
      "\n",
      "   ì‹ ì²­ ë°©ë²•(ì ˆì°¨)\n",
      "   - ì–´ë””ì— ì‹ ì²­ : í•´ë‹¹ ì§€ìì²´ ê³µê³ ë¬¸ ì°¸ê³ \n",
      "   - ì–´ë–»ê²Œ ì‹ ì²­ : ì§€ìì²´ë³„ ì‹ ì²­ ë°©ë²•ì— ë”°ë¼ ì§„í–‰\n",
      "\n",
      "   ìœ ì˜ì‚¬í•­\n",
      "   - ì§€ì›ì€ ì‹¤ì œ ë‚©ë¶€í•˜ëŠ” ì„ëŒ€ë£Œ ë²”ìœ„ ë‚´ì—ì„œ ì´ë£¨ì–´ì§€ë©°, ì„ì°¨ë³´ì¦ê¸ˆ, ê´€ë¦¬ë¹„ ë“±ì€ ì œì™¸ë¨\n",
      "\n",
      "ì¶œì²˜:\n",
      "- 2025ë…„ ì§€ìì²´ ì²­ë…„ì •ì±… ì‹œí–‰ê³„íš-3(ì „ë¶Â·ì „ë‚¨Â·ê²½ë¶Â·ê²½ë‚¨Â·ì œì£¼).pdf (465í˜ì´ì§€, 470í˜ì´ì§€ ì¸ê·¼)\n",
      "- ì˜¨í†µì²­ë…„ ëˆ„ë¦¬ì§‘ ì²­ë…„ì£¼ê±°Â·ì›”ì„¸ ì§€ì› ê´€ë ¨ ì •ì±… í•­ëª©\n",
      "\n",
      "ğŸ“Œìš”ì•½:\n",
      "1. **ì²­ë…„ì›”ì„¸ ì§€ì›ì‚¬ì—…**\n",
      "   - **ëŒ€ìƒ**: 19~34ì„¸ ì´í•˜ ë¬´ì£¼íƒ ì²­ë…„, ì†Œë“ 60% ì´í•˜\n",
      "   - **ì§€ì› ìœ í˜•/ê¸ˆì•¡**: ì›” ìµœëŒ€ 20ë§Œì›, ìµœëŒ€ 24ê°œì›”\n",
      "   \n",
      "2. **ì²­ë…„ì›”ì„¸ í•œì‹œ íŠ¹ë³„ì§€ì›**\n",
      "   - **ëŒ€ìƒ**: ì›”ì„¸ ê±°ì£¼ ì²­ë…„, ì—°ë ¹ ë° ì†Œë“ ì œí•œ ì—†ìŒ\n",
      "   - **ì§€ì› ìœ í˜•/ê¸ˆì•¡**: ì›” ìµœëŒ€ 20ë§Œì›, ìµœëŒ€ 12ê°œì›”\n",
      "\n",
      "ì‹ ì²­ì€ ê° ì§€ìì²´ ê³µê³ ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ì§„í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë¬¸ì„œ ìˆ˜: 20\n",
      "ì§€ì—­ í•„í„°: {'ì§€ì—­ë²”ìœ„': 'ì „êµ­'}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ (ë…¸íŠ¸ë¶ì—ì„œëŠ” ì§ì ‘ í˜¸ì¶œ)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
