"""
ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
ì „ì²˜ë¦¬ëœ JSON ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ì—¬ ë²¡í„° DBì— ì €ì¥
"""

import json
import os
from datetime import datetime
from dotenv import load_dotenv
import chromadb
from chromadb.config import Settings
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=OPENAI_API_KEY)


def load_preprocessed_data(filepath):
    """
    ì „ì²˜ë¦¬ëœ JSON ë°ì´í„° ë¡œë“œ
    
    Args:
        filepath: JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        list: ì •ì±… ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘: {filepath}")
    
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"âœ… ì´ {len(data)}ê°œì˜ ì •ì±… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    return data


def create_policy_text(policy):
    """
    ì •ì±… ë°ì´í„°ë¥¼ ì„ë² ë”©ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ë°°ì¹˜í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ
    
    Args:
        policy: ì •ì±… ë”•ì…”ë„ˆë¦¬
        
    Returns:
        str: ê²°í•©ëœ í…ìŠ¤íŠ¸
    """
    # ì£¼ìš” í•„ë“œë“¤ì„ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ìƒì„± (ì¤‘ìš”ë„ ìˆœ)
    text_parts = []
    
    # 1. ê°€ì¥ ì¤‘ìš”: ì •ì±…ëª…ê³¼ ë¶„ì•¼
    if policy.get('ì •ì±…ëª…'):
        text_parts.append(f"ì •ì±…ëª…: {policy['ì •ì±…ëª…']}")
    
    if policy.get('ëŒ€ë¶„ë¥˜'):
        text_parts.append(f"ëŒ€ë¶„ë¥˜: {policy['ëŒ€ë¶„ë¥˜']}")
    
    if policy.get('ì¤‘ë¶„ë¥˜'):
        text_parts.append(f"ì¤‘ë¶„ë¥˜: {policy['ì¤‘ë¶„ë¥˜']}")
    
    # 2. ì •ì±… ì„¤ëª… (í•µì‹¬ ë‚´ìš©)
    if policy.get('ì •ì±…ì„¤ëª…'):
        text_parts.append(f"ì •ì±…ì„¤ëª…: {policy['ì •ì±…ì„¤ëª…']}")
    
    # 3. ì§€ì›ë‚´ìš© (ê¸¸ì´ ì œí•œ ì—†ìŒ - ì¤‘ìš”í•œ ì •ë³´)
    if policy.get('ì§€ì›ë‚´ìš©'):
        text_parts.append(f"ì§€ì›ë‚´ìš©: {policy['ì§€ì›ë‚´ìš©']}")
    
    if policy.get('ì •ì±…í‚¤ì›Œë“œ'):
        text_parts.append(f"í‚¤ì›Œë“œ: {policy['ì •ì±…í‚¤ì›Œë“œ']}")
    
    # 4. ì§€ì—­ ì •ë³´ (ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ)
    if policy.get('ì§€ì—­'):
        # ì§€ì—­ ì •ë³´ê°€ ê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì ì ˆíˆ í¬í•¨
        region = policy['ì§€ì—­']
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì§€ì—­ì„ ê°„ë‹¨íˆ ì²˜ë¦¬
        if len(region) > 500:
            # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ (ì „êµ­ ì •ì±…ì¼ ê°€ëŠ¥ì„±)
            region = region[:500] + "..."
        text_parts.append(f"ì ìš©ì§€ì—­: {region}")
    
    # 5. ìê²© ì¡°ê±´ (ìƒì„¸)
    if policy.get('ì¶”ê°€ìê²©ì¡°ê±´'):
        # ê¸¸ì´ ì œí•œ í™•ëŒ€ (500ì)
        qual = policy['ì¶”ê°€ìê²©ì¡°ê±´'][:500]
        text_parts.append(f"ìê²©ì¡°ê±´: {qual}")
    
    # 6. ìê²© ìš”ê±´ (í•œê¸€ ë³€í™˜ëœ í•„ë“œ)
    if policy.get('ì·¨ì—…ìƒíƒœ'):
        job_status = policy['ì·¨ì—…ìƒíƒœ']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€ (ê²€ìƒ‰ í–¥ìƒ)
        natural_terms = []
        if 'ë¯¸ì·¨ì—…ì' in job_status:
            natural_terms.append('ì‹¤ì—…ì, êµ¬ì§ì, ë°±ìˆ˜, ì·¨ì—…ì¤€ë¹„ìƒ')
        if 'ì¬ì§ì' in job_status:
            natural_terms.append('ì§ì¥ì¸, ê·¼ë¡œì')
        if 'ì°½ì—…ì' in job_status or 'ì˜ˆë¹„' in job_status:
            natural_terms.append('ì°½ì—…ì¤€ë¹„, ì‚¬ì—…ì')
        
        full_status = f"ì·¨ì—…ìƒíƒœ: {job_status}"
        if natural_terms:
            full_status += f" ({', '.join(natural_terms)})"
        text_parts.append(full_status)
    
    if policy.get('í•™ë ¥ìš”ê±´'):
        edu_req = policy['í•™ë ¥ìš”ê±´']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€
        natural_edu = []
        if 'ê³ ì¡¸' in edu_req or 'ê³ êµ' in edu_req:
            natural_edu.append('ê³ ë“±í•™êµ')
        if 'ëŒ€í•™' in edu_req or 'ëŒ€ì¡¸' in edu_req:
            natural_edu.append('ëŒ€í•™êµ, í•™ì‚¬')
        if 'ì„ë°•ì‚¬' in edu_req:
            natural_edu.append('ëŒ€í•™ì›')
        
        full_edu = f"í•™ë ¥: {edu_req}"
        if natural_edu:
            full_edu += f" ({', '.join(natural_edu)})"
        text_parts.append(full_edu)
    
    if policy.get('ì „ê³µìš”ê±´'):
        major_req = policy['ì „ê³µìš”ê±´']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€
        natural_major = []
        if 'ê³µí•™' in major_req:
            natural_major.append('ì´ê³µê³„, ê¸°ìˆ , IT, ê³µëŒ€')
        if 'ìƒê²½' in major_req:
            natural_major.append('ê²½ì˜, ê²½ì œ, íšŒê³„')
        if 'ì˜ˆì²´ëŠ¥' in major_req:
            natural_major.append('ì˜ˆìˆ , ì²´ìœ¡, ìŒì•…, ë¯¸ìˆ ')
        
        full_major = f"ì „ê³µ: {major_req}"
        if natural_major:
            full_major += f" ({', '.join(natural_major)})"
        text_parts.append(full_major)
    
    if policy.get('íŠ¹í™”ë¶„ì•¼'):
        special = policy['íŠ¹í™”ë¶„ì•¼']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€
        natural_special = []
        if 'ì—¬ì„±' in special:
            natural_special.append('ì—¬ì„±ì²­ë…„, ê²½ë ¥ë‹¨ì ˆì—¬ì„±')
        if 'ì¥ì• ì¸' in special:
            natural_special.append('ì¥ì• ì²­ë…„')
        if 'í•œë¶€ëª¨' in special:
            natural_special.append('ì‹±ê¸€ë§˜, ì‹±ê¸€ëŒ€ë””, ë¯¸í˜¼ëª¨, ë¯¸í˜¼ë¶€')
        if 'ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì' in special:
            natural_special.append('ì €ì†Œë“ì¸µ, ì°¨ìƒìœ„ê³„ì¸µ')
        if 'ì¤‘ì†Œê¸°ì—…' in special:
            natural_special.append('ì¤‘ê²¬ê¸°ì—…, ìŠ¤íƒ€íŠ¸ì—…')
        
        full_special = f"íŠ¹í™”ë¶„ì•¼: {special}"
        if natural_special:
            full_special += f" ({', '.join(natural_special)})"
        text_parts.append(full_special)
    
    if policy.get('ì •ì±…ì œê³µë°©ë²•'):
        text_parts.append(f"ì œê³µë°©ë²•: {policy['ì •ì±…ì œê³µë°©ë²•']}")
    
    if policy.get('ì†Œë“ì¡°ê±´'):
        income = policy['ì†Œë“ì¡°ê±´']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€
        natural_income = []
        if 'ë¬´ê´€' in income:
            natural_income.append('ì†Œë“ì œí•œì—†ìŒ, ëˆ„êµ¬ë‚˜')
        if 'ì—°ì†Œë“' in income:
            natural_income.append('ì†Œë“ê¸°ì¤€, ì†Œë“ì œí•œ')
        
        full_income = f"ì†Œë“ì¡°ê±´: {income}"
        if natural_income:
            full_income += f" ({', '.join(natural_income)})"
        text_parts.append(full_income)
    
    if policy.get('í˜¼ì¸ìƒíƒœ'):
        text_parts.append(f"í˜¼ì¸ìƒíƒœ: {policy['í˜¼ì¸ìƒíƒœ']}")
    
    # 7. ì—°ë ¹ ì œí•œ
    min_age = policy.get('ì§€ì›ìµœì†Œì—°ë ¹', '0')
    max_age = policy.get('ì§€ì›ìµœëŒ€ì—°ë ¹', '0')
    if min_age != '0' or max_age != '0':
        age_info = f"ëŒ€ìƒì—°ë ¹: {min_age}ì„¸ ~ {max_age}ì„¸"
        text_parts.append(age_info)
    
    # 8. ì§€ì›ê¸ˆì•¡
    min_amount = policy.get('ìµœì†Œì§€ì›ê¸ˆì•¡', '0')
    max_amount = policy.get('ìµœëŒ€ì§€ì›ê¸ˆì•¡', '0')
    if min_amount != '0' or max_amount != '0':
        amount_info = f"ì§€ì›ê¸ˆì•¡: {min_amount}ì› ~ {max_amount}ì›"
        text_parts.append(amount_info)
    
    if policy.get('ê¸°íƒ€ì§€ì›ì¡°ê±´'):
        other_cond = policy['ê¸°íƒ€ì§€ì›ì¡°ê±´'][:200]
        text_parts.append(f"ê¸°íƒ€ì¡°ê±´: {other_cond}")
    
    # 9. ì‹ ì²­ ë° ì„ ì • ë°©ë²•
    if policy.get('ì‹ ì²­ê¸°ê°„êµ¬ë¶„'):
        text_parts.append(f"ì‹ ì²­ê¸°ê°„: {policy['ì‹ ì²­ê¸°ê°„êµ¬ë¶„']}")
    
    if policy.get('ì‚¬ì—…ê¸°ê°„êµ¬ë¶„'):
        text_parts.append(f"ì‚¬ì—…ê¸°ê°„: {policy['ì‚¬ì—…ê¸°ê°„êµ¬ë¶„']}")
    
    if policy.get('ì‹ ì²­ë°©ë²•'):
        method = policy['ì‹ ì²­ë°©ë²•'][:200]  # ë„ˆë¬´ ê¸¸ë©´ ì œí•œ
        text_parts.append(f"ì‹ ì²­ë°©ë²•: {method}")
    
    if policy.get('ì„ ì •ë°©ë²•'):
        selection = policy['ì„ ì •ë°©ë²•'][:200]
        text_parts.append(f"ì„ ì •ë°©ë²•: {selection}")
    
    if policy.get('ì œì¶œì„œë¥˜'):
        docs = policy['ì œì¶œì„œë¥˜'][:200]
        text_parts.append(f"ì œì¶œì„œë¥˜: {docs}")
    
    # 10. ì°¸ì—¬ì œì™¸ëŒ€ìƒ (ì¤‘ìš” ì •ë³´)
    if policy.get('ì°¸ì—¬ì œì™¸ëŒ€ìƒ'):
        exclusion = policy['ì°¸ì—¬ì œì™¸ëŒ€ìƒ'][:300]
        text_parts.append(f"ì œì™¸ëŒ€ìƒ: {exclusion}")
    
    # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìµœì†Œí•œì˜ ì •ë³´ë¼ë„ í¬í•¨
    if not text_parts:
        text_parts.append(f"ì²­ë…„ì •ì±…")
    
    # í…ìŠ¤íŠ¸ ê²°í•© ë° ì •ì œ
    full_text = "\n".join(text_parts)
    
    # ì¤‘ë³µ ê³µë°± ì œê±° ë° ì •ë¦¬
    full_text = " ".join(full_text.split())
    
    return full_text


def get_embeddings_batch(texts, model="text-embedding-3-small"):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ë°°ì¹˜ë¡œ ìƒì„± (ì†ë„ í–¥ìƒ)
    
    Args:
        texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸
        
    Returns:
        list: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
    """
    # í…ìŠ¤íŠ¸ ì •ì œ
    cleaned_texts = []
    for text in texts:
        text = text.replace("\n", " ").strip()
        if not text or len(text) < 3:
            text = "ì •ì±… ì •ë³´"
        if len(text) > 8000:
            text = text[:8000]
        cleaned_texts.append(text)
    
    # API í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.embeddings.create(input=cleaned_texts, model=model)
            return [item.embedding for item in response.data]
        except Exception as e:
            if attempt < max_retries - 1:
                import time
                wait_time = (attempt + 1) * 2
                print(f"  âš ï¸  ë°°ì¹˜ API ì˜¤ë¥˜, {wait_time}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})")
                time.sleep(wait_time)
            else:
                raise e


def get_embedding(text, model="text-embedding-3-small"):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
    
    Args:
        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸
               - text-embedding-3-small (1536ì°¨ì›, ë¹ ë¦„, ì €ë ´)
               - text-embedding-3-large (3072ì°¨ì›, ëŠë¦¼, ê³ í’ˆì§ˆ, ê³ ë¹„ìš©)
        
    Returns:
        list: ì„ë² ë”© ë²¡í„°
    """
    # í…ìŠ¤íŠ¸ ì •ì œ
    text = text.replace("\n", " ").strip()
    
    # ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬
    if not text or len(text) < 3:
        text = "ì •ì±… ì •ë³´"
    
    # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ë‚´ê¸°
    # text-embedding-3-small: ìµœëŒ€ 8191 í† í° (~32,000ì)
    # ì•ˆì „ì„ ìœ„í•´ 8000ìë¡œ ì œí•œ
    if len(text) > 8000:
        text = text[:8000]
    
    # API í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§ (Rate limit ëŒ€ì‘)
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.embeddings.create(input=[text], model=model)
            return response.data[0].embedding
        except Exception as e:
            if attempt < max_retries - 1:
                import time
                wait_time = (attempt + 1) * 2  # 2, 4, 6ì´ˆ ëŒ€ê¸°
                print(f"  âš ï¸  API ì˜¤ë¥˜, {wait_time}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})")
                time.sleep(wait_time)
            else:
                raise e


def build_chromadb(policies, db_path="../data/vectordb"):
    """
    ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
    
    Args:
        policies: ì •ì±… ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        db_path: DB ì €ì¥ ê²½ë¡œ
    """
    print("\n" + "=" * 70)
    print("ğŸ”¨ ChromaDB êµ¬ì¶• ì‹œì‘")
    print("=" * 70)
    
    # DB ë””ë ‰í† ë¦¬ ìƒì„±
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    db_full_path = os.path.join(project_root, "data", "vectordb")
    os.makedirs(db_full_path, exist_ok=True)
    
    print(f"ğŸ“ DB ì €ì¥ ê²½ë¡œ: {db_full_path}")
    
    # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    chroma_client = chromadb.PersistentClient(path=db_full_path)
    
    # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (ìˆìœ¼ë©´)
    try:
        chroma_client.delete_collection(name="youth_policies")
        print("ğŸ—‘ï¸  ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ")
    except:
        pass
    
    # ë¬¼ë¦¬ì  íŒŒì¼ ì •ë¦¬ (ì„¸ê·¸ë¨¼íŠ¸ í´ë” ì‚­ì œ)
    import shutil
    for item in os.listdir(db_full_path):
        item_path = os.path.join(db_full_path, item)
        # UUID í˜•ì‹ì˜ í´ë”ë§Œ ì‚­ì œ (chroma.sqlite3ëŠ” ìœ ì§€)
        if os.path.isdir(item_path) and '-' in item:
            try:
                shutil.rmtree(item_path)
                print(f"ğŸ—‘ï¸  ì„¸ê·¸ë¨¼íŠ¸ í´ë” ì‚­ì œ: {item}")
            except:
                pass
    
    # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
    collection = chroma_client.create_collection(
        name="youth_policies",
        metadata={"description": "ì˜¨í†µì²­ë…„ ì •ì±… ë°ì´í„°"}
    )
    
    print(f"\nğŸ“Š ì´ {len(policies)}ê°œ ì •ì±… ì²˜ë¦¬ ì¤‘...")
    
    # ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜
    embedding_batch_size = 20  # OpenAI API ë°°ì¹˜ ì œí•œ
    db_batch_size = 50  # DB ì €ì¥ ë°°ì¹˜
    
    all_policy_texts = []
    all_metadatas = []
    all_ids = []
    
    failed_count = 0
    
    # 1ë‹¨ê³„: ëª¨ë“  ì •ì±… í…ìŠ¤íŠ¸ ìƒì„±
    print("  ğŸ“ ì •ì±… í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    for idx, policy in enumerate(policies, 1):
        try:
            policy_text = create_policy_text(policy)
            all_policy_texts.append(policy_text)
            
            all_metadatas.append({
                'ì •ì±…ëª…': policy.get('ì •ì±…ëª…', ''),
                'ëŒ€ë¶„ë¥˜': policy.get('ëŒ€ë¶„ë¥˜', ''),
                'ì¤‘ë¶„ë¥˜': policy.get('ì¤‘ë¶„ë¥˜', ''),
                'ì£¼ê´€ê¸°ê´€ëª…': policy.get('ì£¼ê´€ê¸°ê´€ëª…', ''),
                'ìš´ì˜ê¸°ê´€ëª…': policy.get('ìš´ì˜ê¸°ê´€ëª…', ''),
                'ë“±ë¡ê¸°ê´€ëª…': policy.get('ë“±ë¡ê¸°ê´€ëª…', ''),
                'ìƒìœ„ê¸°ê´€ëª…': policy.get('ìƒìœ„ê¸°ê´€ëª…', ''),
                'ìƒìœ„ë“±ë¡ê¸°ê´€ëª…': policy.get('ìƒìœ„ë“±ë¡ê¸°ê´€ëª…', ''),
                'ì‹ ì²­URL': policy.get('ì‹ ì²­URL', ''),
                'ì •ì±…í‚¤ì›Œë“œ': policy.get('ì •ì±…í‚¤ì›Œë“œ', ''),
                # ì‹ ì²­ ê´€ë ¨
                'ì‹ ì²­ê¸°ê°„': policy.get('ì‹ ì²­ê¸°ê°„', ''),
                'ì‹ ì²­ë°©ë²•': policy.get('ì‹ ì²­ë°©ë²•', ''),
                'ì œì¶œì„œë¥˜': policy.get('ì œì¶œì„œë¥˜', ''),
                # ì‚¬ì—… ê¸°ê°„
                'ì‚¬ì—…ì‹œì‘ì¼': policy.get('ì‚¬ì—…ì‹œì‘ì¼', ''),
                'ì‚¬ì—…ì¢…ë£Œì¼': policy.get('ì‚¬ì—…ì¢…ë£Œì¼', ''),
                # ì‹¬ì‚¬Â·ì„ ì •
                'ì„ ì •ë°©ë²•': policy.get('ì„ ì •ë°©ë²•', ''),
                # ìê²© ê´€ë ¨
                'ì¶”ê°€ìê²©ì¡°ê±´': policy.get('ì¶”ê°€ìê²©ì¡°ê±´', ''),
                'ì°¸ì—¬ì œì™¸ëŒ€ìƒ': policy.get('ì°¸ì—¬ì œì™¸ëŒ€ìƒ', ''),
                'ì§€ì›ìµœì†Œì—°ë ¹': policy.get('ì§€ì›ìµœì†Œì—°ë ¹', '0'),
                'ì§€ì›ìµœëŒ€ì—°ë ¹': policy.get('ì§€ì›ìµœëŒ€ì—°ë ¹', '0'),
                # ì§€ì›ê¸ˆ ê´€ë ¨
                'ìµœì†Œì§€ì›ê¸ˆì•¡': policy.get('ìµœì†Œì§€ì›ê¸ˆì•¡', '0'),
                'ìµœëŒ€ì§€ì›ê¸ˆì•¡': policy.get('ìµœëŒ€ì§€ì›ê¸ˆì•¡', '0'),
                'ê¸°íƒ€ì§€ì›ì¡°ê±´': policy.get('ê¸°íƒ€ì§€ì›ì¡°ê±´', ''),
                # í•œê¸€ ë³€í™˜ëœ í•„ë“œë“¤
                'ì¬ê³µê¸°ê´€ê·¸ë£¹': policy.get('ì¬ê³µê¸°ê´€ê·¸ë£¹', ''),
                'ì •ì±…ì œê³µë°©ë²•': policy.get('ì •ì±…ì œê³µë°©ë²•', ''),
                'ì •ì±…ìŠ¹ì¸ìƒíƒœ': policy.get('ì •ì±…ìŠ¹ì¸ìƒíƒœ', ''),
                'ì‹ ì²­ê¸°ê°„êµ¬ë¶„': policy.get('ì‹ ì²­ê¸°ê°„êµ¬ë¶„', ''),
                'ì‚¬ì—…ê¸°ê°„êµ¬ë¶„': policy.get('ì‚¬ì—…ê¸°ê°„êµ¬ë¶„', ''),
                'í˜¼ì¸ìƒíƒœ': policy.get('í˜¼ì¸ìƒíƒœ', ''),
                'ì†Œë“ì¡°ê±´': policy.get('ì†Œë“ì¡°ê±´', ''),
                'ì „ê³µìš”ê±´': policy.get('ì „ê³µìš”ê±´', ''),
                'ì·¨ì—…ìƒíƒœ': policy.get('ì·¨ì—…ìƒíƒœ', ''),
                'í•™ë ¥ìš”ê±´': policy.get('í•™ë ¥ìš”ê±´', ''),
                'íŠ¹í™”ë¶„ì•¼': policy.get('íŠ¹í™”ë¶„ì•¼', ''),
                'ì§€ì—­': policy.get('ì§€ì—­', ''),
            })
            all_ids.append(f"policy_{idx}")
            
            if idx % 100 == 0:
                print(f"    {idx}/{len(policies)} ({idx/len(policies)*100:.1f}%)")
                
        except Exception as e:
            print(f"  âš ï¸  ì •ì±… {idx} í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            failed_count += 1
            all_policy_texts.append("ì²­ë…„ì •ì±…")
            all_metadatas.append({})
            all_ids.append(f"policy_{idx}")
    
    # 2ë‹¨ê³„: ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    print(f"\n  ğŸ”® ì„ë² ë”© ìƒì„± ì¤‘ (ë°°ì¹˜ í¬ê¸°: {embedding_batch_size})...")
    all_embeddings = []
    
    for i in range(0, len(all_policy_texts), embedding_batch_size):
        batch_texts = all_policy_texts[i:i+embedding_batch_size]
        try:
            batch_embeddings = get_embeddings_batch(batch_texts)
            all_embeddings.extend(batch_embeddings)
            print(f"    ì„ë² ë”©: {min(i+embedding_batch_size, len(all_policy_texts))}/{len(all_policy_texts)} ({min(i+embedding_batch_size, len(all_policy_texts))/len(all_policy_texts)*100:.1f}%)")
        except Exception as e:
            print(f"  âš ï¸  ë°°ì¹˜ {i//embedding_batch_size + 1} ì„ë² ë”© ì˜¤ë¥˜: {e}")
            # í´ë°±: ê°œë³„ ì„ë² ë”©
            for text in batch_texts:
                try:
                    emb = get_embedding(text)
                    all_embeddings.append(emb)
                except:
                    all_embeddings.append([0] * 1536)  # ë¹ˆ ë²¡í„°
                    failed_count += 1
    
    # 3ë‹¨ê³„: DBì— ë°°ì¹˜ ì €ì¥
    print(f"\n  ğŸ’¾ ChromaDB ì €ì¥ ì¤‘ (ë°°ì¹˜ í¬ê¸°: {db_batch_size})...")
    for i in range(0, len(all_policy_texts), db_batch_size):
        batch_docs = all_policy_texts[i:i+db_batch_size]
        batch_metas = all_metadatas[i:i+db_batch_size]
        batch_ids = all_ids[i:i+db_batch_size]
        batch_embs = all_embeddings[i:i+db_batch_size]
        
        collection.add(
            documents=batch_docs,
            metadatas=batch_metas,
            ids=batch_ids,
            embeddings=batch_embs
        )
        print(f"    ì €ì¥: {min(i+db_batch_size, len(all_policy_texts))}/{len(all_policy_texts)} ({min(i+db_batch_size, len(all_policy_texts))/len(all_policy_texts)*100:.1f}%)")
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„
    all_docs = collection.get()
    if all_docs['documents']:
        avg_text_length = sum([len(d) for d in all_docs['documents']]) / len(all_docs['documents'])
        max_text_length = max([len(d) for d in all_docs['documents']])
        min_text_length = min([len(d) for d in all_docs['documents']])
    else:
        avg_text_length = max_text_length = min_text_length = 0
    
    print("\n" + "=" * 70)
    print("âœ… ChromaDB êµ¬ì¶• ì™„ë£Œ!")
    print("=" * 70)
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {db_full_path}")
    print(f"ğŸ“Š ì´ ì €ì¥ëœ ì •ì±… ìˆ˜: {collection.count()}")
    if failed_count > 0:
        print(f"âš ï¸  ì²˜ë¦¬ ì‹¤íŒ¨: {failed_count}ê±´")
    print(f"âœ… ì„±ê³µë¥ : {(len(policies) - failed_count) / len(policies) * 100:.1f}%")
    print(f"ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´ - í‰ê· : {avg_text_length:.0f}ì, ìµœëŒ€: {max_text_length}ì, ìµœì†Œ: {min_text_length}ì")
    
    return collection


# def test_search(collection, query="ì·¨ì—… ì§€ì› ì •ì±…", top_k=3):
#     """
#     ë²¡í„° DB ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    
#     Args:
#         collection: ChromaDB ì»¬ë ‰ì…˜
#         query: ê²€ìƒ‰ ì¿¼ë¦¬
#         top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
#     """
#     print("\n" + "=" * 70)
#     print("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
#     print("=" * 70)
#     print(f"ì§ˆë¬¸: {query}\n")
    
#     # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
#     query_embedding = get_embedding(query)
    
#     # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
#     results = collection.query(
#         query_embeddings=[query_embedding],
#         n_results=top_k
#     )
    
#     print(f"ìƒìœ„ {top_k}ê°œ ê²€ìƒ‰ ê²°ê³¼:\n")
    
#     for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0]), 1):
#         print(f"[{i}] {metadata.get('ì •ì±…ëª…', 'N/A')}")
#         print(f"    ë¶„ì•¼: {metadata.get('ì¤‘ë¶„ë¥˜', 'N/A')}")
#         print(f"    ë‹´ë‹¹: {metadata.get('ì£¼ê´€ê¸°ê´€ëª…', 'N/A')}")
#         print(f"    ì—°ë ¹: {metadata.get('ì§€ì›ìµœì†Œì—°ë ¹', '0')}ì„¸ ~ {metadata.get('ì§€ì›ìµœëŒ€ì—°ë ¹', '0')}ì„¸")
#         print(f"    ì·¨ì—…: {metadata.get('ì·¨ì—…ìƒíƒœ', 'N/A')}")
#         print(f"    ë‚´ìš©: {doc[:150]}...")
#         print()


def main():
    print("=" * 70)
    print("ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•")
    print("=" * 70)
    
    # API í‚¤ í™•ì¸
    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"âœ… OpenAI API í‚¤ ì„¤ì • ì™„ë£Œ")
    
    # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    data_path = os.path.join(project_root, "data", "processed", "youth_policies_filtered_kr_revised.json")
    
    if not os.path.exists(data_path):
        print(f"âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        return
    
    policies = load_preprocessed_data(data_path)
    
    # ìƒ˜í”Œë¡œ ì¼ë¶€ë§Œ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©)
    # policies = policies[:50]  # ì²˜ìŒ 50ê°œë§Œ í…ŒìŠ¤íŠ¸
    # ì „ì²´ ë°ì´í„° ì‚¬ìš©
    print(f"âš ï¸  ì „ì²´ {len(policies)}ê°œ ì •ì±… ì²˜ë¦¬ - ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ChromaDB êµ¬ì¶•
    collection = build_chromadb(policies)
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
#     test_search(collection, "ì·¨ì—… ì§€ì› í”„ë¡œê·¸ë¨ì´ ìˆë‚˜ìš”?")
#     test_search(collection, "ì°½ì—… ê´€ë ¨ ì •ì±…ì„ ì•Œë ¤ì£¼ì„¸ìš”")
    
    print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    main()
