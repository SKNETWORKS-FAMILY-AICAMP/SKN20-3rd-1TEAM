import json
from pathlib import Path
import os
import pandas as pd

# íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ)
current_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()
project_root = current_dir.parent
IN_PATH = project_root / "data" / "raw" / "youth_policies_api.json"
OUT_PATH = project_root / "data" / "processed" / "youth_policies_with_region_level.json"
ZIP_CODE_PATH = project_root / "data" / "processed" / "ë²•ì •ë™ì½”ë“œ ìˆ˜ì •.txt"


# ë²•ì •ë™ì½”ë“œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ
def load_zip_code_mapping():
    """ë²•ì •ë™ì½”ë“œ -> í•œê¸€ ì§€ì—­ëª… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
    df = pd.read_csv(ZIP_CODE_PATH, sep='\t', dtype=str, encoding='cp949')
    # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ {ì½”ë“œ: ì§€ì—­ëª…}
    return dict(zip(df['ë²•ì •ë™ì½”ë“œ'], df['ë²•ì •ë™ëª…']))


# ì½”ë“œ -> í•œê¸€ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë“¤
PVSN_INST_GROUP = {
    "0054001": "ì¤‘ì•™ë¶€ì²˜",
    "0054002": "ì§€ìžì²´"
}

PLCY_PVSN_METHOD = {
    "0042001": "ì¸í”„ë¼ êµ¬ì¶•",
    "0042002": "í”„ë¡œê·¸ëž¨",
    "0042003": "ì§ì ‘ëŒ€ì¶œ",
    "0042004": "ê³µê³µê¸°ê´€",
    "0042005": "ê³„ì•½(ìœ„íƒìš´ì˜)",
    "0042006": "ë³´ì¡°ê¸ˆ",
    "0042007": "ëŒ€ì¶œë³´ì¦",
    "0042008": "ê³µì ë³´í—˜",
    "0042009": "ì¡°ì„¸ì§€ì¶œ",
    "0042010": "ë°”ìš°ì²˜",
    "0042011": "ì •ë³´ì œê³µ",
    "0042012": "ê²½ì œì  ê·œì œ",
    "0042013": "ê¸°íƒ€"
}

PLCY_APPROVAL_STATUS = {
    "0044001": "ì‹ ì²­",
    "0044002": "ìŠ¹ì¸",
    "0044003": "ë°˜ë ¤",
    "0044004": "ìž„ì‹œì €ìž¥"
}

APPLY_PERIOD_TYPE = {
    "0057001": "íŠ¹ì •ê¸°ê°„",
    "0057002": "ìƒì‹œ",
    "0057003": "ë§ˆê°"
}

BIZ_PERIOD_TYPE = {
    "0056001": "íŠ¹ì •ê¸°ê°„",
    "0056002": "ìƒì‹œ",
    "0056003": "ë§ˆê°"
}

MARRIAGE_STATUS = {
    "0055001": "ê¸°í˜¼",
    "0055002": "ë¯¸í˜¼",
    "0055003": "ì œí•œì—†ìŒ"
}

INCOME_CONDITION = {
    "0043001": "ë¬´ê´€",
    "0043002": "ì—°ì†Œë“",
    "0043003": "ê¸°íƒ€"
}

MAJOR_REQUIREMENT = {
    "0011001": "ì¸ë¬¸ê³„ì—´",
    "0011002": "ì‚¬íšŒê³„ì—´",
    "0011003": "ìƒê²½ê³„ì—´",
    "0011004": "ì´í•™ê³„ì—´",
    "0011005": "ê³µí•™ê³„ì—´",
    "0011006": "ì˜ˆì²´ëŠ¥ê³„ì—´",
    "0011007": "ë†ì‚°ì—…ê³„ì—´",
    "0011008": "ê¸°íƒ€",
    "0011009": "ì œí•œì—†ìŒ"
}

JOB_REQUIREMENT = {
    "0013001": "ìž¬ì§ìž",
    "0013002": "ìžì˜ì—…ìž",
    "0013003": "ë¯¸ì·¨ì—…ìž",
    "0013004": "í”„ë¦¬ëžœì„œ",
    "0013005": "ì¼ìš©ê·¼ë¡œìž",
    "0013006": "(ì˜ˆë¹„)ì°½ì—…ìž",
    "0013007": "ë‹¨ê¸°ê·¼ë¡œìž",
    "0013008": "ì˜ë†ì¢…ì‚¬ìž",
    "0013009": "ê¸°íƒ€",
    "0013010": "ì œí•œì—†ìŒ"
}

SCHOOL_REQUIREMENT = {
    "0049001": "ê³ ì¡¸ ë¯¸ë§Œ",
    "0049002": "ê³ êµ ìž¬í•™",
    "0049003": "ê³ ì¡¸ ì˜ˆì •",
    "0049004": "ê³ êµ ì¡¸ì—…",
    "0049005": "ëŒ€í•™ ìž¬í•™",
    "0049006": "ëŒ€ì¡¸ ì˜ˆì •",
    "0049007": "ëŒ€í•™ ì¡¸ì—…",
    "0049008": "ì„Â·ë°•ì‚¬",
    "0049009": "ê¸°íƒ€",
    "0049010": "ì œí•œì—†ìŒ"
}

SPECIAL_REQUIREMENT = {
    "0014001": "ì¤‘ì†Œê¸°ì—…",
    "0014002": "ì—¬ì„±",
    "0014003": "ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ìž",
    "0014004": "í•œë¶€ëª¨ê°€ì •",
    "0014005": "ìž¥ì• ì¸",
    "0014006": "ë†ì—…ì¸",
    "0014007": "êµ°ì¸",
    "0014008": "ì§€ì—­ì¸ìž¬",
    "0014009": "ê¸°íƒ€",
    "0014010": "ì œí•œì—†ìŒ"
}


# ì›ë³¸ í•„ë“œëª… -> ì „ì²˜ë¦¬ ê²°ê³¼(í•œê¸€) í•„ë“œëª… ë§¤í•‘
FIELD_MAP = {
    # ê¸°ë³¸ ì •ë³´
    "plcyNm": "ì •ì±…ëª…",
    "plcyKywdNm": "ì •ì±…í‚¤ì›Œë“œ",
    "plcyExplnCn": "ì •ì±…ì„¤ëª…",
    "lclsfNm": "ëŒ€ë¶„ë¥˜",
    "mclsfNm": "ì¤‘ë¶„ë¥˜",

    # ì§€ì› ë‚´ìš©Â·ì¡°ê±´
    "plcySprtCn": "ì§€ì›ë‚´ìš©",
    "earnMinAmt": "ìµœì†Œì§€ì›ê¸ˆì•¡",
    "earnMaxAmt": "ìµœëŒ€ì§€ì›ê¸ˆì•¡",
    "earnEtcCn": "ê¸°íƒ€ì§€ì›ì¡°ê±´",
    "sprtTrgtMinAge": "ì§€ì›ìµœì†Œì—°ë ¹",
    "sprtTrgtMaxAge": "ì§€ì›ìµœëŒ€ì—°ë ¹",

    # ê¸°ê´€ ì •ë³´
    "sprvsnInstCdNm": "ì£¼ê´€ê¸°ê´€ëª…",
    "operInstCdNm": "ìš´ì˜ê¸°ê´€ëª…",
    "rgtrInstCdNm": "ë“±ë¡ê¸°ê´€ëª…",
    "rgtrUpInstCdNm": "ìƒìœ„ê¸°ê´€ëª…",
    "rgtrHghrkInstCdNm": "ìƒìœ„ë“±ë¡ê¸°ê´€ëª…",

    # ì‹ ì²­Â·ì‚¬ì—… ê¸°ê°„/ë°©ë²•
    "aplyYmd": "ì‹ ì²­ê¸°ê°„",
    "plcyAplyMthdCn": "ì‹ ì²­ë°©ë²•",
    "sbmsnDcmntCn": "ì œì¶œì„œë¥˜",
    "bizPrdBgngYmd": "ì‚¬ì—…ì‹œìž‘ì¼",
    "bizPrdEndYmd": "ì‚¬ì—…ì¢…ë£Œì¼",

    # ì‹¬ì‚¬Â·ì„ ì •
    "srngMthdCn": "ì„ ì •ë°©ë²•",

    # URL
    "aplyUrlAddr": "ì‹ ì²­URL",
    "refUrlAddr1": "ì°¸ê³ URL1",
    "refUrlAddr2": "ì°¸ê³ URL2",

    # ê¸°íƒ€ í…ìŠ¤íŠ¸ ì¡°ê±´
    "addAplyQlfcCndCn": "ì¶”ê°€ìžê²©ì¡°ê±´",
    "ptcpPrpTrgtCn": "ì°¸ì—¬ì œì™¸ëŒ€ìƒ",
}


def decode_multiple_codes(code_string: str, code_map: dict) -> str:
    """
    ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ ì½”ë“œë¥¼ í•œê¸€ë¡œ ë³€í™˜
    ì˜ˆ: "0013001,0013002,0013004" -> "ìž¬ì§ìž, ìžì˜ì—…ìž, í”„ë¦¬ëžœì„œ"
    """
    if not code_string:
        return ""
    
    # ì‰¼í‘œë¡œ ë¶„ë¦¬
    codes = [c.strip() for c in code_string.split(",")]
    
    # ê° ì½”ë“œë¥¼ í•œê¸€ë¡œ ë³€í™˜
    korean_values = []
    for code in codes:
        if code in code_map:
            korean_values.append(code_map[code])
        else:
            korean_values.append(code)  # ë§¤í•‘ ì—†ìœ¼ë©´ ì›ë³¸ ìœ ì§€
    
    # ì‰¼í‘œë¡œ ì—°ê²°í•˜ì—¬ ë°˜í™˜
    return ", ".join(korean_values)


def decode_zip_codes(zip_code_string: str, zip_code_map: dict) -> str:
    """
    ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë²•ì •ë™ì½”ë“œë¥¼ í•œê¸€ ì§€ì—­ëª…ìœ¼ë¡œ ë³€í™˜
    ì˜ˆ: "11110,11140,11170" -> "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬, ì„œìš¸íŠ¹ë³„ì‹œ ì¤‘êµ¬, ì„œìš¸íŠ¹ë³„ì‹œ ìš©ì‚°êµ¬"
    """
    if not zip_code_string:
        return ""
    
    # ì‰¼í‘œë¡œ ë¶„ë¦¬
    codes = [c.strip() for c in zip_code_string.split(",")]
    
    # ê° ì½”ë“œë¥¼ í•œê¸€ë¡œ ë³€í™˜
    korean_regions = []
    for code in codes:
        if code in zip_code_map:
            korean_regions.append(zip_code_map[code])
        else:
            korean_regions.append(code)  # ë§¤í•‘ ì—†ìœ¼ë©´ ì›ë³¸ ìœ ì§€
    
    # ì‰¼í‘œë¡œ ì—°ê²°í•˜ì—¬ ë°˜í™˜
    return ", ".join(korean_regions)


def decode_code_to_korean(src: dict, zip_code_map: dict) -> dict:
    """
    ì½”ë“œ ê°’ì„ í•œê¸€ë¡œ ë³€í™˜ (ì½”ë“œ í•„ë“œëŠ” ì €ìž¥í•˜ì§€ ì•Šê³  í•œê¸€ í•„ë“œë§Œ ë°˜í™˜)
    ì—¬ëŸ¬ ì½”ë“œê°€ ì‰¼í‘œë¡œ êµ¬ë¶„ë˜ì–´ ìžˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
    """
    decoded = {}
    
    # ìž¬ê³µê¸°ê´€ê·¸ë£¹
    if src.get("pvsnInstGroupCd"):
        decoded["ìž¬ê³µê¸°ê´€ê·¸ë£¹"] = decode_multiple_codes(src["pvsnInstGroupCd"], PVSN_INST_GROUP)
    
    # ì •ì±…ì œê³µë°©ë²•
    if src.get("plcyPvsnMthdCd"):
        decoded["ì •ì±…ì œê³µë°©ë²•"] = decode_multiple_codes(src["plcyPvsnMthdCd"], PLCY_PVSN_METHOD)
    
    # ì •ì±…ìŠ¹ì¸ìƒíƒœ
    if src.get("plcyAprvSttsCd"):
        decoded["ì •ì±…ìŠ¹ì¸ìƒíƒœ"] = decode_multiple_codes(src["plcyAprvSttsCd"], PLCY_APPROVAL_STATUS)
    
    # ì‹ ì²­ê¸°ê°„êµ¬ë¶„
    if src.get("aplyPrdSeCd"):
        decoded["ì‹ ì²­ê¸°ê°„êµ¬ë¶„"] = decode_multiple_codes(src["aplyPrdSeCd"], APPLY_PERIOD_TYPE)
    
    # ì‚¬ì—…ê¸°ê°„êµ¬ë¶„
    if src.get("bizPrdSeCd"):
        decoded["ì‚¬ì—…ê¸°ê°„êµ¬ë¶„"] = decode_multiple_codes(src["bizPrdSeCd"], BIZ_PERIOD_TYPE)
    
    # í˜¼ì¸ìƒíƒœ
    if src.get("mrgSttsCd"):
        decoded["í˜¼ì¸ìƒíƒœ"] = decode_multiple_codes(src["mrgSttsCd"], MARRIAGE_STATUS)
    
    # ì†Œë“ì¡°ê±´
    if src.get("earnCndSeCd"):
        decoded["ì†Œë“ì¡°ê±´"] = decode_multiple_codes(src["earnCndSeCd"], INCOME_CONDITION)
    
    # ì „ê³µìš”ê±´
    if src.get("plcyMajorCd"):
        decoded["ì „ê³µìš”ê±´"] = decode_multiple_codes(src["plcyMajorCd"], MAJOR_REQUIREMENT)
    
    # ì·¨ì—…ìš”ê±´
    if src.get("jobCd"):
        decoded["ì·¨ì—…ìƒíƒœ"] = decode_multiple_codes(src["jobCd"], JOB_REQUIREMENT)
    
    # í•™ë ¥ìš”ê±´
    if src.get("schoolCd"):
        decoded["í•™ë ¥ìš”ê±´"] = decode_multiple_codes(src["schoolCd"], SCHOOL_REQUIREMENT)
    
    # íŠ¹í™”ìš”ê±´
    if src.get("sbizCd"):
        decoded["íŠ¹í™”ë¶„ì•¼"] = decode_multiple_codes(src["sbizCd"], SPECIAL_REQUIREMENT)
    
    # ë²•ì •ë™ì½”ë“œ (zipCd) -> ì§€ì—­ëª…
    if src.get("zipCd"):
        decoded["ì§€ì—­"] = decode_zip_codes(src["zipCd"], zip_code_map)
    
    return decoded


def transform_record(src: dict, zip_code_map: dict) -> dict:
    """
    ì›ë³¸ í•œ ê±´(src)ì„ ì „ì²˜ë¦¬ í˜•ì‹(dict)ìœ¼ë¡œ ë³€í™˜.
    - FIELD_MAPì— ì •ì˜ëœ í•­ëª©ë§Œ ë‚¨ê¸°ê³ ,
    - ê°’ì´ ë¹„ì–´ ìžˆìœ¼ë©´ ìƒëžµ
    - ì½”ë“œ í•„ë“œëŠ” í•œê¸€ë¡œ ë³€í™˜ í›„ ì½”ë“œëŠ” ì‚­ì œ
    """
    dst = {}

    for src_key, dst_key in FIELD_MAP.items():
        value = src.get(src_key)
        if value is None:
            continue

        if isinstance(value, str) and value.strip() == "":
            continue

        dst[dst_key] = value
    
    # ì½”ë“œë¥¼ í•œê¸€ë¡œ ë³€í™˜í•œ í•„ë“œ ì¶”ê°€ (ì½”ë“œ í•„ë“œëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ)
    decoded_fields = decode_code_to_korean(src, zip_code_map)
    dst.update(decoded_fields)

    return dst

# ì§€ì—­ë²”ìœ„(ì „êµ­/ì§€ì—­) ì¶”ê°€ ë¶€ë¶„ 
import re

# ì‹œë„ ëª©ë¡
SIDO_LIST = [
    "ì„œìš¸íŠ¹ë³„ì‹œ","ë¶€ì‚°ê´‘ì—­ì‹œ","ëŒ€êµ¬ê´‘ì—­ì‹œ","ì¸ì²œê´‘ì—­ì‹œ","ê´‘ì£¼ê´‘ì—­ì‹œ",
    "ëŒ€ì „ê´‘ì—­ì‹œ","ìš¸ì‚°ê´‘ì—­ì‹œ","ì„¸ì¢…íŠ¹ë³„ìžì¹˜ì‹œ","ê²½ê¸°ë„","ê°•ì›íŠ¹ë³„ìžì¹˜ë„",
    "ì¶©ì²­ë¶ë„","ì¶©ì²­ë‚¨ë„","ì „ë¶íŠ¹ë³„ìžì¹˜ë„","ì „ë¼ë‚¨ë„","ê²½ìƒë¶ë„",
    "ê²½ìƒë‚¨ë„","ì œì£¼íŠ¹ë³„ìžì¹˜ë„"
]

# ì‹œë„ ì¶”ì¶œìš© íŒ¨í„´
SIDO_PATTERN = "(" + "|".join(SIDO_LIST) + ")"


def detect_region_level(region_field: str) -> str:
    """ë¬¸ìžì—´ì—ì„œ ì‹œë„ ë“±ìž¥ ê°œìˆ˜ë¥¼ ì„¸ì–´ nationwide ì •ì±… ì—¬ë¶€ íŒë‹¨"""
    if not region_field or not isinstance(region_field, str):
        return "ì§€ì—­"

    # ì‹œë„ ì¶”ì¶œ
    found_sido = re.findall(SIDO_PATTERN, region_field)

    unique_sido_count = len(set(found_sido))

    # ì „êµ­ íŒë³„ ê¸°ì¤€: 17ê°œ ì‹œë„ ëª¨ë‘ ë“±ìž¥í•´ì•¼ ì „êµ­
    if unique_sido_count == len(SIDO_LIST):  # == 17
        return "ì „êµ­"

    return "ì§€ì—­"


def assign_region_level(policy: dict) -> str:
    """ì •ì±… ë”•ì…”ë„ˆë¦¬ì—ì„œ 'ì§€ì—­' í•„ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ region_level ì‚°ì •"""
    region_text = policy.get("ì§€ì—­", "")

    # â‘  ì§€ì—­ ì •ë³´ê°€ ë¹„ì—ˆê±°ë‚˜ 'ì „êµ­' í˜•íƒœ í‘œì‹œì¸ ê²½ìš°
    if not region_text or region_text.strip() in ["ì „êµ­", "ì „êµ­ê¶Œ", "ì „ì²´"]:
        return "ì „êµ­"

    # â‘¡ ë¬¸ìžì—´ ê¸°ë°˜ ì „êµ­ íŒì • ë¡œì§ ìˆ˜í–‰
    return detect_region_level(region_text)


def main():
    # 0) ë²•ì •ë™ì½”ë“œ ë§¤í•‘ ë¡œë“œ
    print("ë²•ì •ë™ì½”ë“œ ë§¤í•‘ ë¡œë“œ ì¤‘...")
    zip_code_map = load_zip_code_mapping()
    print(f"âœ… ë²•ì •ë™ì½”ë“œ {len(zip_code_map)}ê°œ ë¡œë“œ ì™„ë£Œ")
    
    # 1) ì›ë³¸ JSON ë¡œë“œ
    with IN_PATH.open("r", encoding="utf-8") as f:
        raw = json.load(f)

    # 2) ì •ì±… ë¦¬ìŠ¤íŠ¸ êº¼ë‚´ê¸° (result > youthPolicyList)
    policies = raw["result"]["youthPolicyList"]

    # 3) ê° ì •ì±…ì„ ì „ì²˜ë¦¬ í¬ë§·ìœ¼ë¡œ ë³€í™˜ (í•œê¸€ "ì§€ì—­" í•„ë“œ ìƒì„±)
    transformed = []
    for p in policies:
        rec = transform_record(p, zip_code_map)
        transformed.append(rec)

    # 4) ì „ì²˜ë¦¬ëœ ë°ì´í„°ì— "ì§€ì—­ë²”ìœ„" í•„ë“œ ì¶”ê°€
    for rec in transformed:
        region_level = assign_region_level(rec)
        rec["ì§€ì—­ë²”ìœ„"] = region_level

    # 5) ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ìž¥
    with OUT_PATH.open("w", encoding="utf-8") as f:
        json.dump(transformed, f, ensure_ascii=False, indent=2)

    print(f"ë³€í™˜ ì™„ë£Œ: {len(transformed)}ê±´ -> {OUT_PATH}")
    
    # 6) í†µê³„ ì¶œë ¥
    nationwide_count = sum(1 for rec in transformed if rec.get("ì§€ì—­ë²”ìœ„") == "ì „êµ­")
    regional_count = sum(1 for rec in transformed if rec.get("ì§€ì—­ë²”ìœ„") == "ì§€ì—­")
    print(f"ðŸ“Š ì§€ì—­ë²”ìœ„ í†µê³„: ì „êµ­ {nationwide_count}ê°œ, ì§€ì—­ {regional_count}ê°œ")


if __name__ == "__main__":
    main()