# ğŸ“¦ ê°œë°œëœ ì†Œí”„íŠ¸ì›¨ì–´: RAG ê¸°ë°˜ LLMê³¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ êµ¬í˜„ ì½”ë“œ

## 4. RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„

### 4.1 QueryRouter (ì§ˆë¬¸ ê²€ì¦)

**íŒŒì¼**: `src/advanced_rag.py` (Line 52-100)

**ëª©ì **: ì‚¬ìš©ì ì§ˆë¬¸ì˜ ìœ íš¨ì„± ê²€ì¦ ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜

**ì½”ë“œ**:
```python
class QueryRouter:
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.router_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°ì…ë‹ˆë‹¤.

ì‘ì—…:
1. ì§ˆë¬¸ì´ ì˜ë¯¸ ìˆëŠ”ì§€ ê²€ì¦ (ì¸ì‚¬ë§, ìš•ì„¤, ë¬´ì˜ë¯¸í•œ ì…ë ¥ ì œì™¸)
2. ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì •ì±…ê²€ìƒ‰, ì¶”ì²œ, ì¼ë°˜ì§ˆë¬¸ ë“±)
3. LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì •ì œ
4. ë§Œì•½ ì§ˆë¬¸ì— 'ì „êµ­', 'ì „ì²´', 'ëª¨ë“ ', 'ëª¨ë‘' ë“± ì „êµ­ ë‹¨ìœ„ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆê³ , ì§€ì—­ëª…ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ refined_queryì—ì„œ 'ì „êµ­', 'ì „ì²´' ë“± ì§€ì—­ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì œê±°í•˜ê³  í•µì‹¬ ì •ì±… í‚¤ì›Œë“œë§Œ ë‚¨ê²¨ì„œ ë” ì¼ë°˜í™”ëœ í˜•íƒœë¡œ ì •ì œí•˜ë¼. ì˜ˆë¥¼ ë“¤ì–´ 'ì „êµ­ ì¼ìë¦¬' â†’ 'ì¼ìë¦¬ ì •ì±…', 'ì „êµ­ ì²­ë…„ ë³µì§€' â†’ 'ì²­ë…„ ë³µì§€ ì •ì±…' ë“±ìœ¼ë¡œ ì •ì œ.
5. refined_queryëŠ” ë°˜ë“œì‹œ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ë°˜í™˜í•˜ë¼.

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "is_valid": true/false,
    "category": "ì •ì±…ê²€ìƒ‰|ì •ì±…ì¶”ì²œ|ì¼ë°˜ì§ˆë¬¸|ê¸°íƒ€",
    "refined_query": "ì •ì œëœ ì§ˆë¬¸",
    "reason": "íŒë‹¨ ì´ìœ "
}}

ì˜ˆì‹œ:
- ì…ë ¥: "ì „êµ­ ì¼ìë¦¬" â†’ refined_query: "ì¼ìë¦¬ ì •ì±…"
- ì…ë ¥: "ì „êµ­ ì²­ë…„ ë³µì§€" â†’ refined_query: "ì²­ë…„ ë³µì§€ ì •ì±…"
- ì…ë ¥: "ì„œìš¸ ì›”ì„¸ ì§€ì›" â†’ refined_query: "ì„œìš¸ ì›”ì„¸ ì§€ì› ì •ì±…"
- ì…ë ¥: "ì²­ë…„ ì •ì±…" â†’ refined_query: "ì²­ë…„ ì •ì±…"
"""),
            ("user", "{query}")
        ])
    
    def route(self, query: str) -> Dict:
        """ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œ"""
        try:
            response = self.router_prompt | self.llm | StrOutputParser()
            result_str = response.invoke({"query": query})
            
            # JSON íŒŒì‹±
            result = json.loads(result_str)
            
            return result
        except Exception as e:
            return {
                "is_valid": True,
                "category": "ì¼ë°˜ì§ˆë¬¸",
                "refined_query": query,
                "reason": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë³¸ ì‚¬ìš©"
            }
```

**íŠ¹ì§•**:
- LLM ê¸°ë°˜ ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ: ì‚¬ìš©ì ì…ë ¥ì˜ ìœ íš¨ì„± ê²€ì‚¬ì™€ ê²€ìƒ‰ ìµœì í™”ëœ `refined_query` ìƒì„±(ì „êµ­/ì§€ì—­ í‚¤ì›Œë“œ ì²˜ë¦¬ í¬í•¨)
- êµ¬ì¡°í™”ëœ JSON ì¶œë ¥: `is_valid`, `category`, `refined_query`, `reason` í•„ë“œë¡œ ì¬í˜„ ê°€ëŠ¥í•œ ì‘ë‹µ ì œê³µ
- ì•ˆì „í•œ í´ë°±: íŒŒì‹±/LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•´ ê²€ìƒ‰ ì§„í–‰
- ë‚´ë¶€ êµ¬í˜„: `ChatPromptTemplate` + `StrOutputParser` í™œìš©ìœ¼ë¡œ ì¼ê´€ëœ íŒŒì‹±ê³¼ ë””ë²„ê¹… ê°€ëŠ¥

---

### 4.2 MultiQueryGenerator (ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±)

**íŒŒì¼**: `src/advanced_rag.py` (Line 105-160)

**ëª©ì **: í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ 3ê°œì˜ ë‹¤ì–‘í•œ ê´€ì  ì¿¼ë¦¬ë¡œ í™•ì¥

**ì½”ë“œ**:
```python
class MultiQueryGenerator:
    """í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
        self.multi_query_prompt = ChatPromptTemplate.from_messages([
            "system", """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸ì„ **ì˜ë„ì™€ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ìœ ì§€**í•œ ì±„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤ã€‚

**ì›ë³¸ ì§ˆë¬¸ì˜ ë‚´ìš©ì´ë‚˜ ì¡°ê±´ì„ ì„ì˜ë¡œ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ê²€ìƒ‰ ê´€ì ë§Œ ë‹¤ì–‘í™”í•´ì•¼ í•©ë‹ˆë‹¤ã€‚**

ì£¼ì–´ì§„ ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ ê´€ì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”:

1.  **ì§€ì—­(Region) ì¶”ì¶œ ê°•ì œ: ì‚¬ìš©ìê°€ ì§€ì—­ì„ ì–¸ê¸‰í•˜ë©´, 'í•´ë‹¹ ì§€ì—­ + ì „êµ­' ì •ì±…ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤ã€‚ 
2.  **ì •ì±… í‚¤ì›Œë“œ(Policy Keyword): ì§ˆë¬¸ì˜ **í•µì‹¬ ì˜ë„**ì™€ ê´€ë ¨ëœ ì •ì±… í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ëœ ì •ì±…ë§Œ ë°˜í™˜í•  ê²ƒã€‚
3.  **ìœ ì‚¬í•œ ì˜ë¯¸ ë˜ëŠ” ê´€ë ¨ ì •ì±…ëª…**ì„ í¬í•¨í•˜ëŠ” ì¿¼ë¦¬ (ìœ ì˜ì–´ í™œìš©)

ê° ì¿¼ë¦¬ëŠ” í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ ì—†ì´ ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”ã€‚""",
            ("user", "{query}")
        ])
    
    def generate(self, query: str) -> List[str]:
        """ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±"""
        try:
            response = self.multi_query_prompt | self.llm | StrOutputParser()
            result = response.invoke({"query": query})
            
            # ì¿¼ë¦¬ ë¶„ë¦¬ (ì¤„ë°”ê¿ˆ ê¸°ì¤€)
            queries = [q.strip() for q in result.split('\n') if q.strip()]
            # ì›ë³¸ ì¿¼ë¦¬ í¬í•¨
            all_queries = [query] + queries
            
            
            return all_queries
        
        except Exception as e:
            return [query]
```

**íŠ¹ì§•**:
- ê²€ìƒ‰ ê´€ì  í™•ì¥: ì›ë³¸ ì¿¼ë¦¬ì™€ LLMì´ ìƒì„±í•œ ìµœëŒ€ 3ê°œì˜ ë³´ì¡° ì¿¼ë¦¬(ì§€ì—­/ì •ì±…/ìœ ì˜ì–´ ê´€ì )ë¡œ íƒìƒ‰ ë²”ìœ„ë¥¼ ë„“í˜
- ì§€ì—­ ë° ì •ì±… í‚¤ì›Œë“œ ë³´ì¡´ ê·œì¹™ í¬í•¨: ì‚¬ìš©ìê°€ ì§€ì—­ì„ ëª…ì‹œí•˜ë©´ í•´ë‹¹ ì§€ì—­ + ì „êµ­(ì „êµ­ë²”ìœ„) ê´€ë ¨ ë¬¸ì„œë¥¼ í•¨ê»˜ ê³ ë ¤í•˜ë„ë¡ ì„¤ê³„
- ì•ˆì „í•œ í´ë°±: LLM ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì¿¼ë¦¬ë§Œ ì‚¬ìš©

---

### 4.3 EnsembleRetriever (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)

**íŒŒì¼**: `src/advanced_rag.py` (Line 165-310)

**ëª©ì **: BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ + ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°í•©

**ì½”ë“œ**:
```python
class EnsembleRetriever:
    """Dense, BM25 ê²€ìƒ‰ì„ ê²°í•©í•œ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„"""
    
    def __init__(
        self, 
        documents: List[any],
        vectorstore: Chroma,
        llm: ChatOpenAI = None,
        bm25_k: int = 5,
        vector_k: int = 10,
        bm25_weight: float = 0.4,
        vector_weight: float = 0.6
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        self.llm = llm
        
        # íŒŒë¼ë¯¸í„° ì €ì¥
        self.bm25_k = bm25_k
        self.vector_k = vector_k
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        
        # ê° ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
        self._build_bm25()
        self._build_vector()
    
    def _build_bm25(self):
        """BM25 Retriever ìƒì„±"""
        if not RETRIEVERS_AVAILABLE or BM25Retriever is None:
            self.bm25_retriever = None
            return
        
        if not self.documents:
            self.bm25_retriever = None
            return
        
        try:
            # BM25Retriever ì´ˆê¸°í™” (from_documents ì‚¬ìš©)
            self.bm25_retriever = BM25Retriever.from_documents(
                documents=self.documents,
                k=self.bm25_k
            )
        except TypeError as e:
            # from_documentsê°€ ì‹¤íŒ¨í•˜ë©´ ì§ì ‘ ì´ˆê¸°í™” ì‹œë„
            try:
                self.bm25_retriever = BM25Retriever(docs=self.documents)
                self.bm25_retriever.k = self.bm25_k
            except Exception as e2:
                self.bm25_retriever = None
        except Exception as e:
            self.bm25_retriever = None
    
    def _build_vector(self):
        """Vector Retriever ìƒì„±"""
        try:
            # VectorStore ìƒíƒœ í™•ì¸
            test_search = self.vectorstore.similarity_search("í…ŒìŠ¤íŠ¸", k=1)
            
            self.vector_retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": self.vector_k}
            )
        except Exception as e:
            self.vector_retriever = None
    
    def dense_search(self, query: str, metadata_filter: Dict = None) -> List[Tuple[any, float]]:
        """Dense ê²€ìƒ‰ (ì„ë² ë”© ê¸°ë°˜)"""
        try:
            if self.vector_retriever:
                if metadata_filter:
                    # ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©
                    docs = self.vectorstore.similarity_search(
                        query, 
                        k=self.vector_k,
                        filter=metadata_filter
                    )
                else:
                    docs = self.vector_retriever.invoke(query)
                
                results = [(doc, 1.0) for doc in docs]
                return results
            return []
        except Exception as e:
            return []
    
    def bm25_search(self, query: str) -> List[Tuple[any, float]]:
        """BM25 ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            if self.bm25_retriever:
                docs = self.bm25_retriever.invoke(query)
                results = [(doc, 1.0) for doc in docs]
                return results
            return []
        except Exception as e:
            return []
    
    def retrieve(self, queries: List[str], metadata_filter: Dict = None) -> Dict[str, List[Tuple[any, float]]]:
        """ëª¨ë“  ê²€ìƒ‰ ì „ëµ ì‹¤í–‰"""
        all_results = {
            'dense': [],
            'bm25': []
        }
        
        for query in queries:
            all_results['dense'].extend(self.dense_search(query, metadata_filter))
            all_results['bm25'].extend(self.bm25_search(query))
        
        return all_results
    
    def get_ensemble(self, query: str) -> List[any]:
        """Ensemble ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìš©)"""
        if not RETRIEVERS_AVAILABLE or EnsembleRetriever is None:
            return self.dense_search(query)
        
        try:
            retrievers = []
            weights = []
            
            if self.bm25_retriever:
                retrievers.append(self.bm25_retriever)
                weights.append(self.bm25_weight)
            
            if self.vector_retriever:
                retrievers.append(self.vector_retriever)
                weights.append(self.vector_weight)
            
            if not retrievers:
                return []
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            total_weight = sum(weights)
            weights = [w / total_weight for w in weights]
            
            # LangChainì˜ EnsembleRetriever ì‚¬ìš©
            ensemble = EnsembleRetriever(
                retrievers=retrievers,
                weights=weights
            )
            
            docs = ensemble.invoke(query)
            return docs
            
        except Exception as e:
            return []

```

**íŠ¹ì§•**:
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: BM25(ê¸°ë³¸ weight=0.4) + ë²¡í„°(ê¸°ë³¸ weight=0.6)ë¥¼ ê²°í•©í•´ ì •ë°€ë„ì™€ ì¬í˜„ì„± ê· í˜•
- ë©”íƒ€ë°ì´í„° í•„í„° ì§€ì›: ì§€ì—­/ì „êµ­ í•„í„° ë“± `metadata_filter`ê°€ ì ìš©ë˜ì–´ ì§€ì—­ ê¸°ë°˜ ê²€ìƒ‰ ê°€ëŠ¥
- ì•ˆì •ì„± ì§€í–¥ ì´ˆê¸°í™”: BM25/Vector retriever ìƒì„± ì‹¤íŒ¨ ì‹œ í´ë°± ë¡œì§ìœ¼ë¡œ ê°€ëŠ¥í•œ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì‚¬ìš©
- LangChain `EnsembleRetriever`ë¥¼ ì´ìš©í•œ ê°€ì¤‘ì¹˜ ê¸°ë°˜ í†µí•©(íŒŒë¼ë¯¸í„°ë¡œ k ë° ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥)

---

### 4.4 ReciprocalRankFusion (ìˆœìœ„ í†µí•©)

**íŒŒì¼**: `src/advanced_rag.py` (Line 315-370)

**ëª©ì **: ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë­í‚¹ ê¸°ë°˜ìœ¼ë¡œ í†µí•©

**ì½”ë“œ**:
```python
class ReciprocalRankFusion:
    """ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë­í‚¹ ê¸°ë°˜ìœ¼ë¡œ í†µí•©"""
    def __init__(self, k: int = 60):
        self.k = k
    def fuse(self, results_dict: Dict[str, List[Tuple[any, float]]], top_k: int = 10) -> List[any]:
        doc_scores = {}
        for method, results in results_dict.items():
            for rank, (doc, score) in enumerate(results, 1):
                doc_id = doc.metadata.get('policy_id', id(doc))
                rrf_score = 1.0 / (self.k + rank)
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {'doc': doc, 'score': 0}
                doc_scores[doc_id]['score'] += rrf_score
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1]['score'], reverse=True)
        final_docs = [item[1]['doc'] for item in sorted_docs[:top_k]]
        return final_docs
```

**íŠ¹ì§•**:
- ë‹¤ì¤‘ ê²€ìƒ‰ ê²°ê³¼ í†µí•©: ì—¬ëŸ¬ ì¿¼ë¦¬ì™€ ê²€ìƒ‰ ë°©ë²•ì—ì„œ ì–»ì€ ê²°ê³¼ë¥¼ ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ ê²°í•©
- RRF ìŠ¤ì½”ì–´ë§: ê°ê°ì˜ ê²°ê³¼ ìˆœìœ„ì— ëŒ€í•´ `1/(k + rank)`ë¥¼ í•©ì‚°í•˜ì—¬ ì•ˆì •ì ì¸ ìƒìœ„ ë¬¸ì„œ ì„ ì •
- ê¸°ë³¸ íŒŒë¼ë¯¸í„°: í´ë˜ìŠ¤ëŠ” `k=60`ë¥¼ ì‚¬ìš©í•˜ë©°, íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” `top_k=20`ìœ¼ë¡œ ìµœì¢… ì„ íƒ(í•„ìš”ì‹œ ì¡°ì • ê°€ëŠ¥)
- ì¤‘ë³µ ë¬¸ì„œ ë³‘í•©ê³¼ ìˆœìœ„ ì•ˆì •ì„± ì œê³µ

---

### 4.5 ConversationMemory (ëŒ€í™” ê¸°ë¡)

**íŒŒì¼**: `src/advanced_rag.py` (Line 375-420)

**ëª©ì **: ìµœê·¼ ëŒ€í™” ê¸°ë¡ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ

**ì½”ë“œ**:
```python
@dataclass
class ConversationMemory:
    messages: List[Dict] = field(default_factory=list)
    max_history: int = 10
    def add_message(self, role: str, content: str):
        self.messages.append({"role": role, "content": content, "timestamp": datetime.now().isoformat()})
        if len(self.messages) > self.max_history * 2:
            self.messages = self.messages[-self.max_history * 2:]
    def get_context(self) -> str:
        if not self.messages:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"
        context_parts = []
        for msg in self.messages[-6:]:
            role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
            context_parts.append(f"{role}: {msg['content']}")
        return "\n".join(context_parts)
    def clear(self):
        self.messages.clear()
```

**íŠ¹ì§•**:
- ëŒ€í™” ë§¥ë½ ìœ ì§€: ìµœê·¼ 3í„´(=ìµœëŒ€ 6ê°œ ë©”ì‹œì§€)ì„ ê¸°ë³¸ìœ¼ë¡œ ë³´ê´€í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
- í¬ê¸° ì œì–´: `max_history`ë¡œ ë³´ê´€ ê¸¸ì´ ì¡°ì • ê°€ëŠ¥, ì´ˆê³¼ ì‹œ FIFOë¡œ ìë™ ì •ë¦¬
- ë¬¸ìì—´ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜: LLM ì…ë ¥ìš©ìœ¼ë¡œ ì í•©í•œ í¬ë§·(ì—­í•  ë¼ë²¨ í¬í•¨)ìœ¼ë¡œ ë³€í™˜

---

### 4.6 AdvancedRAGPipeline (í†µí•© íŒŒì´í”„ë¼ì¸)

**íŒŒì¼**: `src/advanced_rag.py` (Line 425-640)

**ëª©ì **: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•˜ì—¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

**í•µì‹¬ ë©”ì„œë“œ: `query()`**

**ì½”ë“œ**:
```python
def query(self, user_query: str) -> Dict:
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    
    # 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
    if self.router:
        route_result = self.router.route(user_query)
        if not route_result['is_valid']:
            return {
                "answer": "ìŒâ€¦ ì´í•´ë¥¼ ëª» í–ˆì–´ğŸ˜¥. í•œ ë²ˆë§Œ ë‹¤ì‹œ ì–˜ê¸°í•´ì¤˜!",
                "documents": [],
                "metadata": route_result
            }
        query = route_result['refined_query']
    else:
        query = user_query
    
    # 2. Region Filter: ì§€ì—­ ì •ë³´ ì¶”ì¶œ ë° í•„í„° ìƒì„±
    metadata_filter = None
    region_info = None
    if self.region_filter:
        region_info = self.region_filter.detect_region(query)
        metadata_filter = self.region_filter.build_filter(region_info)
    
    # 3. Multi-Query: ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±
    if self.multi_query:
        queries = self.multi_query.generate(query)
    else:
        queries = [query]
    
    # 4. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©)
    if self.ensemble:
        search_results = self.ensemble.retrieve(queries, metadata_filter)
    else:
        if metadata_filter:
            docs_with_score = self.vectorstore.similarity_search_with_score(query, k=5, filter=metadata_filter)
        else:
            docs_with_score = self.vectorstore.similarity_search_with_score(query, k=5)
        search_results = {'dense': docs_with_score}
    
    # 5. RRF: ê²€ìƒ‰ ê²°ê³¼ í†µí•©
    if self.rrf:
        docs = self.rrf.fuse(search_results, top_k=20)
    else:
        docs = [doc for doc, score in search_results['dense']]
    
    # 6. Region Filter: ì§€ì—­ ê¸°ë°˜ í›„ì²˜ë¦¬ í•„í„°ë§
    if self.region_filter and region_info:
        docs = self.region_filter.filter_documents(docs, region_info)
    
    # 7. Memory: ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
    if self.memory:
        context = self.memory.get_context()
    else:
        context = "ì´ì „ ëŒ€í™” ì—†ìŒ"
    
    # 8. LLM: ìµœì¢… ë‹µë³€ ìƒì„± (ì •ì±…ëª… ì¤‘ë³µ ì—†ì´ ìµœëŒ€ 3ê°œë§Œ)
    seen_titles = set()
    unique_docs = []
    for doc in docs:
        title = doc.metadata.get('ì •ì±…ëª…', 'ì œëª© ì—†ìŒ')
        if title not in seen_titles:
            seen_titles.add(title)
            unique_docs.append(doc)
        if len(unique_docs) >= 3:
            break
    docs_text = "\\n\\n".join([
        f"[ì •ì±… {i+1}] {doc.metadata.get('ì •ì±…ëª…', 'ì œëª© ì—†ìŒ')}\\n{doc.page_content[:500]}"
        for i, doc in enumerate(unique_docs)
    ])
    try:
        response = self.answer_prompt | self.llm | StrOutputParser()
        answer = response.invoke({
            "context": context,
            "documents": docs_text,
            "query": user_query
        })
        summary_response = self.summary_prompt | self.llm | StrOutputParser()
        summary = summary_response.invoke({"answer": answer})
        if self.memory:
            self.memory.add_message("user", user_query)
            self.memory.add_message("assistant", answer)
        return {
            "answer": answer,
            "summary": summary,
            "documents": docs,
            "metadata": {
                "queries": queries,
                "num_docs_retrieved": len(docs),
                "has_context": bool(self.memory and self.memory.messages),
                "region_filter": metadata_filter
            }
        }
    except Exception as e:
        return {
            "answer": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "documents": [],
            "metadata": {"error": str(e)}
        }
```

**íŠ¹ì§•**:
- ë‹¨ê³„ë³„ í†µí•© íŒŒì´í”„ë¼ì¸: Router â†’ Region Filter â†’ Multi-Query â†’ Ensemble Retriever â†’ RRF â†’ Region í›„ì²˜ë¦¬ â†’ Memory â†’ LLM ìˆœìœ¼ë¡œ ì‹¤í–‰
- ëª¨ë“ˆí™” ë° ê°€ë³€ì„±: ì´ˆê¸°í™” ì‹œ ê° ì»´í¬ë„ŒíŠ¸(router, multi_query, ensemble, rrf, memory, region_filter)ë¥¼ ì¼œ/ë„ê¸° ê°€ëŠ¥
- ì¶œë ¥ ì œí•œ ë° ì¤‘ë³µ ì œê±°: ë¬¸ì„œ ì¤‘ë³µ ì œê±° í›„ ê¸°ë³¸ì ìœ¼ë¡œ ìµœëŒ€ 3ê±´ì˜ ì •ì±…ì„ ìš”ì•½Â·ì¶œë ¥(ì„¤ì • ë³€ê²½ ê°€ëŠ¥)
- í’ë¶€í•œ ë°˜í™˜ ë©”íƒ€ë°ì´í„°: ì¿¼ë¦¬ ëª©ë¡, ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜, ì»¨í…ìŠ¤íŠ¸ ìœ ë¬´, ì ìš©ëœ ë©”íƒ€í•„í„° ë“± ë°˜í™˜
- ì˜¤ë¥˜ í´ë°±: ê° ë‹¨ê³„ ì‹¤íŒ¨ ì‹œ ë‹¨ê³„ë³„ í´ë°± ë¡œì§ìœ¼ë¡œ ì•ˆì •ì  ì‘ë‹µ ì œê³µ

---

## 5. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™

### 5.1 ChromaDB ì´ˆê¸°í™”

**íŒŒì¼**: `src/advanced_rag.py` (Line 548-640)

**í•¨ìˆ˜**: `initialize_rag_pipeline()`

**ì½”ë“œ**:
```python
def initialize_rag_pipeline(vectordb_path: str = None, api_key: str = None):
    """
    Streamlitì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í•¨ìˆ˜
    
    Args:
        vectordb_path: VectorDB ê²½ë¡œ (Noneì´ë©´ ìë™ ê³„ì‚°)
        api_key: OpenAI API Key (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
    
    Returns:
        AdvancedRAGPipeline: ì´ˆê¸°í™”ëœ íŒŒì´í”„ë¼ì¸ ê°ì²´
    """
    # API Key ì„¤ì •
    if api_key:
        os.environ['OPENAI_API_KEY'] = api_key
    else:
        api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        raise ValueError('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    
    # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.0,
        api_key=api_key
    )
    
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=api_key
    )
    
    # VectorDB ê²½ë¡œ ì„¤ì •
    if vectordb_path is None:
        vectordb_path = os.path.join(os.getcwd(), "data", "vectordb")
    
    if not os.path.exists(vectordb_path):
        raise FileNotFoundError(f"VectorDB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vectordb_path}")
    
    # VectorStore ë¡œë“œ
    vectorstore = Chroma(
        collection_name="youth_policies",
        embedding_function=embeddings,
        persist_directory=vectordb_path
    )
    
    # ë¬¸ì„œ ë¡œë“œ (BM25ë¥¼ ìœ„í•´ í•„ìš”)
    all_docs = vectorstore.get()
    
    if not all_docs or not all_docs.get('documents'):
        raise ValueError("VectorDBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    documents = []
    for i, doc_text in enumerate(all_docs['documents']):
        if doc_text and doc_text.strip():
            metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}
            documents.append(Document(page_content=doc_text, metadata=metadata))
    
    # RAG íŒŒì´í”„ë¼ì¸ ìƒì„±
    rag = AdvancedRAGPipeline(
        documents=documents,
        vectorstore=vectorstore,
        llm=llm,
        enable_router=True,
        enable_multi_query=True,
        enable_ensemble=True,
        enable_rrf=True,
        enable_memory=True,
        enable_region_filter=True,
        bm25_k=5,
        vector_k=10,
        bm25_weight=0.4,
        vector_weight=0.6
    )
    
    return rag
```

**íŠ¹ì§•**:
- ìœ ì—°í•œ ì´ˆê¸°í™”: `api_key` íŒŒë¼ë¯¸í„° ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ `OPENAI_API_KEY`ë¡œ ì„¤ì • ê°€ëŠ¥
- LLM/ì„ë² ë”© ì„¤ì •: ê¸°ë³¸ LLMì€ `gpt-4o-mini`, ì„ë² ë”©ì€ `text-embedding-3-small`ìœ¼ë¡œ ì´ˆê¸°í™”(í•„ìš”ì‹œ ë³€ê²½ ê°€ëŠ¥)
- VectorDB ë¡œë”© ë° ê²€ì¦: ì§€ì • ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , DBì—ì„œ ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ì½ì–´ `Document` ê°ì²´ë¡œ ë³€í™˜
- ê¸°ë³¸ êµ¬ì„±: ëª¨ë“  í•µì‹¬ ì»´í¬ë„ŒíŠ¸(router, multi_query, ensemble, rrf, memory, region_filter)ë¥¼ í™œì„±í™”í•œ ìƒíƒœë¡œ ë°˜í™˜(í•„ìš”ì‹œ í”Œë˜ê·¸ë¡œ ë¹„í™œì„±í™” ê°€ëŠ¥)

---

### 5.2 ë²¡í„° DB êµ¬ì¶•

**íŒŒì¼**: `notebooks/build_vectordb.py` (Line 1-572)

**ì£¼ìš” í•¨ìˆ˜**:

#### 1) ë°ì´í„° ë¡œë“œ
```python
def load_preprocessed_data(filepath):
    """
    ì „ì²˜ë¦¬ëœ JSON ë°ì´í„° ë¡œë“œ
    
    Args:
        filepath: JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        list: ì •ì±… ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return data
```
#### 2) í…ìŠ¤íŠ¸ ìƒì„±
```python
def create_policy_text(policy):
    """
    ì •ì±… ë°ì´í„°ë¥¼ ì„ë² ë”©ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ë°°ì¹˜í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ
    
    Args:
        policy: ì •ì±… ë”•ì…”ë„ˆë¦¬
        
    Returns:
        str: ê²°í•©ëœ í…ìŠ¤íŠ¸
    """
    # ì£¼ìš” í•„ë“œë“¤ì„ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ìƒì„± (ì¤‘ìš”ë„ ìˆœ)
    text_parts = []
    
    # 1. ê°€ì¥ ì¤‘ìš”: ì •ì±…ëª…ê³¼ ë¶„ì•¼
    if policy.get('ì •ì±…ëª…'):
        text_parts.append(f"ì •ì±…ëª…: {policy['ì •ì±…ëª…']}")
    
    if policy.get('ëŒ€ë¶„ë¥˜'):
        text_parts.append(f"ëŒ€ë¶„ë¥˜: {policy['ëŒ€ë¶„ë¥˜']}")
    
    if policy.get('ì¤‘ë¶„ë¥˜'):
        text_parts.append(f"ì¤‘ë¶„ë¥˜: {policy['ì¤‘ë¶„ë¥˜']}")
    
    # 2. ì •ì±… ì„¤ëª… (í•µì‹¬ ë‚´ìš©)
    if policy.get('ì •ì±…ì„¤ëª…'):
        text_parts.append(f"ì •ì±…ì„¤ëª…: {policy['ì •ì±…ì„¤ëª…']}")
    
    # 3. ì§€ì›ë‚´ìš© (ê¸¸ì´ ì œí•œ ì—†ìŒ - ì¤‘ìš”í•œ ì •ë³´)
    if policy.get('ì§€ì›ë‚´ìš©'):
        text_parts.append(f"ì§€ì›ë‚´ìš©: {policy['ì§€ì›ë‚´ìš©']}")
    
    if policy.get('ì •ì±…í‚¤ì›Œë“œ'):
        text_parts.append(f"í‚¤ì›Œë“œ: {policy['ì •ì±…í‚¤ì›Œë“œ']}")
    
    # 4. ì§€ì—­ ì •ë³´ (ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ)
    if policy.get('ì§€ì—­'):
        # ì§€ì—­ ì •ë³´ê°€ ê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì ì ˆíˆ í¬í•¨
        region = policy['ì§€ì—­']
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì§€ì—­ì„ ê°„ë‹¨íˆ ì²˜ë¦¬
        if len(region) > 500:
            # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ (ì „êµ­ ì •ì±…ì¼ ê°€ëŠ¥ì„±)
            region = region[:500] + "..."
        text_parts.append(f"ì ìš©ì§€ì—­: {region}")
    
    if policy.get('ì§€ì—­ë²”ìœ„'):
        region_level = policy['ì§€ì—­ë²”ìœ„']

    # ì§€ì—­ ë²”ìœ„(ì „êµ­/ì§€ì—­)ì„ ìì—°ì–´ ë¼ë²¨ë¡œ ì¶”ê°€
        if region_level == 'ì „êµ­':
            text_parts.append("ì§€ì—­ë²”ìœ„: ì „êµ­ (ëª¨ë“  ì§€ì—­ ì ìš©)")
        else:
            text_parts.append(f"ì§€ì—­ë²”ìœ„: ì§€ì—­ ì ìš© (ì¼ë¶€ ì§€ì—­ ì ìš©)")
            
    # 5. ìê²© ì¡°ê±´ (ìƒì„¸)
    if policy.get('ì¶”ê°€ìê²©ì¡°ê±´'):
        # ê¸¸ì´ ì œí•œ í™•ëŒ€ (500ì)
        qual = policy['ì¶”ê°€ìê²©ì¡°ê±´'][:500]
        text_parts.append(f"ìê²©ì¡°ê±´: {qual}")
    
    # 6. ìê²© ìš”ê±´ (í•œê¸€ ë³€í™˜ëœ í•„ë“œ)
    if policy.get('ì·¨ì—…ìƒíƒœ'):
        job_status = policy['ì·¨ì—…ìƒíƒœ']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€ (ê²€ìƒ‰ í–¥ìƒ)
        natural_terms = []
        if 'ë¯¸ì·¨ì—…ì' in job_status:
            natural_terms.append('ì‹¤ì—…ì, êµ¬ì§ì, ë°±ìˆ˜, ì·¨ì—…ì¤€ë¹„ìƒ')
        if 'ì¬ì§ì' in job_status:
            natural_terms.append('ì§ì¥ì¸, ê·¼ë¡œì')
        if 'ì°½ì—…ì' in job_status or 'ì˜ˆë¹„' in job_status:
            natural_terms.append('ì°½ì—…ì¤€ë¹„, ì‚¬ì—…ì')
        
        full_status = f"ì·¨ì—…ìƒíƒœ: {job_status}"
        if natural_terms:
            full_status += f" ({', '.join(natural_terms)})"
        text_parts.append(full_status)
    
    if policy.get('í•™ë ¥ìš”ê±´'):
        edu_req = policy['í•™ë ¥ìš”ê±´']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€
        natural_edu = []
        if 'ê³ ì¡¸' in edu_req or 'ê³ êµ' in edu_req:
            natural_edu.append('ê³ ë“±í•™êµ')
        if 'ëŒ€í•™' in edu_req or 'ëŒ€ì¡¸' in edu_req:
            natural_edu.append('ëŒ€í•™êµ, í•™ì‚¬')
        if 'ì„ë°•ì‚¬' in edu_req:
            natural_edu.append('ëŒ€í•™ì›')
        
        full_edu = f"í•™ë ¥: {edu_req}"
        if natural_edu:
            full_edu += f" ({', '.join(natural_edu)})"
        text_parts.append(full_edu)
    
    if policy.get('ì „ê³µìš”ê±´'):
        major_req = policy['ì „ê³µìš”ê±´']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€
        natural_major = []
        if 'ê³µí•™' in major_req:
            natural_major.append('ì´ê³µê³„, ê¸°ìˆ , IT, ê³µëŒ€')
        if 'ìƒê²½' in major_req:
            natural_major.append('ê²½ì˜, ê²½ì œ, íšŒê³„')
        if 'ì˜ˆì²´ëŠ¥' in major_req:
            natural_major.append('ì˜ˆìˆ , ì²´ìœ¡, ìŒì•…, ë¯¸ìˆ ')
        
        full_major = f"ì „ê³µ: {major_req}"
        if natural_major:
            full_major += f" ({', '.join(natural_major)})"
        text_parts.append(full_major)
    
    if policy.get('íŠ¹í™”ë¶„ì•¼'):
        special = policy['íŠ¹í™”ë¶„ì•¼']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€
        natural_special = []
        if 'ì—¬ì„±' in special:
            natural_special.append('ì—¬ì„±ì²­ë…„, ê²½ë ¥ë‹¨ì ˆì—¬ì„±')
        if 'ì¥ì• ì¸' in special:
            natural_special.append('ì¥ì• ì²­ë…„')
        if 'í•œë¶€ëª¨' in special:
            natural_special.append('ì‹±ê¸€ë§˜, ì‹±ê¸€ëŒ€ë””, ë¯¸í˜¼ëª¨, ë¯¸í˜¼ë¶€')
        if 'ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì' in special:
            natural_special.append('ì €ì†Œë“ì¸µ, ì°¨ìƒìœ„ê³„ì¸µ')
        if 'ì¤‘ì†Œê¸°ì—…' in special:
            natural_special.append('ì¤‘ê²¬ê¸°ì—…, ìŠ¤íƒ€íŠ¸ì—…')
        
        full_special = f"íŠ¹í™”ë¶„ì•¼: {special}"
        if natural_special:
            full_special += f" ({', '.join(natural_special)})"
        text_parts.append(full_special)
    
    if policy.get('ì •ì±…ì œê³µë°©ë²•'):
        text_parts.append(f"ì œê³µë°©ë²•: {policy['ì •ì±…ì œê³µë°©ë²•']}")
    
    if policy.get('ì†Œë“ì¡°ê±´'):
        income = policy['ì†Œë“ì¡°ê±´']
        # ìì—°ì–´ í‘œí˜„ ì¶”ê°€
        natural_income = []
        if 'ë¬´ê´€' in income:
            natural_income.append('ì†Œë“ì œí•œì—†ìŒ, ëˆ„êµ¬ë‚˜')
        if 'ì—°ì†Œë“' in income:
            natural_income.append('ì†Œë“ê¸°ì¤€, ì†Œë“ì œí•œ')
        
        full_income = f"ì†Œë“ì¡°ê±´: {income}"
        if natural_income:
            full_income += f" ({', '.join(natural_income)})"
        text_parts.append(full_income)
    
    if policy.get('í˜¼ì¸ìƒíƒœ'):
        text_parts.append(f"í˜¼ì¸ìƒíƒœ: {policy['í˜¼ì¸ìƒíƒœ']}")
    
    # 7. ì—°ë ¹ ì œí•œ
    min_age = policy.get('ì§€ì›ìµœì†Œì—°ë ¹', '0')
    max_age = policy.get('ì§€ì›ìµœëŒ€ì—°ë ¹', '0')
    if min_age != '0' or max_age != '0':
        age_info = f"ëŒ€ìƒì—°ë ¹: {min_age}ì„¸ ~ {max_age}ì„¸"
        text_parts.append(age_info)
    
    # 8. ì§€ì›ê¸ˆì•¡
    min_amount = policy.get('ìµœì†Œì§€ì›ê¸ˆì•¡', '0')
    max_amount = policy.get('ìµœëŒ€ì§€ì›ê¸ˆì•¡', '0')
    if min_amount != '0' or max_amount != '0':
        amount_info = f"ì§€ì›ê¸ˆì•¡: {min_amount}ì› ~ {max_amount}ì›"
        text_parts.append(amount_info)
    
    if policy.get('ê¸°íƒ€ì§€ì›ì¡°ê±´'):
        other_cond = policy['ê¸°íƒ€ì§€ì›ì¡°ê±´'][:200]
        text_parts.append(f"ê¸°íƒ€ì¡°ê±´: {other_cond}")
    
    # 9. ì‹ ì²­ ë° ì„ ì • ë°©ë²•
    if policy.get('ì‹ ì²­ê¸°ê°„êµ¬ë¶„'):
        text_parts.append(f"ì‹ ì²­ê¸°ê°„: {policy['ì‹ ì²­ê¸°ê°„êµ¬ë¶„']}")
    
    if policy.get('ì‚¬ì—…ê¸°ê°„êµ¬ë¶„'):
        text_parts.append(f"ì‚¬ì—…ê¸°ê°„: {policy['ì‚¬ì—…ê¸°ê°„êµ¬ë¶„']}")
    
    if policy.get('ì‹ ì²­ë°©ë²•'):
        method = policy['ì‹ ì²­ë°©ë²•'][:200]  # ë„ˆë¬´ ê¸¸ë©´ ì œí•œ
        text_parts.append(f"ì‹ ì²­ë°©ë²•: {method}")
    
    if policy.get('ì„ ì •ë°©ë²•'):
        selection = policy['ì„ ì •ë°©ë²•'][:200]
        text_parts.append(f"ì„ ì •ë°©ë²•: {selection}")
    
    if policy.get('ì œì¶œì„œë¥˜'):
        docs = policy['ì œì¶œì„œë¥˜'][:200]
        text_parts.append(f"ì œì¶œì„œë¥˜: {docs}")
    
    # 10. ì°¸ì—¬ì œì™¸ëŒ€ìƒ (ì¤‘ìš” ì •ë³´)
    if policy.get('ì°¸ì—¬ì œì™¸ëŒ€ìƒ'):
        exclusion = policy['ì°¸ì—¬ì œì™¸ëŒ€ìƒ'][:300]
        text_parts.append(f"ì œì™¸ëŒ€ìƒ: {exclusion}")
    
    # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìµœì†Œí•œì˜ ì •ë³´ë¼ë„ í¬í•¨
    if not text_parts:
        text_parts.append(f"ì²­ë…„ì •ì±…")
    
    # í…ìŠ¤íŠ¸ ê²°í•© ë° ì •ì œ
    full_text = "\n".join(text_parts)
    
    # ì¤‘ë³µ ê³µë°± ì œê±° ë° ì •ë¦¬
    full_text = " ".join(full_text.split())
    
    return full_text
```

#### 3) ì„ë² ë”© ìƒì„±
```python
def get_embedding(text, model="text-embedding-3-small"):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
    
    Args:
        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸
               - text-embedding-3-small (1536ì°¨ì›, ë¹ ë¦„, ì €ë ´)
               - text-embedding-3-large (3072ì°¨ì›, ëŠë¦¼, ê³ í’ˆì§ˆ, ê³ ë¹„ìš©)
        
    Returns:
        list: ì„ë² ë”© ë²¡í„°
    """
    # í…ìŠ¤íŠ¸ ì •ì œ
    text = text.replace("\n", " ").strip()
    
    # ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬
    if not text or len(text) < 3:
        text = "ì •ì±… ì •ë³´"
    
    # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ë‚´ê¸°
    # text-embedding-3-small: ìµœëŒ€ 8191 í† í° (~32,000ì)
    # ì•ˆì „ì„ ìœ„í•´ 8000ìë¡œ ì œí•œ
    if len(text) > 8000:
        text = text[:8000]
    
    # API í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§ (Rate limit ëŒ€ì‘)
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.embeddings.create(input=[text], model=model)
            return response.data[0].embedding
        except Exception as e:
            if attempt < max_retries - 1:
                import time
                wait_time = (attempt + 1) * 2
                time.sleep(wait_time)
            else:
                raise e
```

#### 4) ChromaDB ì €ì¥
```python
def build_chromadb(policies, db_path="../data/vectordb"):
    """
    ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
    
    Args:
        policies: ì •ì±… ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        db_path: DB ì €ì¥ ê²½ë¡œ
    """
    # DB ë””ë ‰í† ë¦¬ ìƒì„±
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    db_full_path = os.path.join(project_root, "data", "vectordb")
    os.makedirs(db_full_path, exist_ok=True)
    
    # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    chroma_client = chromadb.PersistentClient(path=db_full_path)
    
    # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (ìˆìœ¼ë©´)
    try:
        chroma_client.delete_collection(name="youth_policies")
    except:
        pass
    
    # ë¬¼ë¦¬ì  íŒŒì¼ ì •ë¦¬ (ì„¸ê·¸ë¨¼íŠ¸ í´ë” ì‚­ì œ)
    import shutil
    for item in os.listdir(db_full_path):
        item_path = os.path.join(db_full_path, item)
        # UUID í˜•ì‹ì˜ í´ë”ë§Œ ì‚­ì œ (chroma.sqlite3ëŠ” ìœ ì§€)
        if os.path.isdir(item_path) and '-' in item:
            try:
                shutil.rmtree(item_path)
            except:
                pass
    
    # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
    collection = chroma_client.create_collection(
        name="youth_policies",
        metadata={"description": "ì˜¨í†µì²­ë…„ ì •ì±… ë°ì´í„°"}
    )
    
    # ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜
    embedding_batch_size = 20  # OpenAI API ë°°ì¹˜ ì œí•œ
    db_batch_size = 50  # DB ì €ì¥ ë°°ì¹˜
    
    all_policy_texts = []
    all_metadatas = []
    all_ids = []
    
    failed_count = 0
    
    # 1ë‹¨ê³„: ëª¨ë“  ì •ì±… í…ìŠ¤íŠ¸ ìƒì„±
    for idx, policy in enumerate(policies, 1):
        try:
            policy_text = create_policy_text(policy)
            all_policy_texts.append(policy_text)
            
            all_metadatas.append({
                'ì •ì±…ëª…': policy.get('ì •ì±…ëª…', ''),
                'ëŒ€ë¶„ë¥˜': policy.get('ëŒ€ë¶„ë¥˜', ''),
                'ì¤‘ë¶„ë¥˜': policy.get('ì¤‘ë¶„ë¥˜', ''),
                'ì£¼ê´€ê¸°ê´€ëª…': policy.get('ì£¼ê´€ê¸°ê´€ëª…', ''),
                'ìš´ì˜ê¸°ê´€ëª…': policy.get('ìš´ì˜ê¸°ê´€ëª…', ''),
                'ë“±ë¡ê¸°ê´€ëª…': policy.get('ë“±ë¡ê¸°ê´€ëª…', ''),
                'ìƒìœ„ê¸°ê´€ëª…': policy.get('ìƒìœ„ê¸°ê´€ëª…', ''),
                'ìƒìœ„ë“±ë¡ê¸°ê´€ëª…': policy.get('ìƒìœ„ë“±ë¡ê¸°ê´€ëª…', ''),
                'ì‹ ì²­URL': policy.get('ì‹ ì²­URL', ''),
                'ì°¸ê³ URL1': policy.get('ì°¸ê³ URL1', ''),
                'ì •ì±…í‚¤ì›Œë“œ': policy.get('ì •ì±…í‚¤ì›Œë“œ', ''),
                # ì‹ ì²­ ê´€ë ¨
                'ì‹ ì²­ê¸°ê°„': policy.get('ì‹ ì²­ê¸°ê°„', ''),
                'ì‹ ì²­ë°©ë²•': policy.get('ì‹ ì²­ë°©ë²•', ''),
                'ì œì¶œì„œë¥˜': policy.get('ì œì¶œì„œë¥˜', ''),
                # ì‚¬ì—… ê¸°ê°„
                'ì‚¬ì—…ì‹œì‘ì¼': policy.get('ì‚¬ì—…ì‹œì‘ì¼', ''),
                'ì‚¬ì—…ì¢…ë£Œì¼': policy.get('ì‚¬ì—…ì¢…ë£Œì¼', ''),
                # ì‹¬ì‚¬Â·ì„ ì •
                'ì„ ì •ë°©ë²•': policy.get('ì„ ì •ë°©ë²•', ''),
                # ìê²© ê´€ë ¨
                'ì¶”ê°€ìê²©ì¡°ê±´': policy.get('ì¶”ê°€ìê²©ì¡°ê±´', ''),
                'ì°¸ì—¬ì œì™¸ëŒ€ìƒ': policy.get('ì°¸ì—¬ì œì™¸ëŒ€ìƒ', ''),
                'ì§€ì›ìµœì†Œì—°ë ¹': policy.get('ì§€ì›ìµœì†Œì—°ë ¹', '0'),
                'ì§€ì›ìµœëŒ€ì—°ë ¹': policy.get('ì§€ì›ìµœëŒ€ì—°ë ¹', '0'),
                # ì§€ì›ê¸ˆ ê´€ë ¨
                'ìµœì†Œì§€ì›ê¸ˆì•¡': policy.get('ìµœì†Œì§€ì›ê¸ˆì•¡', '0'),
                'ìµœëŒ€ì§€ì›ê¸ˆì•¡': policy.get('ìµœëŒ€ì§€ì›ê¸ˆì•¡', '0'),
                'ê¸°íƒ€ì§€ì›ì¡°ê±´': policy.get('ê¸°íƒ€ì§€ì›ì¡°ê±´', ''),
                # í•œê¸€ ë³€í™˜ëœ í•„ë“œë“¤
                'ì¬ê³µê¸°ê´€ê·¸ë£¹': policy.get('ì¬ê³µê¸°ê´€ê·¸ë£¹', ''),
                'ì •ì±…ì œê³µë°©ë²•': policy.get('ì •ì±…ì œê³µë°©ë²•', ''),
                'ì •ì±…ìŠ¹ì¸ìƒíƒœ': policy.get('ì •ì±…ìŠ¹ì¸ìƒíƒœ', ''),
                'ì‹ ì²­ê¸°ê°„êµ¬ë¶„': policy.get('ì‹ ì²­ê¸°ê°„êµ¬ë¶„', ''),
                'ì‚¬ì—…ê¸°ê°„êµ¬ë¶„': policy.get('ì‚¬ì—…ê¸°ê°„êµ¬ë¶„', ''),
                'í˜¼ì¸ìƒíƒœ': policy.get('í˜¼ì¸ìƒíƒœ', ''),
                'ì†Œë“ì¡°ê±´': policy.get('ì†Œë“ì¡°ê±´', ''),
                'ì „ê³µìš”ê±´': policy.get('ì „ê³µìš”ê±´', ''),
                'ì·¨ì—…ìƒíƒœ': policy.get('ì·¨ì—…ìƒíƒœ', ''),
                'í•™ë ¥ìš”ê±´': policy.get('í•™ë ¥ìš”ê±´', ''),
                'íŠ¹í™”ë¶„ì•¼': policy.get('íŠ¹í™”ë¶„ì•¼', ''),
                'ì§€ì—­': policy.get('ì§€ì—­', ''),
                'ì§€ì—­ë²”ìœ„': policy.get('ì§€ì—­ë²”ìœ„', ''),
            })
            all_ids.append(f"policy_{idx}")
                
        except Exception as e:
            failed_count += 1
            all_policy_texts.append("ì²­ë…„ì •ì±…")
            all_metadatas.append({})
            all_ids.append(f"policy_{idx}")
    
    # 2ë‹¨ê³„: ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    all_embeddings = []
    
    for i in range(0, len(all_policy_texts), embedding_batch_size):
        batch_texts = all_policy_texts[i:i+embedding_batch_size]
        try:
            batch_embeddings = get_embeddings_batch(batch_texts)
            all_embeddings.extend(batch_embeddings)
        except Exception as e:
            # í´ë°±: ê°œë³„ ì„ë² ë”©
            for text in batch_texts:
                try:
                    emb = get_embedding(text)
                    all_embeddings.append(emb)
                except:
                    all_embeddings.append([0] * 1536)  # ë¹ˆ ë²¡í„°
                    failed_count += 1
    
    # 3ë‹¨ê³„: DBì— ë°°ì¹˜ ì €ì¥
    for i in range(0, len(all_policy_texts), db_batch_size):
        batch_docs = all_policy_texts[i:i+db_batch_size]
        batch_metas = all_metadatas[i:i+db_batch_size]
        batch_ids = all_ids[i:i+db_batch_size]
        batch_embs = all_embeddings[i:i+db_batch_size]
        
        collection.add(
            documents=batch_docs,
            metadatas=batch_metas,
            ids=batch_ids,
            embeddings=batch_embs
        )
    
    return collection
```

**íŠ¹ì§•**:
- ì„ë² ë”©/ì €ì¥ ë°°ì¹˜: ì„ë² ë”© ë°°ì¹˜ í¬ê¸°(`embedding_batch_size`)ëŠ” ê¸°ë³¸ 20, DBì— ì €ì¥í•˜ëŠ” ë°°ì¹˜(`db_batch_size`)ëŠ” ê¸°ë³¸ 50ìœ¼ë¡œ ì„¤ì •ë˜ì–´ íš¨ìœ¨ì  ì²˜ë¦¬
- API ì œí•œ ëŒ€ì‘: OpenAI ì„ë² ë”© í˜¸ì¶œì— ì¬ì‹œë„ ë¡œì§ì„ ì ìš©í•˜ê³ , ì‹¤íŒ¨ ì‹œ ê°œë³„ í´ë°± ë˜ëŠ” ë¹ˆ ë²¡í„°ë¡œ ëŒ€ì²´
- ë©”íƒ€ë°ì´í„° ì •êµí™”: ì •ì±…ë³„ ë‹¤ìˆ˜ ë©”íƒ€í•„ë“œë¥¼ ë§¤í•‘í•˜ì—¬ ê²€ìƒ‰ ì‹œ í•„í„°ë§ ë° í‘œì‹œ ì •ë³´ë¡œ í™œìš©
- ì•ˆì „í•œ ì´ˆê¸°í™” ë° ì •ë¦¬: ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ë° ë¬¼ë¦¬ì  ì„¸ê·¸ë¨¼íŠ¸ í´ë” ì •ë¦¬ ë¡œì§ í¬í•¨
- ì§„í–‰ë¥ /ì˜¤ë¥˜ ì§‘ê³„: ì‹¤íŒ¨ ê±´ìˆ˜ ì§‘ê³„ ë° ì²˜ë¦¬ ìƒíƒœ í™•ì¸ ê°€ëŠ¥

---
